{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  TRM Architecture Study (H/L Cycles)\n",
        "\n",
        "One-click runnable notebook to compare **different TRM architectures**, focusing on **`H_cycles` (H)** and **`L_cycles` (L)**, while keeping the overall training loop and compute budget consistent.\n",
        "\n",
        "## âœ… What changed vs the previous ACT notebook?\n",
        "- **Before**: compared different `halt_max_steps` (ACT step cap).\n",
        "- **Now**: compare different **(H, L)** settings (architecture), with **ACT early stopping disabled** during training for a fair ablation.\n",
        "\n",
        "## âœ… Alignment with Trelis Implementation\n",
        "This notebook is still structurally aligned with `TinyRecursiveModels-Trelis` (notably `config/arch/trm.yaml` + `cfg_pretrain*.yaml`) for the baseline hyperparameters (except where explicitly overridden by the sweep).\n",
        "\n",
        "**Intentional differences**\n",
        "- Single GPU (Trelis uses multi-GPU)\n",
        "- AdamW optimizer (Trelis uses Muon)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 1: Configuration - EDIT THIS\n",
        "# ============================================================================\n",
        "import os\n",
        "\n",
        "# API Keys\n",
        "WANDB_API_KEY = '' # Or set directly\n",
        "HF_TOKEN = \"\"\n",
        "\n",
        "# --- Architecture Experiment Selection ---\n",
        "# You can either run a single config (SELECTED_CONFIG) or a sweep in Cell 13.\n",
        "\n",
        "# ðŸ’¡ Recommended 5-Config Set for Initial Comparison:\n",
        "#   1. H2-L2  (minimal, efficiency baseline - 12 blocks/step)\n",
        "#   2. H3-L4  (baseline, standard - 30 blocks/step) â­\n",
        "#   3. H4-L2  (high H, low L - different ratio - 24 blocks/step)\n",
        "#   4. H3-L6  (baseline H, more L - 42 blocks/step)\n",
        "#   5. H4-L4  (balanced high compute - 40 blocks/step)\n",
        "#\n",
        "SELECTED_CONFIG = 'H3-L4'  # â­ Change this to run different configs\n",
        "\n",
        "# --- Training Settings (step-based, aligned with Trelis training semantics) ---\n",
        "MAX_TRAIN_STEPS = 5000\n",
        "BATCH_SIZE = 2048\n",
        "EVAL_EVERY_STEPS = max(1, MAX_TRAIN_STEPS // 5)\n",
        "MIN_EVAL_INTERVAL = 0\n",
        "\n",
        "# --- Compute Budget (carry-based ACT; disable q-based early halt) ---\n",
        "HALT_MAX_STEPS = 16\n",
        "\n",
        "# --- Dataset Settings ---\n",
        "TRAIN_SUBSAMPLE = 1000\n",
        "TEST_SUBSAMPLE = 50_000\n",
        "NUM_AUGMENT = 1000\n",
        "FORCE_REBUILD = False\n",
        "TEST_SEED = 42\n",
        "\n",
        "# Compute stats helper (for reference)\n",
        "L_LAYERS = 2  # Fixed in model config\n",
        "def get_blocks_per_step(H, L):\n",
        "    \"\"\"Calculate blocks per step: H_cycles * (L_cycles + 1) * L_layers\"\"\"\n",
        "    return H * (L + 1) * L_LAYERS\n",
        "\n",
        "print(f'Selected: {SELECTED_CONFIG}, MAX_TRAIN_STEPS={MAX_TRAIN_STEPS}, BatchSize: {BATCH_SIZE}, HALT_MAX_STEPS={HALT_MAX_STEPS}')\n",
        "print(f'Eval every {EVAL_EVERY_STEPS} steps, TEST_SUBSAMPLE={TEST_SUBSAMPLE:,}, TRAIN_SUBSAMPLE={TRAIN_SUBSAMPLE:,}, NUM_AUGMENT={NUM_AUGMENT:,}')\n",
        "\n",
        "# Print selected config compute stats\n",
        "if '-' in SELECTED_CONFIG:\n",
        "    try:\n",
        "        H, L = map(int, SELECTED_CONFIG.replace('H', '').replace('L', '').split('-'))\n",
        "        blocks_per_step = get_blocks_per_step(H, L)\n",
        "        blocks_per_puzzle = blocks_per_step * HALT_MAX_STEPS\n",
        "        print(f'ðŸ“Š {SELECTED_CONFIG} Compute: {blocks_per_step} blocks/step, {blocks_per_puzzle} blocks/puzzle')\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 2: Install Dependencies\n",
        "# ============================================================================\n",
        "!pip install -q torch einops tqdm numpy pydantic wandb coolname datasets huggingface_hub pandas matplotlib\n",
        "print('Dependencies installed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 3: Imports & GPU Setup\n",
        "# ============================================================================\n",
        "from typing import Optional, Any, Sequence, List, Tuple, Dict\n",
        "from dataclasses import dataclass\n",
        "import os, math, json, shutil, copy, time\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import coolname\n",
        "import pydantic\n",
        "from pydantic import BaseModel\n",
        "import einops\n",
        "from torch.nn.functional import scaled_dot_product_attention\n",
        "\n",
        "IGNORE_LABEL_ID = -100\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu = torch.cuda.get_device_name(0)\n",
        "    print(f'GPU: {gpu}')\n",
        "    if 'H100' in gpu or 'A100' in gpu:\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        torch.backends.cudnn.allow_tf32 = True\n",
        "        print('TF32 enabled')\n",
        "    torch.cuda.set_device(0)\n",
        "\n",
        "if WANDB_API_KEY:\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    print('Wandb logged in')\n",
        "else:\n",
        "    os.environ['WANDB_DISABLED'] = 'true'\n",
        "    print('WANDB_API_KEY not set; wandb disabled')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 4: Common Utilities\n",
        "# ============================================================================\n",
        "def trunc_normal_init_(tensor, std=1.0, lower=-2.0, upper=2.0):\n",
        "    with torch.no_grad():\n",
        "        if std == 0:\n",
        "            tensor.zero_()\n",
        "        else:\n",
        "            sqrt2 = math.sqrt(2)\n",
        "            a, b = math.erf(lower/sqrt2), math.erf(upper/sqrt2)\n",
        "            z = (b-a)/2\n",
        "            c = (2*math.pi)**-0.5\n",
        "            pdf_u, pdf_l = c*math.exp(-0.5*lower**2), c*math.exp(-0.5*upper**2)\n",
        "            comp_std = std/math.sqrt(1-(upper*pdf_u-lower*pdf_l)/z-((pdf_u-pdf_l)/z)**2)\n",
        "            tensor.uniform_(a, b).erfinv_().mul_(sqrt2*comp_std).clip_(lower*comp_std, upper*comp_std)\n",
        "    return tensor\n",
        "\n",
        "CosSin = Tuple[torch.Tensor, torch.Tensor]\n",
        "def _find_multiple(a, b): return (-(a//-b))*b\n",
        "def rotate_half(x): return torch.cat((-x[..., x.shape[-1]//2:], x[..., :x.shape[-1]//2]), dim=-1)\n",
        "def apply_rotary_pos_emb(q, k, cos, sin):\n",
        "    orig = q.dtype; q, k = q.to(cos.dtype), k.to(cos.dtype)\n",
        "    return ((q*cos.unsqueeze(-2))+(rotate_half(q)*sin.unsqueeze(-2))).to(orig), ((k*cos.unsqueeze(-2))+(rotate_half(k)*sin.unsqueeze(-2))).to(orig)\n",
        "def rms_norm(x, eps):\n",
        "    dt = x.dtype; x = x.float(); return (x*torch.rsqrt(x.square().mean(-1,keepdim=True)+eps)).to(dt)\n",
        "print('Utilities loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 5: Layers with LoRA Support\n",
        "# ============================================================================\n",
        "class CastedLinear(nn.Module):\n",
        "    def __init__(self, in_f, out_f, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(trunc_normal_init_(torch.empty((out_f, in_f)), std=1.0/(in_f**0.5)))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_f)) if bias else None\n",
        "        self._lora_rank = 0; self._lora_alpha = 1.0; self._lora_scaling = 1.0\n",
        "        self._lora_dropout = None; self._lora_A = None; self._lora_B = None\n",
        "    def forward(self, x):\n",
        "        out = F.linear(x, self.weight.to(x.dtype), self.bias.to(x.dtype) if self.bias is not None else None)\n",
        "        if self._lora_rank > 0 and self._lora_A is not None:\n",
        "            lx = self._lora_dropout(x) if self._lora_dropout else x\n",
        "            out = out + F.linear(F.linear(lx.to(self._lora_A.dtype), self._lora_A), self._lora_B).to(out.dtype) * self._lora_scaling\n",
        "        return out\n",
        "    def enable_lora(self, rank, alpha=None, dropout=0.0, train_base=False, train_bias=False):\n",
        "        if rank <= 0: return\n",
        "        if self._lora_rank > 0: raise RuntimeError('LoRA already enabled')\n",
        "        self._lora_rank = rank\n",
        "        self._lora_alpha = float(alpha if alpha else rank)\n",
        "        self._lora_scaling = self._lora_alpha / rank\n",
        "        self._lora_dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
        "        self._lora_A = nn.Parameter(torch.zeros(rank, self.weight.shape[1]))\n",
        "        self._lora_B = nn.Parameter(torch.zeros(self.weight.shape[0], rank))\n",
        "        nn.init.kaiming_uniform_(self._lora_A, a=math.sqrt(5)); nn.init.zeros_(self._lora_B)\n",
        "        if not train_base: self.weight.requires_grad = False\n",
        "        if self.bias is not None and not train_bias: self.bias.requires_grad = False\n",
        "\n",
        "class CastedEmbedding(nn.Module):\n",
        "    def __init__(self, n, d, std, dtype):\n",
        "        super().__init__()\n",
        "        self.cast_to = dtype\n",
        "        self.embedding_weight = nn.Parameter(trunc_normal_init_(torch.empty(n, d), std=std))\n",
        "    def forward(self, x): return F.embedding(x, self.embedding_weight.to(self.cast_to))\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim, max_pos, base, device=None):\n",
        "        super().__init__()\n",
        "        inv_freq = 1.0/(base**(torch.arange(0, dim, 2, dtype=torch.float32, device=device)/dim))\n",
        "        freqs = torch.outer(torch.arange(max_pos, dtype=torch.float32, device=device), inv_freq)\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        self.cos_cached = nn.Buffer(emb.cos(), persistent=False)\n",
        "        self.sin_cached = nn.Buffer(emb.sin(), persistent=False)\n",
        "    def forward(self): return self.cos_cached, self.sin_cached\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden, head_dim, heads, kv_heads, causal=False):\n",
        "        super().__init__()\n",
        "        self.hidden, self.head_dim, self.heads, self.kv_heads, self.causal = hidden, head_dim, heads, kv_heads, causal\n",
        "        self.out_size = head_dim * heads\n",
        "        self.qkv_proj = CastedLinear(hidden, (heads + 2*kv_heads)*head_dim, False)\n",
        "        self.o_proj = CastedLinear(self.out_size, hidden, False)\n",
        "    def forward(self, cos_sin, x):\n",
        "        B, L, _ = x.shape\n",
        "        qkv = self.qkv_proj(x).view(B, L, self.heads + 2*self.kv_heads, self.head_dim)\n",
        "        q, k, v = qkv[:,:,:self.heads], qkv[:,:,self.heads:self.heads+self.kv_heads], qkv[:,:,self.heads+self.kv_heads:]\n",
        "        if cos_sin: q, k = apply_rotary_pos_emb(q, k, *cos_sin)\n",
        "        q, k, v = (einops.rearrange(t, 'B S H D -> B H S D') for t in (q, k, v))\n",
        "        out = scaled_dot_product_attention(q, k, v, is_causal=self.causal)\n",
        "        return self.o_proj(einops.rearrange(out, 'B H S D -> B S H D').reshape(B, L, self.out_size))\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    def __init__(self, hidden, expansion):\n",
        "        super().__init__()\n",
        "        inter = _find_multiple(round(expansion*hidden*2/3), 256)\n",
        "        self.gate_up = CastedLinear(hidden, inter*2, False)\n",
        "        self.down = CastedLinear(inter, hidden, False)\n",
        "    def forward(self, x):\n",
        "        g, u = self.gate_up(x).chunk(2, dim=-1)\n",
        "        return self.down(F.silu(g) * u)\n",
        "\n",
        "def enable_lora_for_model(model, rank, alpha=None, dropout=0.0, train_base=False, train_bias=False):\n",
        "    if rank <= 0: return 0\n",
        "    cnt = 0\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, CastedLinear):\n",
        "            m.enable_lora(rank, alpha, dropout, train_base, train_bias); cnt += 1\n",
        "    return cnt\n",
        "\n",
        "def count_parameters(model):\n",
        "    total = trainable = lora = 0\n",
        "    for n, p in model.named_parameters():\n",
        "        total += p.numel()\n",
        "        if p.requires_grad: trainable += p.numel()\n",
        "        if '_lora_' in n: lora += p.numel()\n",
        "    return {'total': total, 'trainable': trainable, 'lora': lora, 'ratio': trainable/total if total else 0}\n",
        "\n",
        "print('Layers loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 6: TRM Model (Aligned with TinyRecursiveModels-Trelis)\n",
        "# ============================================================================\n",
        "\n",
        "# NOTE:\n",
        "# - This model matches Trelis TRM semantics for puzzle embeddings (CastedSparseEmbedding) and carry-based ACT.\n",
        "# - We add a small switch `disable_act` to disable q-logits early halting during training.\n",
        "\n",
        "@dataclass\n",
        "class TRMInnerCarry:\n",
        "    z_H: torch.Tensor\n",
        "    z_L: torch.Tensor\n",
        "\n",
        "@dataclass\n",
        "class TRMCarry:\n",
        "    inner: TRMInnerCarry\n",
        "    steps: torch.Tensor\n",
        "    halted: torch.Tensor\n",
        "    data: Dict[str, torch.Tensor]\n",
        "\n",
        "\n",
        "class CastedSparseEmbedding(nn.Module):\n",
        "    def __init__(self, num_embeddings: int, embedding_dim: int, batch_size: int, init_std: float, cast_to: torch.dtype):\n",
        "        super().__init__()\n",
        "        self.cast_to = cast_to\n",
        "\n",
        "        self.weights = nn.Buffer(trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std), persistent=True)\n",
        "        self.local_weights = nn.Buffer(torch.zeros(batch_size, embedding_dim, requires_grad=True), persistent=False)\n",
        "        self.local_ids = nn.Buffer(torch.zeros(batch_size, dtype=torch.int32), persistent=False)\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        if not self.training:\n",
        "            return self.weights[inputs].to(self.cast_to)\n",
        "        with torch.no_grad():\n",
        "            self.local_weights.copy_(self.weights[inputs])\n",
        "            self.local_ids.copy_(inputs)\n",
        "        return self.local_weights.to(self.cast_to)\n",
        "\n",
        "\n",
        "class CastedSparseEmbeddingSignSGD(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr: float = 1e-3, weight_decay: float = 1e-2):\n",
        "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        for group in self.param_groups:\n",
        "            local_weights_grad = None\n",
        "            local_ids = None\n",
        "            weights = None\n",
        "            for p in group['params']:\n",
        "                if getattr(p, 'requires_grad', False):\n",
        "                    local_weights_grad = p.grad\n",
        "                elif p.ndim == 1:\n",
        "                    local_ids = p\n",
        "                elif p.ndim == 2:\n",
        "                    weights = p\n",
        "            if local_weights_grad is None or local_ids is None or weights is None:\n",
        "                continue\n",
        "\n",
        "            # Unique ids for this batch\n",
        "            grad_ids, inv = local_ids.unique(return_inverse=True)\n",
        "            grad = torch.zeros((grad_ids.shape[0], local_weights_grad.shape[1]), dtype=local_weights_grad.dtype, device=local_weights_grad.device)\n",
        "            grad.scatter_add_(0, inv.unsqueeze(-1).expand(-1, grad.shape[1]), local_weights_grad)\n",
        "\n",
        "            lr = float(group['lr'])\n",
        "            wd = float(group['weight_decay'])\n",
        "            p = weights[grad_ids]\n",
        "            p.mul_(1.0 - lr * wd).add_(torch.sign(grad), alpha=-lr)\n",
        "            weights[grad_ids] = p\n",
        "\n",
        "\n",
        "class TRMConfig(BaseModel):\n",
        "    batch_size: int\n",
        "    seq_len: int\n",
        "    vocab_size: int\n",
        "    num_puzzle_identifiers: int\n",
        "\n",
        "    H_cycles: int\n",
        "    L_cycles: int\n",
        "    H_layers: int\n",
        "    L_layers: int\n",
        "\n",
        "    hidden_size: int\n",
        "    expansion: float\n",
        "    num_heads: int\n",
        "    pos_encodings: str\n",
        "\n",
        "    rms_norm_eps: float = 1e-5\n",
        "    rope_theta: float = 10000.0\n",
        "\n",
        "    halt_max_steps: int\n",
        "    halt_exploration_prob: float\n",
        "    halt_max_steps_eval: Optional[int] = None\n",
        "\n",
        "    forward_dtype: str = 'bfloat16'\n",
        "\n",
        "    puzzle_emb_ndim: int = 0\n",
        "    puzzle_emb_len: int = 1\n",
        "\n",
        "    mlp_t: bool = False\n",
        "    no_ACT_continue: bool = True\n",
        "\n",
        "    puzzle_emb_dropout: float = 0.0\n",
        "    grid_token_dropout: float = 0.0\n",
        "\n",
        "    # Extra switch (not in Trelis): disable q-logits early halting during training\n",
        "    disable_act: bool = False\n",
        "\n",
        "\n",
        "class TRMBlock(nn.Module):\n",
        "    def __init__(self, cfg: TRMConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if cfg.mlp_t:\n",
        "            self.mlp_t = SwiGLU(cfg.seq_len + cfg.puzzle_emb_len, cfg.expansion)\n",
        "        else:\n",
        "            self.attn = Attention(cfg.hidden_size, cfg.hidden_size // cfg.num_heads, cfg.num_heads, cfg.num_heads, False)\n",
        "        self.mlp = SwiGLU(cfg.hidden_size, cfg.expansion)\n",
        "        self.eps = cfg.rms_norm_eps\n",
        "\n",
        "    def forward(self, cos_sin, x):\n",
        "        if self.cfg.mlp_t:\n",
        "            x = x.transpose(1, 2)\n",
        "            x = rms_norm(x + self.mlp_t(x), self.eps)\n",
        "            x = x.transpose(1, 2)\n",
        "        else:\n",
        "            x = rms_norm(x + self.attn(cos_sin, x), self.eps)\n",
        "        return rms_norm(x + self.mlp(x), self.eps)\n",
        "\n",
        "\n",
        "class TRMReasoning(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x, inj, **kw):\n",
        "        x = x + inj\n",
        "        for l in self.layers:\n",
        "            x = l(kw.get('cos_sin'), x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TRMInner(nn.Module):\n",
        "    def __init__(self, cfg: TRMConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.dtype = getattr(torch, cfg.forward_dtype)\n",
        "\n",
        "        self.embed_scale = math.sqrt(cfg.hidden_size)\n",
        "        embed_init_std = 1.0 / self.embed_scale\n",
        "\n",
        "        self.embed_tokens = CastedEmbedding(cfg.vocab_size, cfg.hidden_size, embed_init_std, self.dtype)\n",
        "        self.lm_head = CastedLinear(cfg.hidden_size, cfg.vocab_size, False)\n",
        "        self.q_head = CastedLinear(cfg.hidden_size, 2, True)\n",
        "\n",
        "        # puzzle embedding\n",
        "        self.puzzle_emb_len = (-(cfg.puzzle_emb_ndim // -cfg.hidden_size)) if (cfg.puzzle_emb_len == 0) else cfg.puzzle_emb_len\n",
        "        if cfg.puzzle_emb_ndim > 0:\n",
        "            self.puzzle_emb = CastedSparseEmbedding(cfg.num_puzzle_identifiers, cfg.puzzle_emb_ndim, batch_size=cfg.batch_size, init_std=0.0, cast_to=self.dtype)\n",
        "\n",
        "        if cfg.pos_encodings == 'rope':\n",
        "            self.rotary = RotaryEmbedding(cfg.hidden_size // cfg.num_heads, cfg.seq_len + self.puzzle_emb_len, cfg.rope_theta)\n",
        "        elif cfg.pos_encodings == 'learned':\n",
        "            self.pos_emb = CastedEmbedding(cfg.seq_len + self.puzzle_emb_len, cfg.hidden_size, embed_init_std, self.dtype)\n",
        "\n",
        "        self.L_level = TRMReasoning([TRMBlock(cfg) for _ in range(cfg.L_layers)])\n",
        "\n",
        "        self.H_init = nn.Buffer(trunc_normal_init_(torch.empty(cfg.hidden_size, dtype=self.dtype), std=1), persistent=True)\n",
        "        self.L_init = nn.Buffer(trunc_normal_init_(torch.empty(cfg.hidden_size, dtype=self.dtype), std=1), persistent=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.q_head.weight.zero_()\n",
        "            self.q_head.bias.fill_(-5)\n",
        "\n",
        "    def _input_embeddings(self, inputs: torch.Tensor, puzzle_identifiers: torch.Tensor):\n",
        "        emb = self.embed_tokens(inputs.to(torch.int32))\n",
        "\n",
        "        if self.cfg.puzzle_emb_ndim > 0:\n",
        "            pe = self.puzzle_emb(puzzle_identifiers)\n",
        "            pad_count = self.puzzle_emb_len * self.cfg.hidden_size - pe.shape[-1]\n",
        "            if pad_count > 0:\n",
        "                pe = F.pad(pe, (0, pad_count))\n",
        "            emb = torch.cat((pe.view(-1, self.puzzle_emb_len, self.cfg.hidden_size), emb), dim=-2)\n",
        "\n",
        "        if self.cfg.pos_encodings == 'learned':\n",
        "            emb = 0.707106781 * (emb + self.pos_emb.embedding_weight.to(self.dtype))\n",
        "\n",
        "        return self.embed_scale * emb\n",
        "\n",
        "    def empty_carry(self, batch_size: int):\n",
        "        return TRMInnerCarry(\n",
        "            z_H=torch.empty(batch_size, self.cfg.seq_len + self.puzzle_emb_len, self.cfg.hidden_size, dtype=self.dtype),\n",
        "            z_L=torch.empty(batch_size, self.cfg.seq_len + self.puzzle_emb_len, self.cfg.hidden_size, dtype=self.dtype),\n",
        "        )\n",
        "\n",
        "    def reset_carry(self, reset_flag: torch.Tensor, carry: TRMInnerCarry):\n",
        "        return TRMInnerCarry(\n",
        "            z_H=torch.where(reset_flag.view(-1, 1, 1), self.H_init, carry.z_H),\n",
        "            z_L=torch.where(reset_flag.view(-1, 1, 1), self.L_init, carry.z_L),\n",
        "        )\n",
        "\n",
        "    def forward(self, carry: TRMInnerCarry, batch: Dict[str, torch.Tensor]):\n",
        "        cs = self.rotary() if hasattr(self, 'rotary') else None\n",
        "\n",
        "        input_embeddings = self._input_embeddings(batch['inputs'], batch['puzzle_identifiers'])\n",
        "\n",
        "        z_H, z_L = carry.z_H, carry.z_L\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(self.cfg.H_cycles - 1):\n",
        "                for _ in range(self.cfg.L_cycles):\n",
        "                    z_L = self.L_level(z_L, z_H + input_embeddings, cos_sin=cs)\n",
        "                z_H = self.L_level(z_H, z_L, cos_sin=cs)\n",
        "\n",
        "        for _ in range(self.cfg.L_cycles):\n",
        "            z_L = self.L_level(z_L, z_H + input_embeddings, cos_sin=cs)\n",
        "        z_H = self.L_level(z_H, z_L, cos_sin=cs)\n",
        "\n",
        "        new_carry = TRMInnerCarry(z_H=z_H.detach(), z_L=z_L.detach())\n",
        "        logits = self.lm_head(z_H)[:, self.puzzle_emb_len:]\n",
        "        q_logits = self.q_head(z_H[:, 0]).to(torch.float32)\n",
        "\n",
        "        return new_carry, {'logits': logits, 'q_halt_logits': q_logits[:, 0], 'q_continue_logits': q_logits[:, 1]}\n",
        "\n",
        "\n",
        "class TinyRecursiveReasoningModel_ACTV1(nn.Module):\n",
        "    def __init__(self, cfg_dict: dict):\n",
        "        super().__init__()\n",
        "        self.config = TRMConfig(**cfg_dict)\n",
        "        self.inner = TRMInner(self.config)\n",
        "\n",
        "    def initial_carry(self, batch: Dict[str, torch.Tensor]):\n",
        "        B = batch['inputs'].shape[0]\n",
        "        return TRMCarry(\n",
        "            inner=self.inner.empty_carry(B),\n",
        "            steps=torch.zeros(B, dtype=torch.int32, device=batch['inputs'].device),\n",
        "            halted=torch.ones(B, dtype=torch.bool, device=batch['inputs'].device),\n",
        "            data={k: torch.empty_like(v) for k, v in batch.items()},\n",
        "        )\n",
        "\n",
        "    def forward(self, carry: TRMCarry, batch: Dict[str, torch.Tensor], **kw):\n",
        "        new_inner = self.inner.reset_carry(carry.halted, carry.inner)\n",
        "        new_steps = torch.where(carry.halted, torch.zeros_like(carry.steps), carry.steps)\n",
        "        new_data = {k: torch.where(carry.halted.view((-1,) + (1,) * (v.ndim - 1)), batch[k], v) for k, v in carry.data.items()}\n",
        "\n",
        "        new_inner, out = self.inner(new_inner, new_data)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            new_steps = new_steps + 1\n",
        "            halt_limit = self.config.halt_max_steps if (self.training or self.config.halt_max_steps_eval is None) else self.config.halt_max_steps_eval\n",
        "            is_last_step = new_steps >= halt_limit\n",
        "            halted = is_last_step\n",
        "\n",
        "            # Disable q-logits early halting if requested.\n",
        "            if (not self.config.disable_act) and self.training and (self.config.halt_max_steps > 1):\n",
        "                if self.config.no_ACT_continue:\n",
        "                    halted = halted | (out['q_halt_logits'] > 0)\n",
        "                else:\n",
        "                    halted = halted | (out['q_halt_logits'] > out['q_continue_logits'])\n",
        "\n",
        "                min_halt_steps = (torch.rand_like(out['q_halt_logits']) < self.config.halt_exploration_prob) * torch.randint_like(\n",
        "                    new_steps, low=2, high=self.config.halt_max_steps + 1\n",
        "                )\n",
        "                halted = halted & (new_steps >= min_halt_steps)\n",
        "\n",
        "        return TRMCarry(new_inner, new_steps, halted, new_data), out\n",
        "\n",
        "\n",
        "print('TRM Model loaded (aligned with Trelis puzzle embeddings + carry)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 7: Loss Head (Aligned with Trelis ACTLossHead)\n",
        "# ============================================================================\n",
        "\n",
        "def s(x, eps=1e-30):\n",
        "    return torch.where(x < 0, 1 / (1 - x + eps), x + 1)\n",
        "\n",
        "\n",
        "def log_stablemax(x, dim=-1):\n",
        "    sx = s(x)\n",
        "    return torch.log(sx / sx.sum(dim=dim, keepdim=True))\n",
        "\n",
        "\n",
        "def stablemax_ce(logits, labels, ignore_index=-100, valid_mask=None):\n",
        "    lp = log_stablemax(logits.double(), -1)\n",
        "    if valid_mask is None:\n",
        "        valid_mask = labels != ignore_index\n",
        "    tl = torch.where(valid_mask, labels, 0)\n",
        "    plp = torch.gather(lp, index=tl.long().unsqueeze(-1), dim=-1).squeeze(-1)\n",
        "    return -torch.where(valid_mask, plp, 0.0)\n",
        "\n",
        "\n",
        "class TRMLossHead(nn.Module):\n",
        "    \"\"\"Trelis ACTLossHead-equivalent, but bound to our local model wrapper.\"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, loss_type: str):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.loss_fn = stablemax_ce\n",
        "\n",
        "    def initial_carry(self, *args, **kwargs):\n",
        "        return self.model.initial_carry(*args, **kwargs)\n",
        "\n",
        "    def forward(self, return_keys: Sequence[str], **model_kwargs):\n",
        "        new_carry, outputs = self.model(**model_kwargs)\n",
        "        labels = new_carry.data['labels']\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs['preds'] = torch.argmax(outputs['logits'], dim=-1)\n",
        "\n",
        "            mask = labels != IGNORE_LABEL_ID\n",
        "            loss_counts = mask.sum(-1)\n",
        "            loss_divisor = loss_counts.clamp_min(1).unsqueeze(-1)\n",
        "\n",
        "            is_correct = mask & (outputs['preds'] == labels)\n",
        "            seq_is_correct = is_correct.sum(-1) == loss_counts\n",
        "\n",
        "            valid_metrics = new_carry.halted & (loss_counts > 0)\n",
        "            metrics = {\n",
        "                'count': valid_metrics.sum(),\n",
        "                'accuracy': torch.where(valid_metrics, (is_correct.float() / loss_divisor).sum(-1), 0.0).sum(),\n",
        "                'exact_accuracy': (valid_metrics & seq_is_correct).sum(),\n",
        "                'q_halt_accuracy': (valid_metrics & ((outputs['q_halt_logits'] >= 0) == seq_is_correct)).sum(),\n",
        "                'steps': torch.where(valid_metrics, new_carry.steps, 0).sum(),\n",
        "            }\n",
        "\n",
        "        lm_loss = (self.loss_fn(outputs['logits'], labels, ignore_index=IGNORE_LABEL_ID, valid_mask=mask) / loss_divisor).sum()\n",
        "        q_halt_loss = F.binary_cross_entropy_with_logits(outputs['q_halt_logits'], seq_is_correct.to(outputs['q_halt_logits'].dtype), reduction='sum')\n",
        "\n",
        "        metrics.update({'lm_loss': lm_loss.detach(), 'q_halt_loss': q_halt_loss.detach()})\n",
        "\n",
        "        q_continue_loss = 0\n",
        "        if 'target_q_continue' in outputs:\n",
        "            q_continue_loss = F.binary_cross_entropy_with_logits(outputs['q_continue_logits'], outputs['target_q_continue'], reduction='sum')\n",
        "            metrics['q_continue_loss'] = q_continue_loss.detach()\n",
        "\n",
        "        detached_outputs = {k: outputs[k].detach() for k in return_keys if k in outputs}\n",
        "\n",
        "        total_loss = lm_loss + 0.5 * (q_halt_loss + q_continue_loss)\n",
        "        return new_carry, total_loss, metrics, detached_outputs, new_carry.halted.all()\n",
        "\n",
        "\n",
        "print('Loss Head loaded (aligned with Trelis ACTLossHead)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 8: Dataset Classes (Aligned with TinyRecursiveModels-Trelis puzzle_dataset.py)\n",
        "# ============================================================================\n",
        "from torch.utils.data import get_worker_info\n",
        "\n",
        "\n",
        "def _sample_batch(rng, group_order, puzzle_indices, group_indices, start_index, global_batch_size):\n",
        "    batch = []\n",
        "    batch_puzzle_indices = []\n",
        "    current_size = 0\n",
        "\n",
        "    while (start_index < group_order.size) and (current_size < global_batch_size):\n",
        "        group_id = group_order[start_index]\n",
        "        puzzle_id = rng.integers(group_indices[group_id], group_indices[group_id + 1])\n",
        "        start_index += 1\n",
        "\n",
        "        puzzle_start = puzzle_indices[puzzle_id]\n",
        "        puzzle_size = int(puzzle_indices[puzzle_id + 1] - puzzle_start)\n",
        "        if puzzle_size <= 0:\n",
        "            continue\n",
        "\n",
        "        append_size = min(puzzle_size, global_batch_size - current_size)\n",
        "        batch_puzzle_indices.append(np.full(append_size, puzzle_id, dtype=np.int32))\n",
        "\n",
        "        if append_size == puzzle_size:\n",
        "            choices = rng.permutation(puzzle_size)\n",
        "        else:\n",
        "            choices = rng.choice(puzzle_size, append_size, replace=False)\n",
        "        batch.append(puzzle_start + choices)\n",
        "        current_size += append_size\n",
        "\n",
        "    if len(batch) == 0:\n",
        "        return start_index, np.empty((0,), dtype=np.int64), np.empty((0,), dtype=np.int32)\n",
        "\n",
        "    return start_index, np.concatenate(batch), np.concatenate(batch_puzzle_indices)\n",
        "\n",
        "\n",
        "class PuzzleDatasetMetadata(pydantic.BaseModel):\n",
        "    pad_id: int\n",
        "    ignore_label_id: Optional[int]\n",
        "    blank_identifier_id: int\n",
        "    vocab_size: int\n",
        "    seq_len: int\n",
        "    num_puzzle_identifiers: int\n",
        "    total_groups: int\n",
        "    mean_puzzle_examples: float\n",
        "    total_puzzles: int\n",
        "    sets: List[str]\n",
        "\n",
        "\n",
        "class PuzzleDatasetConfig(pydantic.BaseModel):\n",
        "    seed: int\n",
        "    dataset_paths: List[str]\n",
        "    global_batch_size: int\n",
        "    test_set_mode: bool\n",
        "    epochs_per_iter: int\n",
        "    rank: int = 0\n",
        "    num_replicas: int = 1\n",
        "\n",
        "\n",
        "class PuzzleDataset(IterableDataset):\n",
        "    def __init__(self, cfg: PuzzleDatasetConfig, split: str = 'train'):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.split = split\n",
        "\n",
        "        # Merge metadata across dataset_paths\n",
        "        prev = None\n",
        "        mean_puzzle_examples = 0.0\n",
        "        total_puzzles = 0\n",
        "        total_groups = 0\n",
        "        num_identifiers = 0\n",
        "\n",
        "        for dataset_path in cfg.dataset_paths:\n",
        "            with open(os.path.join(dataset_path, split, 'dataset.json')) as f:\n",
        "                md = PuzzleDatasetMetadata(**json.load(f))\n",
        "\n",
        "            if prev is None:\n",
        "                prev = md\n",
        "            else:\n",
        "                assert prev.seq_len == md.seq_len\n",
        "                assert prev.vocab_size == md.vocab_size\n",
        "                assert prev.pad_id == md.pad_id\n",
        "                assert prev.ignore_label_id == md.ignore_label_id\n",
        "                assert prev.blank_identifier_id == md.blank_identifier_id\n",
        "                assert prev.sets == md.sets\n",
        "\n",
        "            mean_puzzle_examples += float(md.mean_puzzle_examples) * int(md.total_puzzles)\n",
        "            total_puzzles += int(md.total_puzzles)\n",
        "            total_groups += int(md.total_groups)\n",
        "            num_identifiers += int(md.num_puzzle_identifiers)\n",
        "\n",
        "        assert prev is not None\n",
        "        mean_puzzle_examples = mean_puzzle_examples / max(1, total_puzzles)\n",
        "\n",
        "        self.metadata = PuzzleDatasetMetadata(\n",
        "            pad_id=prev.pad_id,\n",
        "            ignore_label_id=prev.ignore_label_id,\n",
        "            blank_identifier_id=prev.blank_identifier_id,\n",
        "            vocab_size=prev.vocab_size,\n",
        "            seq_len=prev.seq_len,\n",
        "            num_puzzle_identifiers=num_identifiers,\n",
        "            total_groups=total_groups,\n",
        "            mean_puzzle_examples=mean_puzzle_examples,\n",
        "            total_puzzles=total_puzzles,\n",
        "            sets=prev.sets,\n",
        "        )\n",
        "\n",
        "        assert cfg.global_batch_size % cfg.num_replicas == 0\n",
        "        self.local_bs = cfg.global_batch_size // cfg.num_replicas\n",
        "\n",
        "        self._data = None\n",
        "        self._iters = 0\n",
        "\n",
        "    def _lazy_load_dataset(self):\n",
        "        if self._data is not None:\n",
        "            return\n",
        "\n",
        "        mmap_modes = {\n",
        "            'inputs': 'r',\n",
        "            'labels': 'r',\n",
        "            'puzzle_identifiers': None,\n",
        "            'puzzle_indices': None,\n",
        "            'group_indices': None,\n",
        "        }\n",
        "\n",
        "        self._data = {}\n",
        "        for set_name in self.metadata.sets:\n",
        "            for i, dataset_path in enumerate(self.cfg.dataset_paths):\n",
        "                set_name_ = set_name + (str(i) if i > 0 else '')\n",
        "                dataset = {\n",
        "                    k: np.load(os.path.join(dataset_path, self.split, f'{set_name}__{k}.npy'), mmap_mode=mmap_modes[k])\n",
        "                    for k in mmap_modes\n",
        "                }\n",
        "\n",
        "                group_indices = dataset['group_indices']\n",
        "                num_groups = group_indices.size - 1\n",
        "                puzzle_group_ids = np.empty(int(group_indices[-1]), dtype=np.int32)\n",
        "                for gid in range(num_groups):\n",
        "                    start = int(group_indices[gid])\n",
        "                    end = int(group_indices[gid + 1])\n",
        "                    puzzle_group_ids[start:end] = gid\n",
        "                dataset['puzzle_group_ids'] = puzzle_group_ids\n",
        "\n",
        "                self._data[set_name_] = dataset\n",
        "\n",
        "    def _collate_batch(self, batch: Dict[str, np.ndarray]):\n",
        "        batch = {k: v.astype(np.int32) for k, v in batch.items()}\n",
        "\n",
        "        if self.metadata.ignore_label_id is not None:\n",
        "            batch['labels'][batch['labels'] == self.metadata.ignore_label_id] = IGNORE_LABEL_ID\n",
        "\n",
        "        if batch['puzzle_identifiers'].size < self.local_bs:\n",
        "            pad = self.local_bs - batch['puzzle_identifiers'].size\n",
        "            pad_values = {\n",
        "                'inputs': self.metadata.pad_id,\n",
        "                'labels': IGNORE_LABEL_ID,\n",
        "                'puzzle_identifiers': self.metadata.blank_identifier_id,\n",
        "                'task_identifiers': -1,\n",
        "            }\n",
        "            batch = {\n",
        "                k: np.pad(v, ((0, pad),) + ((0, 0),) * (v.ndim - 1), constant_values=pad_values[k])\n",
        "                for k, v in batch.items()\n",
        "            }\n",
        "\n",
        "        return {k: torch.from_numpy(v) for k, v in batch.items()}\n",
        "\n",
        "    def _iter_test(self):\n",
        "        for set_name, dataset in self._data.items():\n",
        "            total_examples = len(dataset['inputs'])\n",
        "            start_index = 0\n",
        "            while start_index < total_examples:\n",
        "                end_index = min(total_examples, start_index + self.cfg.global_batch_size)\n",
        "\n",
        "                local_start = start_index + self.cfg.rank * self.local_bs\n",
        "                local_end = min(start_index + (self.cfg.rank + 1) * self.local_bs, end_index)\n",
        "\n",
        "                puzzle_indices = []\n",
        "                puzzle_index = np.searchsorted(dataset['puzzle_indices'], local_start, side='right') - 1\n",
        "                for i in range(local_start, local_end):\n",
        "                    while puzzle_index + 1 < len(dataset['puzzle_indices']) and i >= dataset['puzzle_indices'][puzzle_index + 1]:\n",
        "                        puzzle_index += 1\n",
        "                    puzzle_indices.append(puzzle_index)\n",
        "\n",
        "                batch = self._collate_batch({\n",
        "                    'inputs': dataset['inputs'][local_start:local_end],\n",
        "                    'labels': dataset['labels'][local_start:local_end],\n",
        "                    'puzzle_identifiers': dataset['puzzle_identifiers'][puzzle_indices],\n",
        "                    'task_identifiers': dataset['puzzle_group_ids'][puzzle_indices],\n",
        "                })\n",
        "\n",
        "                yield set_name, batch, end_index - start_index\n",
        "                start_index += self.cfg.global_batch_size\n",
        "\n",
        "    def _iter_train(self):\n",
        "        self._iters += 1\n",
        "        epoch_seed = self.cfg.seed + self._iters\n",
        "\n",
        "        rng = np.random.Generator(np.random.Philox(seed=epoch_seed))\n",
        "\n",
        "        for set_name, dataset in self._data.items():\n",
        "            group_order = np.concatenate([\n",
        "                rng.permutation(dataset['group_indices'].size - 1)\n",
        "                for _ in range(self.cfg.epochs_per_iter)\n",
        "            ])\n",
        "            start_index = 0\n",
        "\n",
        "            while start_index < group_order.size:\n",
        "                start_index, batch_indices, batch_puzzle_indices = _sample_batch(\n",
        "                    rng,\n",
        "                    group_order=group_order,\n",
        "                    puzzle_indices=dataset['puzzle_indices'],\n",
        "                    group_indices=dataset['group_indices'],\n",
        "                    start_index=start_index,\n",
        "                    global_batch_size=self.cfg.global_batch_size,\n",
        "                )\n",
        "\n",
        "                gbs = batch_puzzle_indices.size\n",
        "                if gbs < self.cfg.global_batch_size:\n",
        "                    break\n",
        "\n",
        "                batch_indices = batch_indices[self.cfg.rank * self.local_bs:(self.cfg.rank + 1) * self.local_bs]\n",
        "                batch_puzzle_indices = batch_puzzle_indices[self.cfg.rank * self.local_bs:(self.cfg.rank + 1) * self.local_bs]\n",
        "\n",
        "                batch = self._collate_batch({\n",
        "                    'inputs': dataset['inputs'][batch_indices],\n",
        "                    'labels': dataset['labels'][batch_indices],\n",
        "                    'puzzle_identifiers': dataset['puzzle_identifiers'][batch_puzzle_indices],\n",
        "                    'task_identifiers': dataset['puzzle_group_ids'][batch_puzzle_indices],\n",
        "                })\n",
        "\n",
        "                yield set_name, batch, gbs\n",
        "\n",
        "    def __iter__(self):\n",
        "        worker_info = get_worker_info()\n",
        "        assert worker_info is None or worker_info.num_workers == 1\n",
        "\n",
        "        self._lazy_load_dataset()\n",
        "\n",
        "        if self.cfg.test_set_mode:\n",
        "            yield from self._iter_test()\n",
        "        else:\n",
        "            yield from self._iter_train()\n",
        "\n",
        "\n",
        "print('Dataset loaded (aligned with Trelis)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 9: Training Framework (Single GPU + AdamW + Sparse Embedding SignSGD)\n",
        "# ============================================================================\n",
        "class LossConfig(pydantic.BaseModel):\n",
        "    model_config = pydantic.ConfigDict(extra='allow')\n",
        "    name: str\n",
        "\n",
        "\n",
        "class ArchConfig(pydantic.BaseModel):\n",
        "    model_config = pydantic.ConfigDict(extra='allow')\n",
        "    name: str\n",
        "    loss: LossConfig\n",
        "\n",
        "\n",
        "class PretrainConfig(pydantic.BaseModel):\n",
        "    \"\"\"Minimal pretrain config aligned with Trelis training semantics, but step-based.\"\"\"\n",
        "\n",
        "    arch: ArchConfig\n",
        "    data_paths: List[str]\n",
        "    data_paths_test: List[str] = []\n",
        "\n",
        "    global_batch_size: int\n",
        "\n",
        "    # Step-based control\n",
        "    max_steps: int\n",
        "    eval_every_steps: int\n",
        "    min_eval_interval: int = 0\n",
        "\n",
        "    # Optimizer hyperparams (trunk)\n",
        "    lr: float\n",
        "    lr_min_ratio: float\n",
        "    lr_warmup_steps: int\n",
        "    weight_decay: float\n",
        "    beta1: float\n",
        "    beta2: float\n",
        "\n",
        "    # Puzzle embedding training (aligned to Trelis defaults)\n",
        "    puzzle_emb_lr: float = 1e-2\n",
        "    puzzle_emb_weight_decay: float = 0.1\n",
        "\n",
        "    # Names / logging\n",
        "    project_name: Optional[str] = None\n",
        "    run_name: Optional[str] = None\n",
        "    checkpoint_path: Optional[str] = None\n",
        "    checkpoint_every_eval: bool = False\n",
        "\n",
        "    ema: bool = False\n",
        "    ema_rate: float = 0.999\n",
        "\n",
        "    seed: int = 0\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainState:\n",
        "    model: nn.Module\n",
        "    optimizers: List[Any]\n",
        "    optimizer_lrs: List[float]\n",
        "    optimizer_tags: List[str]\n",
        "    carry: Any\n",
        "    step: int\n",
        "    total_steps: int\n",
        "\n",
        "\n",
        "class EMAHelper:\n",
        "    def __init__(self, mu=0.999):\n",
        "        self.mu = mu\n",
        "        self.shadow = {}\n",
        "\n",
        "    def register(self, m):\n",
        "        for n, p in m.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n] = p.data.clone()\n",
        "\n",
        "    def update(self, m):\n",
        "        for n, p in m.named_parameters():\n",
        "            if p.requires_grad and n in self.shadow:\n",
        "                self.shadow[n] = self.mu * self.shadow[n] + (1 - self.mu) * p.data\n",
        "\n",
        "    def ema_copy(self, m):\n",
        "        mc = copy.deepcopy(m)\n",
        "        for n, p in mc.named_parameters():\n",
        "            if n in self.shadow:\n",
        "                p.data.copy_(self.shadow[n])\n",
        "        return mc\n",
        "\n",
        "\n",
        "def cosine_lr(step, base_lr, warmup, total, min_ratio=0.0):\n",
        "    if step < warmup:\n",
        "        return base_lr * step / max(1, warmup)\n",
        "    prog = (step - warmup) / max(1, total - warmup)\n",
        "    return base_lr * (min_ratio + (1 - min_ratio) * 0.5 * (1 + math.cos(math.pi * prog)))\n",
        "\n",
        "\n",
        "def create_dataloader(cfg: PretrainConfig, split: str, epochs_per_iter: int):\n",
        "    ds = PuzzleDataset(\n",
        "        PuzzleDatasetConfig(\n",
        "            seed=cfg.seed,\n",
        "            dataset_paths=cfg.data_paths_test if split == 'test' and cfg.data_paths_test else cfg.data_paths,\n",
        "            global_batch_size=cfg.global_batch_size,\n",
        "            test_set_mode=(split == 'test'),\n",
        "            epochs_per_iter=epochs_per_iter,\n",
        "            rank=0,\n",
        "            num_replicas=1,\n",
        "        ),\n",
        "        split,\n",
        "    )\n",
        "    loader = DataLoader(ds, batch_size=None, num_workers=1, prefetch_factor=8, pin_memory=True, persistent_workers=True)\n",
        "    return loader, ds.metadata\n",
        "\n",
        "\n",
        "def _get_sparse_puzzle_emb_buffers(loss_head_model: nn.Module):\n",
        "    # loss_head_model is TRMLossHead\n",
        "    core = getattr(loss_head_model, 'model', None)\n",
        "    inner = getattr(core, 'inner', None) if core is not None else None\n",
        "    puzzle_emb = getattr(inner, 'puzzle_emb', None) if inner is not None else None\n",
        "    if puzzle_emb is None:\n",
        "        return None\n",
        "    return list(puzzle_emb.buffers())\n",
        "\n",
        "\n",
        "def create_model(cfg: PretrainConfig, meta: PuzzleDatasetMetadata):\n",
        "    model_cfg = {\n",
        "        **cfg.arch.__pydantic_extra__,\n",
        "        'batch_size': cfg.global_batch_size,\n",
        "        'vocab_size': meta.vocab_size,\n",
        "        'seq_len': meta.seq_len,\n",
        "        'num_puzzle_identifiers': meta.num_puzzle_identifiers,\n",
        "        'causal': False,\n",
        "    }\n",
        "\n",
        "    with torch.device('cuda'):\n",
        "        m = TinyRecursiveReasoningModel_ACTV1(model_cfg)\n",
        "        m = TRMLossHead(m, cfg.arch.loss.__pydantic_extra__.get('loss_type', 'stablemax_cross_entropy'))\n",
        "        stats = count_parameters(m)\n",
        "        print(f'Params: {stats[\"total\"]:,} total, {stats[\"trainable\"]:,} trainable ({stats[\"ratio\"]:.2%})')\n",
        "        if 'DISABLE_COMPILE' not in os.environ:\n",
        "            m = torch.compile(m)\n",
        "\n",
        "    optimizers: List[Any] = []\n",
        "    optimizer_lrs: List[float] = []\n",
        "    optimizer_tags: List[str] = []\n",
        "\n",
        "    # Puzzle embedding optimizer (SignSGD) if present\n",
        "    sparse_buffers = _get_sparse_puzzle_emb_buffers(m)\n",
        "    if sparse_buffers is not None:\n",
        "        optimizers.append(CastedSparseEmbeddingSignSGD(sparse_buffers, lr=cfg.puzzle_emb_lr, weight_decay=cfg.puzzle_emb_weight_decay))\n",
        "        optimizer_lrs.append(cfg.puzzle_emb_lr)\n",
        "        optimizer_tags.append('embedding')\n",
        "\n",
        "    # Trunk optimizer (AdamW on trainable parameters)\n",
        "    optimizers.append(\n",
        "        torch.optim.AdamW(\n",
        "            [p for p in m.parameters() if p.requires_grad],\n",
        "            lr=cfg.lr,\n",
        "            weight_decay=cfg.weight_decay,\n",
        "            betas=(cfg.beta1, cfg.beta2),\n",
        "        )\n",
        "    )\n",
        "    optimizer_lrs.append(cfg.lr)\n",
        "    optimizer_tags.append('trunk')\n",
        "\n",
        "    return m, optimizers, optimizer_lrs, optimizer_tags\n",
        "\n",
        "\n",
        "def init_train_state(cfg: PretrainConfig, meta: PuzzleDatasetMetadata):\n",
        "    model, opts, lrs, tags = create_model(cfg, meta)\n",
        "    return TrainState(model=model, optimizers=opts, optimizer_lrs=lrs, optimizer_tags=tags, carry=None, step=0, total_steps=cfg.max_steps)\n",
        "\n",
        "\n",
        "def train_batch(cfg: PretrainConfig, ts: TrainState, batch: Dict[str, torch.Tensor], gbs: int):\n",
        "    step_start = time.time()\n",
        "    ts.step += 1\n",
        "    if ts.step > ts.total_steps:\n",
        "        return None\n",
        "\n",
        "    batch = {k: v.cuda() for k, v in batch.items()}\n",
        "\n",
        "    if ts.carry is None:\n",
        "        with torch.device('cuda'):\n",
        "            ts.carry = ts.model.initial_carry(batch)\n",
        "\n",
        "    ts.carry, loss, metrics, _, _ = ts.model(carry=ts.carry, batch=batch, return_keys=[])\n",
        "    (loss / gbs).backward()\n",
        "\n",
        "    # Step optimizers with their own LR schedules\n",
        "    lr_logged = None\n",
        "    for opt, base_lr, tag in zip(ts.optimizers, ts.optimizer_lrs, ts.optimizer_tags):\n",
        "        lr_now = cosine_lr(ts.step, base_lr, cfg.lr_warmup_steps, ts.total_steps, cfg.lr_min_ratio if tag == 'trunk' else 0.0)\n",
        "        for pg in opt.param_groups:\n",
        "            pg['lr'] = lr_now\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        if tag == 'trunk':\n",
        "            lr_logged = lr_now\n",
        "\n",
        "    step_time = time.time() - step_start\n",
        "\n",
        "    if metrics:\n",
        "        keys = sorted(metrics.keys())\n",
        "        vals = torch.stack([metrics[k] for k in keys]).cpu().numpy()\n",
        "        rm = {k: vals[i] for i, k in enumerate(keys)}\n",
        "        cnt = max(rm.get('count', 1), 1)\n",
        "\n",
        "        train_metrics = {f'train/{k}': v / (gbs if k.endswith('loss') else cnt) for k, v in rm.items()}\n",
        "        if lr_logged is not None:\n",
        "            train_metrics['train/lr'] = lr_logged\n",
        "        train_metrics['train/samples_per_sec'] = gbs / step_time if step_time > 0 else 0\n",
        "        return train_metrics\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def evaluate(cfg: PretrainConfig, ts: TrainState, loader: DataLoader, max_batches: Optional[int] = None):\n",
        "    metrics = None\n",
        "    batch_count = 0\n",
        "    with torch.inference_mode():\n",
        "        for i, (sn, batch, gbs) in enumerate(loader):\n",
        "            if max_batches is not None and i >= max_batches:\n",
        "                break\n",
        "            batch = {k: v.cuda() for k, v in batch.items()}\n",
        "            with torch.device('cuda'):\n",
        "                carry = ts.model.initial_carry(batch)\n",
        "\n",
        "            while True:\n",
        "                carry, _, m, _, done = ts.model(carry=carry, batch=batch, return_keys=[])\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            if metrics is None:\n",
        "                metrics = {k: 0.0 for k in m}\n",
        "            for k in m:\n",
        "                metrics[k] += m[k].item() if torch.is_tensor(m[k]) else m[k]\n",
        "            batch_count += 1\n",
        "\n",
        "    if metrics:\n",
        "        cnt = max(metrics.get('count', 1), 1)\n",
        "        result = {f'eval/{k}': v / cnt for k, v in metrics.items() if k != 'count'}\n",
        "        result['eval/batches_evaluated'] = batch_count\n",
        "        return result\n",
        "\n",
        "    return {}\n",
        "\n",
        "\n",
        "print('Training framework loaded (step-based, aligned with Trelis carry + sparse puzzle emb)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 10: Architecture Configurations (H/L cycles)\n",
        "# ============================================================================\n",
        "# We compare different architectures by varying (H_cycles, L_cycles).\n",
        "# `HALT_MAX_STEPS` (Cell 1) is kept constant and ACT early stopping is disabled.\n",
        "\n",
        "H_CYCLES_LIST = [2, 3, 4]\n",
        "L_CYCLES_LIST = [2, 4, 6]\n",
        "\n",
        "ARCH_CONFIGS = {\n",
        "    f'H{H}-L{L}': {\n",
        "        'H_cycles': H,\n",
        "        'L_cycles': L,\n",
        "        'desc': f'Architecture: H_cycles={H}, L_cycles={L}',\n",
        "    }\n",
        "    for H in H_CYCLES_LIST\n",
        "    for L in L_CYCLES_LIST\n",
        "}\n",
        "\n",
        "# Convenience alias for the standard Trelis baseline\n",
        "if 'H3-L4' not in ARCH_CONFIGS:\n",
        "    ARCH_CONFIGS['H3-L4'] = {'H_cycles': 3, 'L_cycles': 4, 'desc': 'Trelis baseline: H=3, L=4'}\n",
        "\n",
        "print('ARCH configs:', sorted(ARCH_CONFIGS.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 11: Build Sudoku Dataset (Aligned with TinyRecursiveModels-Trelis)\n",
        "# ============================================================================\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "\n",
        "DATASET_DIR = './data/sudoku_arch'\n",
        "\n",
        "\n",
        "def shuffle_sudoku(board: np.ndarray, solution: np.ndarray):\n",
        "    digit_map = np.pad(np.random.permutation(np.arange(1, 10)), (1, 0))\n",
        "\n",
        "    transpose_flag = np.random.rand() < 0.5\n",
        "\n",
        "    bands = np.random.permutation(3)\n",
        "    row_perm = np.concatenate([b * 3 + np.random.permutation(3) for b in bands])\n",
        "\n",
        "    stacks = np.random.permutation(3)\n",
        "    col_perm = np.concatenate([s * 3 + np.random.permutation(3) for s in stacks])\n",
        "\n",
        "    mapping = np.array([row_perm[i // 9] * 9 + col_perm[i % 9] for i in range(81)])\n",
        "\n",
        "    def apply_transformation(x: np.ndarray) -> np.ndarray:\n",
        "        if transpose_flag:\n",
        "            x = x.T\n",
        "        new_board = x.flatten()[mapping].reshape(9, 9).copy()\n",
        "        return digit_map[new_board]\n",
        "\n",
        "    return apply_transformation(board), apply_transformation(solution)\n",
        "\n",
        "\n",
        "def build_sudoku_dataset():\n",
        "    train_md_path = os.path.join(DATASET_DIR, 'train', 'dataset.json')\n",
        "\n",
        "    if os.path.exists(train_md_path) and not FORCE_REBUILD:\n",
        "        try:\n",
        "            with open(train_md_path) as f:\n",
        "                md = json.load(f)\n",
        "            expected_mean = float(1 + NUM_AUGMENT)\n",
        "            if float(md.get('mean_puzzle_examples', 0.0)) >= max(1.0, expected_mean - 0.5) or NUM_AUGMENT == 0:\n",
        "                print('Dataset exists, skipping build')\n",
        "                return\n",
        "            else:\n",
        "                print('Dataset exists but has mean_puzzle_examples too small; rebuilding')\n",
        "        except Exception as e:\n",
        "            print(f'Dataset exists but could not read metadata ({e}); rebuilding')\n",
        "\n",
        "    if os.path.exists(DATASET_DIR):\n",
        "        shutil.rmtree(DATASET_DIR)\n",
        "\n",
        "    if HF_TOKEN:\n",
        "        os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "        try:\n",
        "            login(token=HF_TOKEN, add_to_git_credential=False)\n",
        "            print('âœ… Successfully authenticated with Hugging Face Hub')\n",
        "        except Exception as e:\n",
        "            print(f'âš ï¸ Warning: Could not login to Hugging Face Hub: {e}')\n",
        "    else:\n",
        "        print('â„¹ï¸ HF_TOKEN not set; will try downloading dataset without authentication')\n",
        "\n",
        "    print('Building Sudoku dataset...')\n",
        "\n",
        "    ds = load_dataset('sapientinc/sudoku-extreme', token=HF_TOKEN) if HF_TOKEN else load_dataset('sapientinc/sudoku-extreme')\n",
        "\n",
        "    sample = ds['train'][0]\n",
        "    puzzle_key = next((k for k in sample.keys() if k in ['question', 'puzzle', 'quiz', 'input']), None)\n",
        "    solution_key = next((k for k in sample.keys() if k in ['answer', 'solution', 'output', 'target']), None)\n",
        "    if puzzle_key is None or solution_key is None:\n",
        "        raise ValueError(f'Cannot determine puzzle/solution columns from keys: {list(sample.keys())}')\n",
        "\n",
        "    def convert(split: str):\n",
        "        data = ds[split]\n",
        "        if split == 'train':\n",
        "            data = data.select(range(min(TRAIN_SUBSAMPLE, len(data))))\n",
        "        elif split == 'test':\n",
        "            original_size = len(data)\n",
        "            if original_size > TEST_SUBSAMPLE:\n",
        "                import random\n",
        "                random.seed(TEST_SEED)\n",
        "                np.random.seed(TEST_SEED)\n",
        "                indices = list(range(original_size))\n",
        "                random.shuffle(indices)\n",
        "                selected_indices = sorted(indices[:TEST_SUBSAMPLE])\n",
        "                data = data.select(selected_indices)\n",
        "                print(f'Test set: Using {len(data):,} samples (sampled from {original_size:,}, seed={TEST_SEED})')\n",
        "            else:\n",
        "                print(f'Test set: Using all {len(data):,} samples')\n",
        "\n",
        "        inputs = [np.frombuffer(str(r[puzzle_key]).replace('.', '0').encode(), dtype=np.uint8).reshape(9, 9) - ord('0') for r in data]\n",
        "        labels = [np.frombuffer(str(r[solution_key]).encode(), dtype=np.uint8).reshape(9, 9) - ord('0') for r in data]\n",
        "\n",
        "        num_augments = NUM_AUGMENT if split == 'train' else 0\n",
        "\n",
        "        results = {k: [] for k in ['inputs', 'labels', 'puzzle_identifiers', 'puzzle_indices', 'group_indices']}\n",
        "        puzzle_id = 0\n",
        "        example_id = 0\n",
        "\n",
        "        results['puzzle_indices'].append(0)\n",
        "        results['group_indices'].append(0)\n",
        "\n",
        "        for orig_inp, orig_out in zip(inputs, labels):\n",
        "            for aug_idx in range(1 + num_augments):\n",
        "                if aug_idx == 0:\n",
        "                    inp, out = orig_inp, orig_out\n",
        "                else:\n",
        "                    inp, out = shuffle_sudoku(orig_inp, orig_out)\n",
        "\n",
        "                results['inputs'].append(inp)\n",
        "                results['labels'].append(out)\n",
        "                example_id += 1\n",
        "\n",
        "            puzzle_id += 1\n",
        "            results['puzzle_indices'].append(example_id)\n",
        "            results['puzzle_identifiers'].append(0)\n",
        "            results['group_indices'].append(puzzle_id)\n",
        "\n",
        "        def _seq_to_numpy(seq):\n",
        "            arr = np.concatenate(seq).reshape(len(seq), -1)\n",
        "            assert np.all((arr >= 0) & (arr <= 9))\n",
        "            return (arr + 1).astype(np.int32)\n",
        "\n",
        "        results = {\n",
        "            'inputs': _seq_to_numpy(results['inputs']),\n",
        "            'labels': _seq_to_numpy(results['labels']),\n",
        "            'group_indices': np.array(results['group_indices'], dtype=np.int32),\n",
        "            'puzzle_indices': np.array(results['puzzle_indices'], dtype=np.int32),\n",
        "            'puzzle_identifiers': np.array(results['puzzle_identifiers'], dtype=np.int32),\n",
        "        }\n",
        "\n",
        "        metadata = PuzzleDatasetMetadata(\n",
        "            seq_len=81,\n",
        "            vocab_size=11,\n",
        "            pad_id=0,\n",
        "            ignore_label_id=0,\n",
        "            blank_identifier_id=0,\n",
        "            num_puzzle_identifiers=1,\n",
        "            total_groups=len(results['group_indices']) - 1,\n",
        "            mean_puzzle_examples=float(1 + num_augments),\n",
        "            total_puzzles=len(results['puzzle_indices']) - 1,\n",
        "            sets=['all'],\n",
        "        )\n",
        "\n",
        "        save_dir = os.path.join(DATASET_DIR, split)\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        with open(os.path.join(save_dir, 'dataset.json'), 'w') as f:\n",
        "            json.dump(metadata.model_dump(), f)\n",
        "\n",
        "        for k, v in results.items():\n",
        "            np.save(os.path.join(save_dir, f'all__{k}.npy'), v)\n",
        "\n",
        "        print(f'{split}: inputs={results[\"inputs\"].shape}, groups={metadata.total_groups}, puzzles={results[\"puzzle_indices\"].size - 1}')\n",
        "\n",
        "    convert('train')\n",
        "    convert('test')\n",
        "\n",
        "    print('Dataset built!')\n",
        "\n",
        "\n",
        "build_sudoku_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 12: Launch Experiment (H/L ablation, compute-normalized)\n",
        "# ============================================================================\n",
        "import time\n",
        "\n",
        "\n",
        "def _arch_compute_stats(H_cycles: int, L_cycles: int, L_layers: int, halt_max_steps: int):\n",
        "    blocks_per_step = H_cycles * (L_cycles + 1) * L_layers\n",
        "    blocks_per_puzzle = halt_max_steps * blocks_per_step\n",
        "    return blocks_per_step, blocks_per_puzzle\n",
        "\n",
        "\n",
        "def launch_experiment(config_name: str):\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    arch_cfg = ARCH_CONFIGS[config_name]\n",
        "    H_cycles = arch_cfg['H_cycles']\n",
        "    L_cycles = arch_cfg['L_cycles']\n",
        "\n",
        "    print('=' * 70)\n",
        "    print(f'Experiment: {config_name} - {arch_cfg.get(\"desc\", \"\")}'.strip())\n",
        "    print('=' * 70)\n",
        "\n",
        "    exp_start_time = time.time()\n",
        "\n",
        "    L_layers = 2\n",
        "    blocks_per_step, blocks_per_puzzle = _arch_compute_stats(H_cycles, L_cycles, L_layers, HALT_MAX_STEPS)\n",
        "\n",
        "    base_blocks_per_step, _ = _arch_compute_stats(3, 4, L_layers, HALT_MAX_STEPS)\n",
        "    total_blocks_budget = int(MAX_TRAIN_STEPS * base_blocks_per_step)\n",
        "    max_steps = max(1, int(round(total_blocks_budget / max(1, blocks_per_step))))\n",
        "    eval_every_steps = max(1, max_steps // 5)\n",
        "\n",
        "    cfg_dict = {\n",
        "        'arch': {\n",
        "            'name': 'TRM',\n",
        "            'loss': {'name': 'TRMLossHead', 'loss_type': 'stablemax_cross_entropy'},\n",
        "            'halt_exploration_prob': 0.1,\n",
        "            'halt_max_steps': HALT_MAX_STEPS,\n",
        "            'halt_max_steps_eval': None,\n",
        "            'disable_act': True,\n",
        "            'H_cycles': H_cycles,\n",
        "            'L_cycles': L_cycles,\n",
        "            'H_layers': 0,\n",
        "            'L_layers': L_layers,\n",
        "            'hidden_size': 512,\n",
        "            'num_heads': 8,\n",
        "            'expansion': 4,\n",
        "            'pos_encodings': 'rope',\n",
        "            'forward_dtype': 'bfloat16',\n",
        "            'puzzle_emb_ndim': 512,\n",
        "            'puzzle_emb_len': 1,\n",
        "            'mlp_t': False,\n",
        "            'no_ACT_continue': True,\n",
        "        },\n",
        "        'data_paths': [DATASET_DIR],\n",
        "        'data_paths_test': [],\n",
        "        'global_batch_size': BATCH_SIZE,\n",
        "        'max_steps': max_steps,\n",
        "        'eval_every_steps': eval_every_steps,\n",
        "        'min_eval_interval': MIN_EVAL_INTERVAL,\n",
        "        'lr': 1e-4,\n",
        "        'lr_min_ratio': 1.0,\n",
        "        'lr_warmup_steps': 2000,\n",
        "        'beta1': 0.9,\n",
        "        'beta2': 0.95,\n",
        "        'weight_decay': 0.1,\n",
        "        'puzzle_emb_lr': 1e-2,\n",
        "        'puzzle_emb_weight_decay': 0.1,\n",
        "        'ema': True,\n",
        "        'ema_rate': 0.999,\n",
        "        'seed': 0,\n",
        "        'project_name': 'TRM-A100-LH',\n",
        "        'run_name': f'sudoku-{config_name}',\n",
        "        'checkpoint_path': f'./checkpoints/{config_name}',\n",
        "        'checkpoint_every_eval': False,\n",
        "    }\n",
        "\n",
        "    cfg = PretrainConfig(**cfg_dict)\n",
        "    torch.manual_seed(cfg.seed)\n",
        "\n",
        "    train_loader, train_meta = create_dataloader(cfg, 'train', epochs_per_iter=1)\n",
        "    eval_loader, _ = create_dataloader(cfg, 'test', epochs_per_iter=1)\n",
        "\n",
        "    ts = init_train_state(cfg, train_meta)\n",
        "\n",
        "    use_wandb = bool(WANDB_API_KEY)\n",
        "    if use_wandb:\n",
        "        wandb.init(project=cfg.project_name, name=cfg.run_name, config={**cfg_dict, 'config_name': config_name})\n",
        "\n",
        "    param_stats = count_parameters(ts.model)\n",
        "    peak_memory = 0.0\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log(\n",
        "            {\n",
        "                'model/total_params': param_stats['total'],\n",
        "                'model/trainable_params': param_stats['trainable'],\n",
        "                'model/trainable_ratio': param_stats['ratio'],\n",
        "                'arch/H_cycles': H_cycles,\n",
        "                'arch/L_cycles': L_cycles,\n",
        "                'arch/halt_max_steps': HALT_MAX_STEPS,\n",
        "                'arch/blocks_per_step': blocks_per_step,\n",
        "                'arch/blocks_per_puzzle': blocks_per_puzzle,\n",
        "                'compute/base_blocks_per_step': base_blocks_per_step,\n",
        "                'compute/total_blocks_budget': total_blocks_budget,\n",
        "                'compute/max_steps': max_steps,\n",
        "                'compute/blocks_budget_ratio_to_base': (max_steps * blocks_per_step) / max(1, total_blocks_budget),\n",
        "            },\n",
        "            step=0,\n",
        "        )\n",
        "\n",
        "    print(f\"ðŸ“Š Params: Total={param_stats['total']:,}, Trainable={param_stats['trainable']:,} ({param_stats['ratio']:.2%})\")\n",
        "    print(f\"ðŸ“Š Arch: H_cycles={H_cycles}, L_cycles={L_cycles}, L_layers={L_layers}, halt_max_steps={HALT_MAX_STEPS}\")\n",
        "    print(f\"ðŸ“Š Approx blocks: {blocks_per_step} /step, {blocks_per_puzzle} /puzzle\")\n",
        "    print(f\"ðŸ“Š Compute budget: total_blocks_budget={total_blocks_budget:,}, max_steps={cfg.max_steps}, eval_every_steps={cfg.eval_every_steps}\")\n",
        "\n",
        "    ema = EMAHelper(cfg.ema_rate) if cfg.ema else None\n",
        "    if ema:\n",
        "        ema.register(ts.model)\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    last_eval_metrics = {}\n",
        "\n",
        "    pbar = tqdm(total=cfg.max_steps)\n",
        "\n",
        "    while ts.step < cfg.max_steps:\n",
        "        try:\n",
        "            _, batch, gbs = next(train_iter)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(train_loader)\n",
        "            continue\n",
        "\n",
        "        ts.model.train()\n",
        "        m = train_batch(cfg, ts, batch, gbs)\n",
        "        if m:\n",
        "            m['compute/blocks_per_step'] = float(blocks_per_step)\n",
        "            m['compute/blocks_trained'] = float(ts.step * blocks_per_step)\n",
        "            m['compute/blocks_budget'] = float(total_blocks_budget)\n",
        "\n",
        "        if m and use_wandb:\n",
        "            wandb.log(m, step=ts.step)\n",
        "\n",
        "        if ema:\n",
        "            ema.update(ts.model)\n",
        "\n",
        "        pbar.update(ts.step - pbar.n)\n",
        "\n",
        "        if (ts.step % cfg.eval_every_steps) == 0 and (ts.step // cfg.eval_every_steps) >= cfg.min_eval_interval:\n",
        "            if ema:\n",
        "                ts_eval = copy.deepcopy(ts)\n",
        "                ts_eval.model = ema.ema_copy(ts.model)\n",
        "            else:\n",
        "                ts_eval = ts\n",
        "\n",
        "            ts_eval.model.eval()\n",
        "            em = evaluate(cfg, ts_eval, eval_loader, max_batches=None)\n",
        "            if em:\n",
        "                em['compute/blocks_per_step'] = float(blocks_per_step)\n",
        "                em['compute/blocks_trained'] = float(ts.step * blocks_per_step)\n",
        "                em['compute/blocks_budget'] = float(total_blocks_budget)\n",
        "\n",
        "            last_eval_metrics = em\n",
        "\n",
        "            if em:\n",
        "                print(em)\n",
        "                if use_wandb:\n",
        "                    wandb.log(em, step=ts.step)\n",
        "\n",
        "            if ema:\n",
        "                del ts_eval\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    total_time = time.time() - exp_start_time\n",
        "    if torch.cuda.is_available():\n",
        "        peak_memory = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "    summary = {\n",
        "        'config': config_name,\n",
        "        'H_cycles': H_cycles,\n",
        "        'L_cycles': L_cycles,\n",
        "        'halt_max_steps': HALT_MAX_STEPS,\n",
        "        'blocks_per_step': blocks_per_step,\n",
        "        'blocks_per_puzzle': blocks_per_puzzle,\n",
        "        'base_blocks_per_step': base_blocks_per_step,\n",
        "        'total_blocks_budget': total_blocks_budget,\n",
        "        'max_steps': cfg.max_steps,\n",
        "        'total_blocks_trained': int(ts.step * blocks_per_step),\n",
        "        'blocks_budget_ratio_to_base': (ts.step * blocks_per_step) / max(1, total_blocks_budget),\n",
        "        'trainable_params': param_stats['trainable'],\n",
        "        'trainable_ratio': param_stats['ratio'],\n",
        "        'peak_memory_gb': peak_memory,\n",
        "        'total_time_s': total_time,\n",
        "        'samples_per_sec': (ts.step * BATCH_SIZE) / max(total_time, 1),\n",
        "        'final_accuracy': last_eval_metrics.get('eval/accuracy', 0),\n",
        "        'final_exact_accuracy': last_eval_metrics.get('eval/exact_accuracy', 0),\n",
        "    }\n",
        "\n",
        "    if use_wandb:\n",
        "        wandb.log(\n",
        "            {\n",
        "                'arch/peak_memory_gb': summary['peak_memory_gb'],\n",
        "                'arch/samples_per_sec': summary['samples_per_sec'],\n",
        "                'arch/final_exact_accuracy': summary['final_exact_accuracy'],\n",
        "                'compute/total_blocks_trained': summary['total_blocks_trained'],\n",
        "                'compute/blocks_budget_ratio_to_base': summary['blocks_budget_ratio_to_base'],\n",
        "            },\n",
        "            step=ts.step,\n",
        "        )\n",
        "        wandb.finish()\n",
        "\n",
        "    print(f\"\\nðŸ“ˆ {config_name}: H={H_cycles}, L={L_cycles}, exact_acc={summary['final_exact_accuracy']:.2%}\\n\")\n",
        "\n",
        "    return ts, summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! export DISABLE_COMPILE=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 13: Run Experiment(s) - Single or All Architectures\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "\n",
        "RUN_MODE = 'single'  # 'single' or 'all_ARCH'\n",
        "\n",
        "if RUN_MODE == 'single':\n",
        "    train_state, summary = launch_experiment(SELECTED_CONFIG)\n",
        "    print(f\"âœ… {SELECTED_CONFIG}: {summary['final_exact_accuracy']:.2%} exact accuracy\")\n",
        "\n",
        "elif RUN_MODE == 'all_ARCH':\n",
        "    all_summaries = []\n",
        "    for name in sorted(ARCH_CONFIGS.keys()):\n",
        "        _, summary = launch_experiment(name)\n",
        "        all_summaries.append(summary)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    df = pd.DataFrame(all_summaries)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"ðŸ“Š ARCHITECTURE COMPARISON (H/L cycles)\")\n",
        "    print(\"=\" * 110)\n",
        "    cols = [\n",
        "        'config',\n",
        "        'H_cycles',\n",
        "        'L_cycles',\n",
        "        'halt_max_steps',\n",
        "        'blocks_per_step',\n",
        "        'blocks_per_puzzle',\n",
        "        'trainable_params',\n",
        "        'trainable_ratio',\n",
        "        'peak_memory_gb',\n",
        "        'samples_per_sec',\n",
        "        'final_exact_accuracy',\n",
        "    ]\n",
        "    print(df[cols].round(6).to_string(index=False))\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "    df.to_csv('arch_results.csv', index=False)\n",
        "    print(\"âœ… Saved to arch_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Cell 14: Architecture Comparison Visualization\n",
        "# ============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    df = pd.read_csv('arch_results.csv')\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
        "\n",
        "# 1. H cycles\n",
        "axes[0].bar(df['config'], df['H_cycles'])\n",
        "axes[0].set_ylabel('H_cycles')\n",
        "axes[0].set_title('H (outer cycles)')\n",
        "axes[0].tick_params(axis='x', rotation=60)\n",
        "\n",
        "# 2. L cycles\n",
        "axes[1].bar(df['config'], df['L_cycles'])\n",
        "axes[1].set_ylabel('L_cycles')\n",
        "axes[1].set_title('L (inner cycles)')\n",
        "axes[1].tick_params(axis='x', rotation=60)\n",
        "\n",
        "# 3. Approx compute (blocks per puzzle)\n",
        "axes[2].bar(df['config'], df['blocks_per_puzzle'])\n",
        "axes[2].set_ylabel('Blocks / puzzle')\n",
        "axes[2].set_title('Approx compute')\n",
        "axes[2].tick_params(axis='x', rotation=60)\n",
        "\n",
        "# 4. Exact accuracy\n",
        "axes[3].bar(df['config'], df['final_exact_accuracy'])\n",
        "axes[3].set_ylabel('Exact Accuracy')\n",
        "axes[3].set_title('Performance')\n",
        "axes[3].tick_params(axis='x', rotation=60)\n",
        "\n",
        "plt.suptitle('TRM Architecture Comparison (H/L cycles)', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('arch_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"âœ… Saved to arch_comparison.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
