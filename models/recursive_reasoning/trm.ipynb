{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c7bea0",
   "metadata": {},
   "source": [
    "# Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63da294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 27 20:51:16 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   40C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1cbb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu126\n",
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import torch , numpy\n",
    "print(torch.__version__)\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "744b21c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m58 packages\u001b[0m \u001b[2min 765ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m10 packages\u001b[0m \u001b[2min 844ms\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 38ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1madam-atan2\u001b[0m\u001b[2m==0.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1margdantic\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoolname\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhydra-core\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1minquirerpy\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipdb\u001b[0m\u001b[2m==0.13.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mninja\u001b[0m\u001b[2m==1.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpfzy\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools-scm\u001b[0m\u001b[2m==9.2.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install adam-atan2 einops tqdm coolname pydantic argdantic wandb omegaconf hydra-core huggingface_hub packaging ninja wheel setuptools setuptools-scm pydantic-core numba triton ipdb \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc19f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange, repeat\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# 设置随机种子，保证复现结果一致\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a27c7a",
   "metadata": {},
   "source": [
    "# The Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51b12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "IGNORE_LABEL_ID = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8adcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3234b4d7",
   "metadata": {},
   "source": [
    "## common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762161e",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13b3b3",
   "metadata": {},
   "source": [
    "## lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0e49b",
   "metadata": {},
   "source": [
    "## sparse_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e97e93",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
