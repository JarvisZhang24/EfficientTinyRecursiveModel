{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iL1U7NOlQNI"
      },
      "source": [
        "# ğŸ§  TinyRecursiveModel: Baseline Implementation\n",
        "\n",
        "This notebook provides a complete implementation of the **TinyRecursiveModels** (TRM) architecture from the paper \"Less is More: Recursive Reasoning with Tiny Networks\".\n",
        "\n",
        "This notebook serves as a **baseline** for future efficiency-related experiments and optimizations.\n",
        "\n",
        "## ğŸ“‹ Structure\n",
        "\n",
        "| Part | Description |\n",
        "|------|-------------|\n",
        "| **Part 1** | Environment Setup & Utility Functions |\n",
        "| **Part 2** | Original TinyRecursiveModels Implementation |\n",
        "| **Part 3** | Training & Evaluation Framework |\n",
        "| **Part 4** | Experiment Configurations |\n",
        "| **Part 5** | Training & Evaluation |\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ“¦ Part 1: Environment Setup & Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfMrAjlulQNJ"
      },
      "source": [
        "## Cell 1: Environment Installation\n",
        "\n",
        "Install all required dependencies. This cell should be run once at the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZUFgiY_lQNJ",
        "outputId": "a0ba9210-4abe-4367-9c08-787681d82444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for adam-atan2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Triton already installed\n",
            "\n",
            "======================================================================\n",
            "âœ… All dependencies installed successfully!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 1: Environment Installation\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Core dependencies\n",
        "!pip install -q torch adam-atan2 einops tqdm numpy\n",
        "\n",
        "# Configuration & logging\n",
        "!pip install -q pydantic argdantic wandb omegaconf hydra-core\n",
        "\n",
        "# Hugging Face & utilities\n",
        "!pip install -q huggingface_hub packaging coolname\n",
        "\n",
        "# Build tools (for adam-atan2)\n",
        "!pip install -q ninja wheel setuptools setuptools-scm\n",
        "\n",
        "# Optional: Triton for GPU acceleration (if available)\n",
        "try:\n",
        "    import triton\n",
        "    print(\"âœ… Triton already installed\")\n",
        "except ImportError:\n",
        "    !pip install -q triton\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… All dependencies installed successfully!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKiy4ot6lQNK"
      },
      "source": [
        "## Cell 2: Import Libraries\n",
        "\n",
        "Import all necessary libraries and setup device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9PF78h8lQNK",
        "outputId": "0f3b405f-7819-4c18-e0e9-b5f9bd03ff4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ“¦ Library Versions\n",
            "======================================================================\n",
            "PyTorch: 2.9.0+cu126\n",
            "NumPy: 2.0.2\n",
            "CUDA Available: True\n",
            "CUDA Version: 12.6\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 2: Import Libraries\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "from typing import Any, Tuple, Dict, Sequence, Optional, List\n",
        "from dataclasses import dataclass, field\n",
        "from copy import deepcopy\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, IterableDataset, get_worker_info\n",
        "\n",
        "# Scientific computing\n",
        "import numpy as np\n",
        "\n",
        "# Tensor operations\n",
        "import einops\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "# Progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Configuration\n",
        "import pydantic\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Hugging Face (for downloading Sudoku dataset)\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Logging\n",
        "import wandb\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Print versions\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“¦ Library Versions\")\n",
        "print(\"=\"*70)\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YdIpCzHlQNK"
      },
      "source": [
        "## Cell 3: Utility Functions\n",
        "\n",
        "Core utility functions used throughout the notebook:\n",
        "- `set_seed()`: Set random seeds for reproducibility\n",
        "- `trunc_normal_init_()`: Truncated normal initialization (JAX-style)\n",
        "- Device setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ylK5DrlQNK",
        "outputId": "982e12ee-89de-495f-eb44-434dce052fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ² Random seed set to 42\n",
            "ğŸš€ Using CUDA: NVIDIA A100-SXM4-80GB\n",
            "\n",
            "======================================================================\n",
            "âœ… Utility functions loaded!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 3: Utility Functions\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Random Seed Setting\n",
        "# -----------------------------------------------------------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    \"\"\"Set random seeds for reproducibility across all libraries.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # For deterministic behavior (may impact performance)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(f\"ğŸ² Random seed set to {seed}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Truncated Normal Initialization (JAX-style)\n",
        "# -----------------------------------------------------------------------------\n",
        "def trunc_normal_init_(tensor: torch.Tensor, std: float = 1.0, lower: float = -2.0, upper: float = 2.0):\n",
        "    \"\"\"\n",
        "    Truncated normal initialization.\n",
        "\n",
        "    NOTE: PyTorch nn.init.trunc_normal_ is not mathematically correct -\n",
        "    the std dev is not actually the std dev of initialized tensor.\n",
        "    This function is a PyTorch version of JAX truncated normal init (default init method in Flax).\n",
        "\n",
        "    References:\n",
        "    - https://github.com/jax-ml/jax/blob/main/jax/_src/random.py#L807-L848\n",
        "    - https://github.com/jax-ml/jax/blob/main/jax/_src/nn/initializers.py#L162-L199\n",
        "\n",
        "    Args:\n",
        "        tensor: Tensor to initialize in-place\n",
        "        std: Standard deviation of the truncated normal distribution\n",
        "        lower: Lower truncation bound (in units of std)\n",
        "        upper: Upper truncation bound (in units of std)\n",
        "\n",
        "    Returns:\n",
        "        The initialized tensor\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        if std == 0:\n",
        "            tensor.zero_()\n",
        "        else:\n",
        "            sqrt2 = math.sqrt(2)\n",
        "            a = math.erf(lower / sqrt2)\n",
        "            b = math.erf(upper / sqrt2)\n",
        "            z = (b - a) / 2\n",
        "\n",
        "            c = (2 * math.pi) ** -0.5\n",
        "            pdf_u = c * math.exp(-0.5 * lower ** 2)\n",
        "            pdf_l = c * math.exp(-0.5 * upper ** 2)\n",
        "            comp_std = std / math.sqrt(1 - (upper * pdf_u - lower * pdf_l) / z - ((pdf_u - pdf_l) / z) ** 2)\n",
        "\n",
        "            tensor.uniform_(a, b)\n",
        "            tensor.erfinv_()\n",
        "            tensor.mul_(sqrt2 * comp_std)\n",
        "            tensor.clip_(lower * comp_std, upper * comp_std)\n",
        "\n",
        "    return tensor\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Device Setup\n",
        "# -----------------------------------------------------------------------------\n",
        "def get_device():\n",
        "    \"\"\"Get the best available device (CUDA > MPS > CPU).\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"ğŸš€ Using CUDA: {torch.cuda.get_device_name(0)}\")\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"ğŸ Using Apple MPS\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"ğŸ’» Using CPU\")\n",
        "    return device\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helper function to find nearest multiple\n",
        "# -----------------------------------------------------------------------------\n",
        "def find_multiple(a: int, b: int) -> int:\n",
        "    \"\"\"Find the smallest multiple of b that is >= a.\"\"\"\n",
        "    return (-(a // -b)) * b\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize\n",
        "# -----------------------------------------------------------------------------\n",
        "set_seed(42)\n",
        "DEVICE = get_device()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… Utility functions loaded!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HccHokMslQNK"
      },
      "source": [
        "## Cell 4: Configuration Management\n",
        "\n",
        "Define all configuration classes and constants used in the experiments:\n",
        "- `IGNORE_LABEL_ID`: Special token for ignored labels in loss computation\n",
        "- `PuzzleDatasetMetadata`: Metadata structure for puzzle datasets\n",
        "- `TrainingConfig`: Training hyperparameters\n",
        "- `ModelConfig`: Model architecture configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK0-DiNHlQNK",
        "outputId": "a2b7f67f-7447-4f3c-df4f-e2b7d56e8807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Configuration classes defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Available configurations:\n",
            "  - TRMConfig: Model architecture\n",
            "  - TrainingConfig: Training hyperparameters\n",
            "  - SudokuConfig: Sudoku dataset settings\n",
            "  - PuzzleDatasetMetadata: Dataset metadata structure\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 4: Configuration Management\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Constants\n",
        "# -----------------------------------------------------------------------------\n",
        "IGNORE_LABEL_ID = -100  # PyTorch standard ignore index for cross-entropy loss\n",
        "\n",
        "# Dihedral transforms for data augmentation (rotation/flip symmetries)\n",
        "DIHEDRAL_INVERSE = [0, 3, 2, 1, 4, 5, 6, 7]\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Dataset Metadata\n",
        "# -----------------------------------------------------------------------------\n",
        "class PuzzleDatasetMetadata(pydantic.BaseModel):\n",
        "    \"\"\"Metadata for puzzle datasets (Sudoku, ARC, Maze, etc.).\"\"\"\n",
        "    pad_id: int                      # Token ID used for padding\n",
        "    ignore_label_id: Optional[int]   # Token ID to ignore in loss computation\n",
        "    blank_identifier_id: int         # ID for blank/unknown puzzle identifier\n",
        "    vocab_size: int                  # Total vocabulary size\n",
        "    seq_len: int                     # Sequence length (e.g., 81 for 9x9 Sudoku)\n",
        "    num_puzzle_identifiers: int      # Number of unique puzzle identifiers\n",
        "    total_groups: int                # Total number of puzzle groups\n",
        "    mean_puzzle_examples: float      # Average examples per puzzle\n",
        "    total_puzzles: int               # Total number of puzzles\n",
        "    sets: List[str]                  # Dataset split names (e.g., ['all'])\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Model Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class TRMConfig:\n",
        "    \"\"\"\n",
        "    Configuration for TinyRecursiveReasoningModel.\n",
        "\n",
        "    Architecture:\n",
        "    - H_cycles: Number of high-level (outer) recursion cycles\n",
        "    - L_cycles: Number of low-level (inner) recursion cycles\n",
        "    - H_layers: Number of transformer layers in H-block (0 = no H-block)\n",
        "    - L_layers: Number of transformer layers in L-block\n",
        "\n",
        "    The model uses Adaptive Computation Time (ACT) to learn when to halt.\n",
        "    \"\"\"\n",
        "    # Vocabulary & Embedding\n",
        "    vocab_size: int = 11            # 0-9 digits + padding\n",
        "    seq_len: int = 81               # 9x9 = 81 for Sudoku\n",
        "    hidden_size: int = 512          # Model dimension\n",
        "\n",
        "    # Attention\n",
        "    num_heads: int = 8              # Number of attention heads\n",
        "    head_dim: int = 64              # Dimension per head (hidden_size // num_heads)\n",
        "\n",
        "    # FFN\n",
        "    expansion: int = 4              # FFN expansion factor\n",
        "\n",
        "    # Recursion structure\n",
        "    H_cycles: int = 3               # High-level recursion cycles\n",
        "    L_cycles: int = 6               # Low-level recursion cycles\n",
        "    H_layers: int = 0               # Transformer layers in H-block\n",
        "    L_layers: int = 2               # Transformer layers in L-block\n",
        "\n",
        "    # ACT (Adaptive Computation Time)\n",
        "    halt_exploration_prob: float = 0.1   # Probability of random halting during training\n",
        "    halt_max_steps: int = 16             # Maximum ACT steps during training\n",
        "    halt_max_steps_eval: Optional[int] = None  # Max steps during eval (None = use halt_max_steps)\n",
        "\n",
        "    # Puzzle embeddings\n",
        "    puzzle_emb_len: int = 16        # Length of puzzle-specific embedding\n",
        "    puzzle_emb_ndim: int = 512      # Dimension of puzzle embedding\n",
        "    num_puzzle_identifiers: int = 1  # Number of unique puzzle types\n",
        "\n",
        "    # Positional encoding\n",
        "    pos_encodings: str = \"rope\"     # Type: \"rope\" or \"none\"\n",
        "\n",
        "    # Data types\n",
        "    forward_dtype: str = \"bfloat16\" # Computation dtype\n",
        "\n",
        "    # Additional flags\n",
        "    mlp_t: bool = False             # Use MLP instead of transformer on L\n",
        "    no_ACT_continue: bool = True    # Only use halt sigmoid, no continue loss\n",
        "\n",
        "    # Optimizations (Trelis version)\n",
        "    dropout: float = 0.0            # Dropout probability\n",
        "    use_lora: bool = False          # Enable LoRA adaptation\n",
        "    lora_rank: int = 8              # LoRA rank\n",
        "    lora_alpha: float = 16.0        # LoRA scaling factor\n",
        "\n",
        "    def __post_init__(self):\n",
        "        # Auto-compute head_dim if not specified\n",
        "        if self.head_dim is None:\n",
        "            self.head_dim = self.hidden_size // self.num_heads\n",
        "        # Set eval max steps\n",
        "        if self.halt_max_steps_eval is None:\n",
        "            self.halt_max_steps_eval = self.halt_max_steps\n",
        "        # Match puzzle embedding dim to hidden size\n",
        "        if self.puzzle_emb_ndim is None:\n",
        "            self.puzzle_emb_ndim = self.hidden_size\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Training Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    \"\"\"Training hyperparameters.\"\"\"\n",
        "    # Batch size\n",
        "    global_batch_size: int = 768\n",
        "\n",
        "    # Training schedule\n",
        "    epochs: int = 100000\n",
        "    eval_interval: int = 10000\n",
        "    checkpoint_every_eval: bool = True\n",
        "\n",
        "    # Learning rate\n",
        "    lr: float = 1e-4\n",
        "    lr_min_ratio: float = 1.0       # Minimum LR as ratio of initial LR\n",
        "    lr_warmup_steps: int = 2000\n",
        "\n",
        "    # Optimizer (AdamW-like)\n",
        "    beta1: float = 0.9\n",
        "    beta2: float = 0.95\n",
        "    weight_decay: float = 0.1\n",
        "    puzzle_emb_weight_decay: float = 0.1\n",
        "\n",
        "    # Puzzle embedding LR\n",
        "    puzzle_emb_lr: float = 1e-2\n",
        "\n",
        "    # Misc\n",
        "    seed: int = 42\n",
        "    min_eval_interval: int = 0\n",
        "\n",
        "    # EMA (Exponential Moving Average)\n",
        "    ema: bool = False\n",
        "    ema_rate: float = 0.999\n",
        "\n",
        "    # Freeze weights (learn only embeddings)\n",
        "    freeze_weights: bool = False\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Sudoku-specific Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class SudokuConfig:\n",
        "    \"\"\"Configuration for Sudoku dataset.\"\"\"\n",
        "    source_repo: str = \"sapientinc/sudoku-extreme\"\n",
        "    output_dir: str = \"data/sudoku-extreme\"\n",
        "\n",
        "    # Data sampling\n",
        "    subsample_size: Optional[int] = None  # None = use all data\n",
        "    min_difficulty: Optional[int] = None  # Filter by minimum difficulty rating\n",
        "    num_aug: int = 0                      # Number of augmentations per puzzle\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Configuration classes defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Available configurations:\")\n",
        "print(\"  - TRMConfig: Model architecture\")\n",
        "print(\"  - TrainingConfig: Training hyperparameters\")\n",
        "print(\"  - SudokuConfig: Sudoku dataset settings\")\n",
        "print(\"  - PuzzleDatasetMetadata: Dataset metadata structure\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRSoXYdalQNL"
      },
      "source": [
        "## Cell 5: Weights & Biases Setup\n",
        "\n",
        "Configure Weights & Biases for experiment tracking and comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZveIziAlQNL",
        "outputId": "964912f1-9daa-4f30-d679-cd3235b3587d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ“Š Configuring Weights & Biases\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjarviszhang\u001b[0m (\u001b[33mjarviszhang-new-york-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“ W&B Project: TRM-Baseline\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 5: Weights & Biases Setup\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“Š Configuring Weights & Biases\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Option 1: Login interactively (recommended for first time)\n",
        "# wandb.login()\n",
        "\n",
        "# Option 2: Login with API key (for Colab or automated runs)\n",
        "# Uncomment and replace with your API key:\n",
        "WANDB_API_KEY = ''\n",
        "wandb.login(key=WANDB_API_KEY)\n",
        "\n",
        "# Option 3: Use environment variable\n",
        "# os.environ[\"WANDB_API_KEY\"] = \"your-api-key-here\"\n",
        "\n",
        "# For now, let's try to login (will prompt if not already logged in)\n",
        "\n",
        "# Project configuration\n",
        "WANDB_PROJECT = \"TRM-Baseline\"\n",
        "WANDB_ENTITY = None  # Set to your W&B username/team if needed\n",
        "\n",
        "print(f\"\\nğŸ“ W&B Project: {WANDB_PROJECT}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "277TPZlplQNL"
      },
      "source": [
        "## Cell 6: Build Sudoku Dataset\n",
        "\n",
        "Download and preprocess the Sudoku dataset from Hugging Face Hub.\n",
        "\n",
        "The dataset contains:\n",
        "- **Input**: 9Ã—9 Sudoku puzzle with empty cells marked as 0\n",
        "- **Label**: Complete solution\n",
        "\n",
        "Data augmentation includes:\n",
        "- Digit permutation (relabeling 1-9)\n",
        "- Row/column band shuffling\n",
        "- Transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_P6gesVlQNL",
        "outputId": "5e55a017-2a9d-4ce8-a028-6483b76bdc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Sudoku dataset builder ready!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 6: Sudoku Dataset Builder\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# ============ é…ç½® ============\n",
        "SOURCE_REPO = \"sapientinc/sudoku-extreme\"\n",
        "TRAIN_SUBSAMPLE_SIZE = 10000  # è®­ç»ƒé›†é‡‡æ ·æ•°é‡ï¼ŒNone è¡¨ç¤ºå…¨éƒ¨\n",
        "TEST_SUBSAMPLE_SIZE = 1000    # æµ‹è¯•é›†é‡‡æ ·æ•°é‡ï¼ŒNone è¡¨ç¤ºå…¨éƒ¨\n",
        "NUM_AUG = 0                   # æ•°æ®å¢å¼ºæ¬¡æ•°\n",
        "\n",
        "# è¾“å‡ºç›®å½•ååŒ…å«é…ç½®ä¿¡æ¯\n",
        "train_str = f\"{TRAIN_SUBSAMPLE_SIZE}\" if TRAIN_SUBSAMPLE_SIZE else \"full\"\n",
        "test_str = f\"{TEST_SUBSAMPLE_SIZE}\" if TEST_SUBSAMPLE_SIZE else \"full\"\n",
        "OUTPUT_DIR = f\"data/sudoku-extreme-train{train_str}-test{test_str}-aug{NUM_AUG}\"\n",
        "\n",
        "# ============ æ•°æ®å¢å¼ºå‡½æ•° ============\n",
        "def shuffle_sudoku(board: np.ndarray, solution: np.ndarray):\n",
        "    \"\"\"å¯¹æ•°ç‹¬è¿›è¡Œç­‰ä»·å˜æ¢ï¼ˆä¿æŒæœ‰æ•ˆæ€§ï¼‰\"\"\"\n",
        "    # æ•°å­—æ˜ å°„ï¼šéšæœºç½®æ¢ 1-9\n",
        "    digit_map = np.pad(np.random.permutation(np.arange(1, 10)), (1, 0))\n",
        "\n",
        "    # éšæœºè½¬ç½®\n",
        "    transpose_flag = np.random.rand() < 0.5\n",
        "\n",
        "    # è¡Œç½®æ¢ï¼šå…ˆæ‰“ä¹± 3 ä¸ª bandï¼Œå†æ‰“ä¹±æ¯ä¸ª band å†…çš„ 3 è¡Œ\n",
        "    bands = np.random.permutation(3)\n",
        "    row_perm = np.concatenate([b * 3 + np.random.permutation(3) for b in bands])\n",
        "\n",
        "    # åˆ—ç½®æ¢ï¼šåŒç†\n",
        "    stacks = np.random.permutation(3)\n",
        "    col_perm = np.concatenate([s * 3 + np.random.permutation(3) for s in stacks])\n",
        "\n",
        "    # æ„å»º 81->81 çš„ä½ç½®æ˜ å°„\n",
        "    mapping = np.array([row_perm[i // 9] * 9 + col_perm[i % 9] for i in range(81)])\n",
        "\n",
        "    def apply_transformation(x: np.ndarray) -> np.ndarray:\n",
        "        if transpose_flag:\n",
        "            x = x.T\n",
        "        new_board = x.flatten()[mapping].reshape(9, 9).copy()\n",
        "        return digit_map[new_board]\n",
        "\n",
        "    return apply_transformation(board), apply_transformation(solution)\n",
        "\n",
        "# ============ å¤„ç†å•ä¸ªå­é›† ============\n",
        "def convert_subset(set_name: str):\n",
        "    \"\"\"å¤„ç†è®­ç»ƒé›†æˆ–æµ‹è¯•é›†\"\"\"\n",
        "    print(f\"\\nğŸ“¥ Processing {set_name} set...\")\n",
        "\n",
        "    # ä» HuggingFace ä¸‹è½½ CSV\n",
        "    csv_path = hf_hub_download(SOURCE_REPO, f\"{set_name}.csv\", repo_type=\"dataset\")\n",
        "\n",
        "    # è¯»å– CSV\n",
        "    inputs, labels = [], []\n",
        "    with open(csv_path, newline=\"\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # è·³è¿‡ header\n",
        "        for source, q, a, rating in tqdm(reader, desc=\"Reading CSV\"):\n",
        "            assert len(q) == 81 and len(a) == 81\n",
        "            inputs.append(np.frombuffer(q.replace('.', '0').encode(), dtype=np.uint8).reshape(9, 9) - ord('0'))\n",
        "            labels.append(np.frombuffer(a.encode(), dtype=np.uint8).reshape(9, 9) - ord('0'))\n",
        "\n",
        "    print(f\"  Loaded {len(inputs)} puzzles\")\n",
        "\n",
        "    # æ•°æ®é›†é‡‡æ ·\n",
        "    subsample_size = TRAIN_SUBSAMPLE_SIZE if set_name == \"train\" else TEST_SUBSAMPLE_SIZE\n",
        "    if subsample_size is not None and subsample_size < len(inputs):\n",
        "        indices = np.random.choice(len(inputs), size=subsample_size, replace=False)\n",
        "        inputs = [inputs[i] for i in indices]\n",
        "        labels = [labels[i] for i in indices]\n",
        "        print(f\"  Subsampled to {len(inputs)} puzzles\")\n",
        "\n",
        "    # æ•°æ®å¢å¼ºï¼ˆä»…è®­ç»ƒé›†ï¼‰\n",
        "    num_augments = NUM_AUG if set_name == \"train\" else 0\n",
        "\n",
        "    # æ„å»ºç»“æœ\n",
        "    results = {k: [] for k in [\"inputs\", \"labels\", \"puzzle_identifiers\", \"puzzle_indices\", \"group_indices\"]}\n",
        "    puzzle_id = 0\n",
        "    example_id = 0\n",
        "\n",
        "    results[\"puzzle_indices\"].append(0)\n",
        "    results[\"group_indices\"].append(0)\n",
        "\n",
        "    for orig_inp, orig_out in tqdm(zip(inputs, labels), total=len(inputs), desc=\"Augmenting\"):\n",
        "        for aug_idx in range(1 + num_augments):\n",
        "            if aug_idx == 0:\n",
        "                inp, out = orig_inp, orig_out\n",
        "            else:\n",
        "                inp, out = shuffle_sudoku(orig_inp, orig_out)\n",
        "\n",
        "            results[\"inputs\"].append(inp)\n",
        "            results[\"labels\"].append(out)\n",
        "            example_id += 1\n",
        "            puzzle_id += 1\n",
        "\n",
        "            results[\"puzzle_indices\"].append(example_id)\n",
        "            results[\"puzzle_identifiers\"].append(0)\n",
        "\n",
        "        results[\"group_indices\"].append(puzzle_id)\n",
        "\n",
        "    # è½¬æ¢ä¸º NumPy æ•°ç»„\n",
        "    def seq_to_numpy(seq):\n",
        "        arr = np.concatenate(seq).reshape(len(seq), -1)\n",
        "        assert np.all((arr >= 0) & (arr <= 9))\n",
        "        return arr + 1  # åç§» +1ï¼Œ0 ç•™ç»™ PAD\n",
        "\n",
        "    results = {\n",
        "        \"inputs\": seq_to_numpy(results[\"inputs\"]),\n",
        "        \"labels\": seq_to_numpy(results[\"labels\"]),\n",
        "        \"group_indices\": np.array(results[\"group_indices\"], dtype=np.int32),\n",
        "        \"puzzle_indices\": np.array(results[\"puzzle_indices\"], dtype=np.int32),\n",
        "        \"puzzle_identifiers\": np.array(results[\"puzzle_identifiers\"], dtype=np.int32),\n",
        "    }\n",
        "\n",
        "    # å…ƒæ•°æ®\n",
        "    metadata = PuzzleDatasetMetadata(\n",
        "        seq_len=81,\n",
        "        vocab_size=11,  # PAD (0) + digits 1-10 (representing 0-9)\n",
        "        pad_id=0,\n",
        "        ignore_label_id=0,\n",
        "        blank_identifier_id=0,\n",
        "        num_puzzle_identifiers=1,\n",
        "        total_groups=len(results[\"group_indices\"]) - 1,\n",
        "        mean_puzzle_examples=1,\n",
        "        total_puzzles=len(results[\"group_indices\"]) - 1,\n",
        "        sets=[\"all\"]\n",
        "    )\n",
        "\n",
        "    # ä¿å­˜\n",
        "    save_dir = os.path.join(OUTPUT_DIR, set_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with open(os.path.join(save_dir, \"dataset.json\"), \"w\") as f:\n",
        "        json.dump(metadata.model_dump(), f, indent=2)\n",
        "\n",
        "    for k, v in results.items():\n",
        "        np.save(os.path.join(save_dir, f\"all__{k}.npy\"), v)\n",
        "\n",
        "    print(f\"  âœ… Saved to {save_dir}\")\n",
        "    print(f\"  ğŸ“Š Total examples: {results['inputs'].shape[0]}\")\n",
        "\n",
        "    return metadata\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Sudoku dataset builder ready!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juhN68gQlQNL"
      },
      "source": [
        "## Cell 7: Download and Build Sudoku Dataset\n",
        "\n",
        "Actually download and preprocess the Sudoku dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745,
          "referenced_widgets": [
            "3348a10d6f9245469fa73df072bbc763",
            "60ffd019eef7498d8acddd9f75e993f6",
            "261596042dfd453db52e15a621add88e",
            "51b084d4a3f442d3b8c7af0b52b0b733",
            "1e0be965b1aa41c4b2beae7b81984582",
            "565ccb324af14f7397c529aa82c0f276",
            "1e916a981f1b439e901270f327f95d5e",
            "af1cb79c0a92411bbab4ade2bd0a3470",
            "31bb4725caae47b4b77bcef6e0f3947b",
            "f69cf6386ff44ec5920343e3661af529",
            "92ecffad6dea4685b7d2618ccff0281e",
            "404dddce768d4732a411bca4f080b7e5",
            "5f800cd2257c4686a9e030e195c8ac8a",
            "b7ea7a06db8f4f9bb3789a28e4c283e8",
            "0244142daba0413bbb60c6251152fdee",
            "98efff2a3e01443383e7d2dfd872310c",
            "172333e5bce24dc1ab5c1a69c8cfaf6c",
            "17ca2bcf38074319a29df9ddd4171867",
            "354ddcf830a14413aed57043e39ee816",
            "98d9a7ce6d2d40f789a18554de988e8a",
            "863e093b87924d44af65ee0df0deb9ec",
            "297836094b0043a7bab779d41c04935e",
            "bf2d64c97d054a90b6436b0df10120bb",
            "dbe8c2dea1fd46f9aa929e0285d896d8",
            "e5f0f04a68c74c389c93a3d6d273dbcc",
            "de202c6cb8734091bfba87ff224b2993",
            "77e4c56008774c12b021e3e214c40750",
            "6e47c02e634d4b3491454a0d534f7ff6",
            "3cdf3c8ad63b4a89b78e5f7f30adcea0",
            "490819751e8846e28b9ff67eed553fa1",
            "c268f37851f94ff3a5de0f22e732d447",
            "5d584203cf304648a8a1a3c720565ed7",
            "70789fbc92754577b4a5f27f6a202064",
            "9f9c5d07abb74981a31e500d653cad26",
            "8371b0424c8640d9a581167cec0b522f",
            "251de39768164ec2bb91615333ad3c45",
            "e248404d9ab9429c91b311966eee8dab",
            "048c444bc8304c4dbcb635bfd6ce9c79",
            "74c4d59c5f2e458fadfa8d85bac5f5a1",
            "3c32a182c040468d98703e222dad956f",
            "09012e04d2b749aa8eaaafc6bc92914a",
            "f9b2a3764c17459e96a6647deec87d8b",
            "e9718beb154346a6a46adfd85efa8627",
            "7db794b3d0aa402286b4de66ca747a2c",
            "f3bc8c5a07894432a942e67f1a0dc6ad",
            "ac2374f51d454953bc5252823c5fec51",
            "fe0d9ded37ff4656b9c98951103528a1",
            "dd2acc101a144854b8b161542da6d066",
            "0e8482e7036e44fbb80a22ed3236a818",
            "4b5f478716ed461ebeafabf9f3abe842",
            "b4bf82ed874f4cd68f7ff6343ffd1969",
            "2ea5873e06a948968f8ed4b55c835ca8",
            "6dfed1f126774c1894c4edc4c9ff8cd7",
            "1471721645a94e9e9bd98eea60421376",
            "a86b552699fe49198648f8089ca78bac",
            "3f2a55d2835d4f7f83d4a7fbee1cc65f",
            "2395f964b0d74bf5a1f96d367b80ac15",
            "5032b4004f854829a2fbaa0448ad0921",
            "aa41a0f64a33401f94a5527852fd5d26",
            "30a52a85c5ce47e89dc192ae373c65f0",
            "4ce722c6de60489d9074d849376386f6",
            "5b896d4addd04e84bc12aec6a6b5bec5",
            "9b9aa4b5fa5a44f3920514fc1525f3ac",
            "845c3c87bd7047c7916b7f8067efe352",
            "5fe5d387f8ca4be29f8a9dd95bbfb7c7",
            "ab58b3a43a464c7ab8d8280e9c8c96e7"
          ]
        },
        "id": "LWL8G7cmlQNL",
        "outputId": "ffce2321-dc4b-48e3-f3c2-f1160ce134e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ“¦ Building Sudoku Dataset\n",
            "======================================================================\n",
            "Source: sapientinc/sudoku-extreme\n",
            "Output: data/sudoku-extreme-train10000-test1000-aug0\n",
            "Train subsample: 10000\n",
            "Test subsample: 1000\n",
            "Augmentation: 0\n",
            "\n",
            "ğŸ“¥ Processing train set...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3348a10d6f9245469fa73df072bbc763",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.csv:   0%|          | 0.00/719M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "404dddce768d4732a411bca4f080b7e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Reading CSV: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loaded 3831994 puzzles\n",
            "  Subsampled to 10000 puzzles\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf2d64c97d054a90b6436b0df10120bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Augmenting:   0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… Saved to data/sudoku-extreme-train10000-test1000-aug0/train\n",
            "  ğŸ“Š Total examples: 10000\n",
            "\n",
            "ğŸ“¥ Processing test set...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f9c5d07abb74981a31e500d653cad26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.csv:   0%|          | 0.00/79.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3bc8c5a07894432a942e67f1a0dc6ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Reading CSV: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Loaded 422786 puzzles\n",
            "  Subsampled to 1000 puzzles\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f2a55d2835d4f7f83d4a7fbee1cc65f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Augmenting:   0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ… Saved to data/sudoku-extreme-train10000-test1000-aug0/test\n",
            "  ğŸ“Š Total examples: 1000\n",
            "\n",
            "======================================================================\n",
            "ğŸ“Š Dataset Summary\n",
            "======================================================================\n",
            "Train puzzles: 10,000\n",
            "Test puzzles: 1,000\n",
            "Sequence length: 81\n",
            "Vocabulary size: 11\n",
            "Dataset path: data/sudoku-extreme-train10000-test1000-aug0\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 7: Download and Build Sudoku Dataset\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“¦ Building Sudoku Dataset\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Source: {SOURCE_REPO}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n",
        "print(f\"Train subsample: {TRAIN_SUBSAMPLE_SIZE}\")\n",
        "print(f\"Test subsample: {TEST_SUBSAMPLE_SIZE}\")\n",
        "print(f\"Augmentation: {NUM_AUG}\")\n",
        "\n",
        "# Check if already exists\n",
        "train_metadata_path = os.path.join(OUTPUT_DIR, \"train\", \"dataset.json\")\n",
        "test_metadata_path = os.path.join(OUTPUT_DIR, \"test\", \"dataset.json\")\n",
        "\n",
        "if os.path.exists(train_metadata_path) and os.path.exists(test_metadata_path):\n",
        "    print(\"\\nâœ… Dataset already exists! Loading metadata...\")\n",
        "    with open(train_metadata_path, \"r\") as f:\n",
        "        train_metadata = PuzzleDatasetMetadata(**json.load(f))\n",
        "    with open(test_metadata_path, \"r\") as f:\n",
        "        test_metadata = PuzzleDatasetMetadata(**json.load(f))\n",
        "else:\n",
        "    # Build train set\n",
        "    train_metadata = convert_subset(\"train\")\n",
        "\n",
        "    # Build test set (with subsampling if TEST_SUBSAMPLE_SIZE is set)\n",
        "    test_metadata = convert_subset(\"test\")\n",
        "\n",
        "    # Save identifiers.json (only once)\n",
        "    with open(os.path.join(OUTPUT_DIR, \"identifiers.json\"), \"w\") as f:\n",
        "        json.dump([\"<blank>\"], f)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š Dataset Summary\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Train puzzles: {train_metadata.total_puzzles:,}\")\n",
        "print(f\"Test puzzles: {test_metadata.total_puzzles:,}\")\n",
        "print(f\"Sequence length: {train_metadata.seq_len}\")\n",
        "print(f\"Vocabulary size: {train_metadata.vocab_size}\")\n",
        "print(f\"Dataset path: {OUTPUT_DIR}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-2-yrW3lQNL"
      },
      "source": [
        "## Cell 8: Dataset and DataLoader\n",
        "\n",
        "Create PyTorch Dataset and DataLoader classes for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VELLi8MelQNL",
        "outputId": "609234b8-f129-4b75-d720-e8bf7e68c410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Dataset and DataLoader classes defined!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 8: Dataset and DataLoader Classes\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def _sample_batch(\n",
        "    rng: np.random.Generator,\n",
        "    group_order: np.ndarray,\n",
        "    puzzle_indices: np.ndarray,\n",
        "    group_indices: np.ndarray,\n",
        "    start_index: int,\n",
        "    global_batch_size: int\n",
        "):\n",
        "    \"\"\"Sample a batch of puzzle indices.\"\"\"\n",
        "    batch = []\n",
        "    batch_puzzle_indices = []\n",
        "    current_size = 0\n",
        "\n",
        "    while (start_index < group_order.size) and (current_size < global_batch_size):\n",
        "        group_id = group_order[start_index]\n",
        "        puzzle_id = rng.integers(group_indices[group_id], group_indices[group_id + 1])\n",
        "        start_index += 1\n",
        "\n",
        "        puzzle_start = puzzle_indices[puzzle_id]\n",
        "        puzzle_size = int(puzzle_indices[puzzle_id + 1] - puzzle_start)\n",
        "\n",
        "        append_size = min(puzzle_size, global_batch_size - current_size)\n",
        "\n",
        "        batch_puzzle_indices.append(np.full(append_size, puzzle_id, dtype=np.int32))\n",
        "        batch.append(puzzle_start + np.random.choice(puzzle_size, append_size, replace=False))\n",
        "\n",
        "        current_size += append_size\n",
        "\n",
        "    return start_index, np.concatenate(batch), np.concatenate(batch_puzzle_indices)\n",
        "\n",
        "\n",
        "class PuzzleDataset(IterableDataset):\n",
        "    \"\"\"\n",
        "    Iterable dataset for puzzle training.\n",
        "\n",
        "    Features:\n",
        "    - Memory-efficient: uses memory-mapped arrays\n",
        "    - Supports distributed training\n",
        "    - Handles multiple epochs per iteration\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset_paths: List[str],\n",
        "        global_batch_size: int,\n",
        "        seed: int = 42,\n",
        "        test_set_mode: bool = False,\n",
        "        epochs_per_iter: int = 1,\n",
        "        rank: int = 0,\n",
        "        num_replicas: int = 1,\n",
        "        split: str = \"train\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dataset_paths = dataset_paths\n",
        "        self.global_batch_size = global_batch_size\n",
        "        self.seed = seed\n",
        "        self.test_set_mode = test_set_mode\n",
        "        self.epochs_per_iter = epochs_per_iter\n",
        "        self.rank = rank\n",
        "        self.num_replicas = num_replicas\n",
        "        self.split = split\n",
        "\n",
        "        # Load metadata\n",
        "        self.metadata = self._load_merged_metadata()\n",
        "\n",
        "        # Compute local batch size\n",
        "        assert global_batch_size % num_replicas == 0\n",
        "        self.local_batch_size = global_batch_size // num_replicas\n",
        "\n",
        "        # State\n",
        "        self._data = None\n",
        "        self._iters = 0\n",
        "\n",
        "    def _load_merged_metadata(self) -> PuzzleDatasetMetadata:\n",
        "        \"\"\"Load and merge metadata from all dataset paths.\"\"\"\n",
        "        first_metadata = None\n",
        "        total_groups = 0\n",
        "        total_puzzles = 0\n",
        "        mean_puzzle_examples_sum = 0\n",
        "\n",
        "        for path in self.dataset_paths:\n",
        "            with open(os.path.join(path, self.split, \"dataset.json\"), \"r\") as f:\n",
        "                meta = PuzzleDatasetMetadata(**json.load(f))\n",
        "\n",
        "            if first_metadata is None:\n",
        "                first_metadata = meta\n",
        "            else:\n",
        "                # Validate consistency\n",
        "                assert first_metadata.seq_len == meta.seq_len\n",
        "                assert first_metadata.vocab_size == meta.vocab_size\n",
        "\n",
        "            total_groups += meta.total_groups\n",
        "            total_puzzles += meta.total_puzzles\n",
        "            mean_puzzle_examples_sum += meta.mean_puzzle_examples * meta.total_puzzles\n",
        "\n",
        "        return PuzzleDatasetMetadata(\n",
        "            seq_len=first_metadata.seq_len,\n",
        "            vocab_size=first_metadata.vocab_size,\n",
        "            pad_id=first_metadata.pad_id,\n",
        "            ignore_label_id=first_metadata.ignore_label_id,\n",
        "            blank_identifier_id=first_metadata.blank_identifier_id,\n",
        "            num_puzzle_identifiers=first_metadata.num_puzzle_identifiers,\n",
        "            total_groups=total_groups,\n",
        "            mean_puzzle_examples=mean_puzzle_examples_sum / total_puzzles if total_puzzles > 0 else 0,\n",
        "            total_puzzles=total_puzzles,\n",
        "            sets=first_metadata.sets\n",
        "        )\n",
        "\n",
        "    def _lazy_load_dataset(self):\n",
        "        \"\"\"Lazily load dataset arrays.\"\"\"\n",
        "        if self._data is not None:\n",
        "            return\n",
        "\n",
        "        field_mmap_modes = {\n",
        "            \"inputs\": \"r\",\n",
        "            \"labels\": \"r\",\n",
        "            \"puzzle_identifiers\": None,\n",
        "            \"puzzle_indices\": None,\n",
        "            \"group_indices\": None\n",
        "        }\n",
        "\n",
        "        self._data = {}\n",
        "        for set_name in self.metadata.sets:\n",
        "            for i, dataset_path in enumerate(self.dataset_paths):\n",
        "                key = set_name if i == 0 else f\"{set_name}{i}\"\n",
        "                self._data[key] = {\n",
        "                    field: np.load(\n",
        "                        os.path.join(dataset_path, self.split, f\"{set_name}__{field}.npy\"),\n",
        "                        mmap_mode=mmap\n",
        "                    )\n",
        "                    for field, mmap in field_mmap_modes.items()\n",
        "                }\n",
        "\n",
        "    def _collate_batch(self, batch):\n",
        "        \"\"\"Collate and convert batch to tensors.\"\"\"\n",
        "        batch = {k: v.astype(np.int32) for k, v in batch.items()}\n",
        "\n",
        "        # Convert ignore label IDs\n",
        "        if self.metadata.ignore_label_id is not None:\n",
        "            batch[\"labels\"][batch[\"labels\"] == self.metadata.ignore_label_id] = IGNORE_LABEL_ID\n",
        "\n",
        "        # Pad if needed\n",
        "        if batch[\"puzzle_identifiers\"].size < self.local_batch_size:\n",
        "            pad_size = self.local_batch_size - batch[\"puzzle_identifiers\"].size\n",
        "            pad_values = {\n",
        "                \"inputs\": self.metadata.pad_id,\n",
        "                \"labels\": IGNORE_LABEL_ID,\n",
        "                \"puzzle_identifiers\": self.metadata.blank_identifier_id\n",
        "            }\n",
        "            batch = {\n",
        "                k: np.pad(v, ((0, pad_size),) + ((0, 0),) * (v.ndim - 1), constant_values=pad_values[k])\n",
        "                for k, v in batch.items()\n",
        "            }\n",
        "\n",
        "        return {k: torch.from_numpy(v) for k, v in batch.items()}\n",
        "\n",
        "    def _iter_train(self):\n",
        "        \"\"\"Training iteration.\"\"\"\n",
        "        for set_name, dataset in self._data.items():\n",
        "            self._iters += 1\n",
        "\n",
        "            rng = np.random.Generator(np.random.Philox(seed=self.seed + self._iters))\n",
        "            group_order = np.concatenate([\n",
        "                rng.permutation(dataset[\"group_indices\"].size - 1)\n",
        "                for _ in range(self.epochs_per_iter)\n",
        "            ])\n",
        "            start_index = 0\n",
        "\n",
        "            while start_index < group_order.size:\n",
        "                start_index, batch_indices, batch_puzzle_indices = _sample_batch(\n",
        "                    rng,\n",
        "                    group_order=group_order,\n",
        "                    puzzle_indices=dataset[\"puzzle_indices\"],\n",
        "                    group_indices=dataset[\"group_indices\"],\n",
        "                    start_index=start_index,\n",
        "                    global_batch_size=self.global_batch_size,\n",
        "                )\n",
        "\n",
        "                global_effective_batch_size = batch_puzzle_indices.size\n",
        "\n",
        "                # Drop last incomplete batch\n",
        "                if global_effective_batch_size < self.global_batch_size:\n",
        "                    break\n",
        "\n",
        "                # Select local batch\n",
        "                local_start = self.rank * self.local_batch_size\n",
        "                local_end = (self.rank + 1) * self.local_batch_size\n",
        "\n",
        "                batch_indices = batch_indices[local_start:local_end]\n",
        "                batch_puzzle_indices = batch_puzzle_indices[local_start:local_end]\n",
        "\n",
        "                batch = self._collate_batch({\n",
        "                    \"inputs\": dataset[\"inputs\"][batch_indices],\n",
        "                    \"labels\": dataset[\"labels\"][batch_indices],\n",
        "                    \"puzzle_identifiers\": dataset[\"puzzle_identifiers\"][batch_puzzle_indices]\n",
        "                })\n",
        "\n",
        "                yield set_name, batch, global_effective_batch_size\n",
        "\n",
        "    def _iter_test(self):\n",
        "        \"\"\"Test iteration (sequential).\"\"\"\n",
        "        for set_name, dataset in self._data.items():\n",
        "            total_examples = len(dataset[\"inputs\"])\n",
        "            start_index = 0\n",
        "\n",
        "            while start_index < total_examples:\n",
        "                end_index = min(total_examples, start_index + self.global_batch_size)\n",
        "\n",
        "                local_start = start_index + self.rank * self.local_batch_size\n",
        "                local_end = min(start_index + (self.rank + 1) * self.local_batch_size, end_index)\n",
        "\n",
        "                # Get puzzle indices for this batch\n",
        "                puzzle_indices_list = []\n",
        "                puzzle_index = np.searchsorted(dataset[\"puzzle_indices\"], local_start, side=\"right\") - 1\n",
        "                for i in range(local_start, local_end):\n",
        "                    while puzzle_index + 1 < len(dataset[\"puzzle_indices\"]) and i >= dataset[\"puzzle_indices\"][puzzle_index + 1]:\n",
        "                        puzzle_index += 1\n",
        "                    puzzle_indices_list.append(puzzle_index)\n",
        "\n",
        "                batch = self._collate_batch({\n",
        "                    \"inputs\": dataset[\"inputs\"][local_start:local_end],\n",
        "                    \"labels\": dataset[\"labels\"][local_start:local_end],\n",
        "                    \"puzzle_identifiers\": dataset[\"puzzle_identifiers\"][puzzle_indices_list]\n",
        "                })\n",
        "\n",
        "                yield set_name, batch, end_index - start_index\n",
        "                start_index += self.global_batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        worker_info = get_worker_info()\n",
        "        assert worker_info is None or worker_info.num_workers == 1\n",
        "\n",
        "        self._lazy_load_dataset()\n",
        "\n",
        "        if self.test_set_mode:\n",
        "            yield from self._iter_test()\n",
        "        else:\n",
        "            yield from self._iter_train()\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Dataset and DataLoader classes defined!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4UK8phdlQNM"
      },
      "source": [
        "## Cell 9: Visualization Utilities\n",
        "\n",
        "Helper functions for visualizing Sudoku puzzles and training progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okpSNW_klQNM",
        "outputId": "d5d8b87e-ca49-40ee-f97f-2cc094396a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Visualization utilities ready!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 9: Visualization Utilities\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def visualize_sudoku(puzzle: np.ndarray, solution: np.ndarray = None, prediction: np.ndarray = None, title: str = \"Sudoku\"):\n",
        "    \"\"\"\n",
        "    Visualize a Sudoku puzzle with optional solution and prediction.\n",
        "\n",
        "    Args:\n",
        "        puzzle: 9x9 input puzzle (1-10, where 1 = empty after preprocessing)\n",
        "        solution: 9x9 ground truth solution (optional)\n",
        "        prediction: 9x9 model prediction (optional)\n",
        "        title: Plot title\n",
        "    \"\"\"\n",
        "    # Convert back to 0-9 range\n",
        "    puzzle = puzzle - 1 if puzzle.max() > 9 else puzzle\n",
        "    if solution is not None:\n",
        "        solution = solution - 1 if solution.max() > 9 else solution\n",
        "    if prediction is not None:\n",
        "        prediction = prediction - 1 if prediction.max() > 9 else prediction\n",
        "\n",
        "    n_plots = 1 + (solution is not None) + (prediction is not None)\n",
        "    fig, axes = plt.subplots(1, n_plots, figsize=(4 * n_plots, 4))\n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    def draw_sudoku(ax, data, subtitle, highlight_errors=False, original=None):\n",
        "        ax.set_xlim(0, 9)\n",
        "        ax.set_ylim(0, 9)\n",
        "        ax.set_aspect('equal')\n",
        "        ax.axis('off')\n",
        "        ax.set_title(subtitle, fontsize=12, fontweight='bold')\n",
        "\n",
        "        # Draw cells\n",
        "        for i in range(9):\n",
        "            for j in range(9):\n",
        "                val = data[i, j]\n",
        "\n",
        "                # Determine cell color\n",
        "                if highlight_errors and original is not None and val != original[i, j]:\n",
        "                    color = '#ffcccc'  # Light red for errors\n",
        "                elif puzzle[i, j] == 0:  # Originally empty cell\n",
        "                    color = '#e6f3ff'  # Light blue for filled cells\n",
        "                else:\n",
        "                    color = 'white'\n",
        "\n",
        "                rect = plt.Rectangle((j, 8-i), 1, 1, fill=True, facecolor=color, edgecolor='gray', linewidth=0.5)\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                if val != 0:\n",
        "                    ax.text(j + 0.5, 8 - i + 0.5, str(val), ha='center', va='center',\n",
        "                           fontsize=14, fontweight='bold' if puzzle[i, j] != 0 else 'normal')\n",
        "\n",
        "        # Draw 3x3 box borders\n",
        "        for i in range(4):\n",
        "            lw = 2 if i % 3 == 0 else 0.5\n",
        "            ax.axhline(y=i*3, color='black', linewidth=lw)\n",
        "            ax.axvline(x=i*3, color='black', linewidth=lw)\n",
        "\n",
        "    # Draw puzzle\n",
        "    draw_sudoku(axes[0], puzzle, \"Input\")\n",
        "\n",
        "    # Draw solution if provided\n",
        "    plot_idx = 1\n",
        "    if solution is not None:\n",
        "        draw_sudoku(axes[plot_idx], solution, \"Solution\")\n",
        "        plot_idx += 1\n",
        "\n",
        "    # Draw prediction if provided\n",
        "    if prediction is not None:\n",
        "        draw_sudoku(axes[plot_idx], prediction, \"Prediction\",\n",
        "                   highlight_errors=solution is not None, original=solution)\n",
        "\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_training_curves(history: Dict[str, List[float]], title: str = \"Training Progress\"):\n",
        "    \"\"\"\n",
        "    Plot training and validation metrics.\n",
        "\n",
        "    Args:\n",
        "        history: Dictionary with metric names as keys and lists of values\n",
        "        title: Plot title\n",
        "    \"\"\"\n",
        "    metrics = list(history.keys())\n",
        "    n_metrics = len(metrics)\n",
        "\n",
        "    fig, axes = plt.subplots(1, n_metrics, figsize=(5 * n_metrics, 4))\n",
        "    if n_metrics == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, metric in zip(axes, metrics):\n",
        "        values = history[metric]\n",
        "        ax.plot(values, linewidth=2)\n",
        "        ax.set_xlabel('Step')\n",
        "        ax.set_ylabel(metric)\n",
        "        ax.set_title(metric)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Visualization utilities ready!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0n5xR30lQNM"
      },
      "source": [
        "## Cell 10: Test Dataset Loading\n",
        "\n",
        "Verify that the dataset loads correctly and visualize some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "l1Ifm5SYlQNM",
        "outputId": "bb87e7ca-caf7-4c6f-bc80-1ac444fe8ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ§ª Testing Dataset Loading\n",
            "======================================================================\n",
            "\n",
            "ğŸ“Š Dataset metadata:\n",
            "  Sequence length: 81\n",
            "  Vocabulary size: 11\n",
            "  Total puzzles: 1000\n",
            "\n",
            "ğŸ“¦ Sample batch:\n",
            "  Set name: all\n",
            "  Batch size: 32\n",
            "  Input shape: torch.Size([32, 81])\n",
            "  Labels shape: torch.Size([32, 81])\n",
            "  Input range: [1, 10]\n",
            "  Labels range: [2, 10]\n",
            "\n",
            "ğŸ¨ Visualizing first example...\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAGNCAYAAAC7a38TAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlldJREFUeJzs3XdUFOfbxvHvItKkGAELKiCoMVbsDQFF0diNDY1GMRpjjTWW+EY0aoyFWLCABWKPigpqVKIG7N1obFGx10Tshebu+wdh4wq2X8LMGO/POZyzOzPsXGyZ+2b3mWd1BoPBgBBCCCGEEEJxZmoHEEIIIYQQ4l0lzbgQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRdCCCGEEEIl0owLIYQQQgihEmnGhRBCCCGEUIk040IIIYQQQqhEmnEhhBBCCCFUIs24EOKd0rlzZ3Q6HRcuXFA7yr8uLi4OnU5HcHDwP7odnU6Hn5/fv5Lpvyo4OBidTkdcXJzaUYQQbzlpxoUQmTx69Ihx48ZRoUIFbG1tsbS0pFChQtSqVYthw4aRkJCgdkTNMhgMLFq0iDp16uDo6IiFhQX58uWjfPny9OzZk/j4eLUjapKfnx86nc74Y2ZmxnvvvUetWrWIjIzEYDCoHVEIIbKFudoBhBDa8uDBA7y9vTl69ChFixalQ4cOODo6cuvWLfbt28f48ePx9PTE09NT7aia1KVLFyIjI3nvvfdo3LgxBQsW5MmTJxw5coR58+Zx//59fH191Y6pWQMHDsTW1panT59y7tw5Vq1axY4dOzh48CDTp09XO54QQvzrpBkXQpiYMmUKR48epWvXroSHh6PT6UzWnz9/nuTkZJXSadv27duJjIzEy8uL+Ph47O3tTdbfvXuXEydOqJTu7TBo0CDy589vvP7bb79RtWpVZsyYwYABAyhSpIiK6YQQ4t8nw1SEECZ2794NQK9evTI14gBFihShRIkSJst++eUXunTpwvvvv4+trS22trZUqlSJ8PDwLPeRMSb56tWrtG/fHicnJ+zs7GjUqBHnzp0D4OTJkzRv3pw8efJgZ2dHq1atuHnzpsntXLhwAZ1OR+fOnTl+/DiNGjUid+7c2NraEhAQwMGDB9/ob9+2bRtNmjTByckJS0tLihUrxogRI3j8+PFr/X7GfdepU6dMjThA7ty5qVGjhsmyjOEZWXnR+PYnT54wdOhQChcujJWVFaVLl2bOnDkvzbZz504aNWpEnjx5sLKyokSJEowcOfK1/zaDwUD//v3R6XR8/PHHpKamvnTcdGRkJDqdjsjIyNe6/RcpU6YMvr6+GAwGDhw4ALz5ffbs8JesfjIyZvzui35edxz90aNHCQwMpECBAlhYWODm5kafPn1ITEz8J3eFEOI/St4ZF0KYcHR0BOD06dN4eXm91u989913nD17lmrVqtGiRQvu3r3Lxo0b6d69O7///juTJ0/O9Dt37tzB29ub/Pnz06lTJ06fPs26des4deoU0dHR1KpVi4oVK9KlSxcOHjxIVFQUt2/fZuvWrZlu69y5c9SsWZMKFSrQo0cPLl68yIoVK/Dx8WHr1q1UrVr1lX/DrFmz6NWrF7lz56ZJkybkzZuXAwcOMHbsWH755Rd++eUXLCwsXvu+yy56vZ6mTZuyefNmypQpQ/v27UlMTKR///7Url07y99ZsWIF7dq1w9LSkrZt25I3b15iY2MZPXo0mzZtIi4uDisrqxfuMzU1lc6dO7NkyRL69etHSEjIC5vh7PS/7nPkyJFZLp81axZ//PEHNjY2ADRv3hx3d/dM2+3evZvY2Fjjdi8TExNDmzZtMDMzo1mzZhQuXJgTJ04QGhrKpk2b2Lt3L++9997/9HcIIf6jDEII8Yzo6GgDYLCzszMMHDjQsGnTJsOtW7de+jvnzp3LtCw1NdVQr149Q44cOQwXL140WQcYAEP//v1Nlvfo0cMAGHLnzm2YMmWKcblerzc0bNjQABgOHjxoXH7+/HnjbQ0dOtTktjZu3GgADGXKlDFZ3qlTJwNgOH/+vHHZ8ePHDebm5oZy5cpl+lu//fZbA2CYNGnSS+8Dg8FguHz5ssHe3t6g0+kM7du3N6xYscJw4cKFl/6Or6+v4UWH4qyyRkREGABDgwYNDGlpacblR48eNVhYWBgAw8iRI43L7927Z3BwcDBYWloajhw5Ylz+9OlTQ9u2bQ2AYfTo0Sb7BQy+vr4Gg8FgePDggSEgIMAAGL799luT7UaOHGkADL/88kum7Bk5IyIiXvr3P38/XL9+3WT5sWPHDNbW1gadTme8H970PsvK+PHjDYChWbNmhqdPn75wu1OnThly585tyJMnj+H06dPG5Vn97bdu3TLY29sbChYsmOlxX7p0qQEw9O7d+6W5hBDvHmnGhRCZTJ482WBra2tsdAGDp6enoVevXiYNyatERUUZAENkZKTJcsBga2trePTokcnybdu2Gfel1+tN1i1YsMAAGObPn29cltGM586d2/DgwYNM+/f39zcAhgMHDhiXZdWs9e3b1wAYtm3bluk2nj59anB2djZUrFjxtf7mn3/+2eDq6mpy3zk7OxvatGlj2LJlS6bt37SxrF27dqZ/SjJ8+umnmZrxjPutR48emba/ePGiwdzc3ODh4WGyPKMZ//PPPw2VK1c25MiRw+R+z5AdzfjAgQMNI0eONIwYMcLw8ccfG6ytrQ2AoW/fvpm2zcrrNONRUVEGnU5nqFChguHhw4cv3O7PP/80eHp6GiwsLAzx8fEm67L620NCQgyAYcGCBVneXoUKFQxOTk4v3J8Q4t0kw1SEEJkMGDCAbt26sXHjRnbt2sWBAwfYu3cvM2bMYN68efz44480bdrUuP2DBw+YNGkSa9asISEhgUePHpnc3rVr1zLto1ixYpk+9i9QoAAAZcuWzTQkIWNdVrdVvnx5bG1tMy2vVasWW7Zs4fDhw1SsWPGFf++ePXsA2LRpE1u2bMm0PmfOnJw6deqFv/+sunXrkpCQQFxcHNu2bePgwYPs2LGD5cuXs3z5coYNG8a4ceNe67aycuTIEXLlykWFChUyratVqxbz5s0zWXb48GGALMc7u7q64uHhwenTp3nw4AF2dnbGdTdv3qRmzZpcvnyZ1atX06RJk/8585vIGNKk0+mwt7enUqVKfPrpp3zyySf/yu0fOHCAjh074uLiwtq1a8mVK1eW2yUnJ9OiRQsSEhKIjIzEx8fnlbed8Tzau3dvltN/JiUlcevWLW7duoWTk9M/+0OEEP8Z0owLIbJkZ2dH69atad26NQD37t1j+PDhzJw5k08//ZSrV69iYWFBSkoKfn5+HDp0iPLly9OxY0ccHR0xNzfnwoUL/PDDD1nOvpLVCY7m5uavXJeampppXb58+bL8GzKW37t376V/6+3btwEYO3bsS7d7Xebm5tStW5e6desCkJaWRmRkJD169ODbb7+lVatWWTbTr+PevXsULlw4y3VZ3Q/3799/4TpI/yfn9OnT3L9/36QZv379Ovfv36do0aKvNeb+33L9+nWT2VT+TZcvX6ZJkybodDrWrl2Li4vLC7f99NNP2bFjB8OHD6dTp06vdfsZz6MZM2a8dLtHjx5JMy6EMJLZVIQQr8XBwYHQ0FDc3Ny4desWv/32GwDR0dEcOnSITz/9lEOHDjFr1izGjBlDcHAwDRo0UCTb87OsPL/cwcHhpb+f0fzfv38fQ/rwvSx//lfm5uZ07dqV9u3bA+mzz2QwM0s/DKelpWX6vaz+iXBwcODPP//Mcj9Z3Q8Zf9uL7qMbN26YbJfBy8uLefPmkZCQQO3atbP8/TfN/m/5X/b74MEDGjduzB9//MGSJUsoX778C29/1KhRLF68mNatWzNmzJjXzpVxH/72228vfR65ubm99m0KIf77pBkXQrw2nU6X6WP9jI/jmzVrlmn77du3K5Lr8OHDPHz48IX7f1njBRjf+c0YZpBdshpKkzGzxtWrV02W6/V6jhw5kmn7cuXK8ejRIw4dOpRpXVb3d8bfntX0g5cvXyYhIQEPDw+Td8UzBAUFERERwalTp7JsyF+UHf4eHpMd3vQ+e/r0KYGBgRw9epSJEyeaDLF63tKlSwkODqZKlSr88MMPbzSDS8bzKGOKSyGEeB3SjAshTISFhbF///4s161Zs4aTJ0+SO3duSpcuDWB8l2/Hjh0m28bHx79y7ut/y927dzMNMckY/126dOmXjhcH6NmzJ+bm5vTp04dLly5lefuv01xu3LiR6OjoLN+xPXv2LCtWrADA29vbuLxy5coAmebjDgkJ4fz585lup2PHjgB89dVXPH361Lj8t99+Y+HChZm2b9asGQ4ODkRERHD8+HHjcoPBwJAhQ0hLS6Nz584v/Js++eQTIiMj+f333/Hz8zO+k/5s9gULFqDX643Ld+/ezeLFi194m//Um95n/fr146effuKzzz5jwIABL7zdXbt2ERQUhKurKzExMVhbW79RrqCgIOzs7Pjqq69M7usMjx8/zvZ/+IQQbx8ZMy6EMLFhwwY+//xzihYtSs2aNXFxceHRo0ccPnyY7du3Y2ZmxsyZM7G0tASgSZMmuLu7M2HCBI4dO0bp0qX5/fffWbduHS1atGDlypXZnrlWrVrMmjWLvXv3Uq1aNS5cuMCKFSuwtrZm7ty5r/z90qVLM3PmTHr06MH7779Pw4YN8fT05MGDB5w7d474+Hg6d+7M7NmzX3o7p06don///jg5OeHj44OnpycGg4GzZ8/y008/kZKSQo8ePUzGYAcFBTFhwgSCg4P59ddf8fT05MCBAxw7dgxfX1/i4+NN9tGpUyeWLFnCxo0bKV++PB9++CG3b99m6dKlBAQEsG7dOpPt7e3tmTNnDu3ataNq1aq0bdsWZ2dnNm/ezMGDB6lSpQqDBw9+6d/VsWNHzMzM6NSpE35+fvzyyy8UKFCAatWqUbNmTbZu3Ur16tXx8fHh4sWLREdH06RJE1avXv3K+/5/8Sb32b59+wgNDcXa2hpnZ2eCg4Mz3V7z5s3x8vKia9euJCcnU6VKFWbNmpVpO3d395f+4+Ls7MzSpUtp3bo15cqVo0GDBpQoUYLk5GQuXLhAfHw8NWrUYOPGjf/G3SCE+K9QfgIXIYSWnTp1yjBhwgRDvXr1DEWKFDFYWVkZrKysDJ6enoZOnTqZTBOY4dy5c4aWLVsanJ2dDTY2NobKlSsbli1bZvjll18yTbVnMJjOY/2sjKkKO3XqlGldVrf17PbHjh0zNGzY0GBvb2/IlSuXoW7dullmfdnUd/v27TMEBgYaXFxcDDlz5jQ4OTkZKlSoYBg6dKjh5MmTr7rrDH/88Ydhzpw5hlatWhnef/99g52dnSFnzpyGAgUKGBo3bmxYuXJllr/366+/Gvz9/Q02NjYGe3t7Q7NmzQxnzpx5YdZHjx4ZvvzyS0PBggUNlpaWhpIlSxrCw8NfeH8bDOnTRn744YeG3LlzGywsLAzFixc3/N///V+WU/u96PFZsmSJIUeOHIb333/fcPXqVYPBkD639ieffGLIkyePwdra2lCtWjXDpk2b/rV5xl/kde+zjPvkZT8ZGd3c3F663bP3ycumdTx16pTh008/Nbi5uRksLCwM7733nqFMmTKGvn37Gvbt2/daf58Q4t2hMxj+wVlJQgihogsXLlCkSBE6der0j792XQghhFCDjBkXQgghhBBCJdKMCyGEEEIIoRJpxoUQQgghhFCJjBkXQgghhBBCJfLOuBBCCCGEECqRZlwIIYQQQgiVSDMuhBBCCCGESqQZF0IIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghNOPChQvodDp0Oh1+fn7Zth8/Pz/jfi5cuJBt+xHiVaQZF9kiODjYeJDr3Lmz2nGyFBkZSXBwMMHBwdy9e1ftOEII8da5cuUK3bp1w93dHQsLCxwcHChatChNmjRh9OjRqmb79ddfjcf4uLg4VbMI8TLmagcQQi2RkZHEx8cD0LlzZ3Lnzq1uICGEeIvcuHGDKlWqcP36deOy1NRU7t+/T0JCAhs2bODrr79WLd+vv/7KqFGjjNeff5d9+vTp3Lt3D4ACBQooGU0IE9KMCyGEEOKNTZ8+3diI+/v706tXL2xtbblw4QL79u1jzZo16gZ8hTJlyqgdQQhAhqkIBT07dCUiIoIpU6ZQtGhRLC0tKVeuHFu3bjXZ/tnxfL/99hu9evXC2dmZXLly0bhxYxISEky2z9jW3d39hbdz4cIF4uLi0Ol0xnfFAYoUKSJjB4UQ4g0cOnTIePn777+nRYsW1KtXj27dujFnzhwuXrxosv2NGzfo27cvnp6eWFpakjt3bvz8/FixYsVr7a9z587G4/Szw04iIyONy4ODgwFwd3cnKCjIuM2oUaMybfOyMeMrV66kdu3a5M6dG0tLSzw8POjdu7fJpwDPZ4qNjeXrr7+mUKFCWFlZUbNmTY4cOfJaf5t4t8k740IVY8aM4dy5c8brR48epXnz5ly8eJH33nsv0/atW7fm999/N15fv349v/76K0eOHMHR0VGRzEIIIf5mZ2dnvDxixAgGDx5MlSpVsLCwAMDGxsa4/vz589SoUYMbN24Yl6WkpBAfH098fDxDhgxh/PjxyoV/iSFDhjBhwgSTZefPn2fGjBlERUWxa9cuihQpkun3evToYVLXdu3aRfPmzTlz5gzm5tJuiReTd8aFKs6dO8eQIUOIiYmhXLlyADx48IAlS5ZkuX1iYiIRERGsWLECDw8PAK5evcq4cePeeN/ly5dn+/bteHl5GZetWLGC7du3s337dhk7KIQQr6Fu3brGyzExMdSqVQs7Ozu8vb2ZPHkyjx49Mq7v2bOnsRH38/MjJiaGkJAQrKysAPjuu+/Yu3fvv5Zt5cqVDB8+3Hg9KCjIeIzv0qXLC39v7969xkbcysqKSZMmERMTQ+3atYH0d/d79uyZ5e9evnyZ7777jlWrVlG4cGEgfWaYTZs2/Vt/lviPkn/VhCqaNWtmfBfk8ePHBAYGAnD27Nkst//222+Ns7Lkzp2bevXqAbBmzRomT578Rvt2cHDA29sbBwcH47JKlSplGt4ihBDixT799FO2bdvG4sWLjctSUlLYuXMnO3fuZNasWezfvx+DwWBsSC0tLVm5cqXxE82rV68aj+FLly6latWq/0q2SpUqcezYMeN1V1dXvL29X/l7z74h1KtXLwYOHAhA9erVKVSoEMnJyWzatInbt2+TJ08ek9/t2bMnX375JQCnT59m6NChwIvrmhAZ5J1xoQpfX1/j5WeHmbxoisFnD9BVqlQxXr5w4QIGg+HfDyiEEOKlcuTIwaJFi9izZw8DBw6kfPnymJn93VYkJCQwceJEzpw5YzxOe3p6mhzznz2enz59WrnwL/BshmfrjpOTk/FTWYPBkGWD/aZ1TYgM0owLVTw7LvzZsXSv01jrdLqXrn/69KnJ9Vu3br1hOiGEEK+ratWqTJo0iUOHDnHt2jU++ugj47pnT/LMyquO5y/a9tnjvFLH+Fdl/Sd1TbzbpBkXb4V9+/YZLz87rtDd3d14gMwYdpKYmEhqaiqQ/s75qVOnsrzNZ9/B0ev1/3pmIYT4L9u2bRsPHz40WZYvXz46depkvP706VOKFi1qPE4nJCSQmJhoXP/s8bx48eIv3d+zQwufPRF048aNWW7/vxzjn83wbN1JTEw0zuCl0+koWrToa92eEK9DxoyLt8KwYcMwNzcnV65cDBs2zLi8WbNmxstFixbl4MGDPHnyhPbt2+Pj48PMmTMzvVOe4dl3MebMmUPDhg2xtramUqVK2feHCCHEf0R4eDjr16+ndevW+Pr64uLiws2bN01OrK9cuTKOjo7Ur1+fjRs3kpycTJs2bejfvz8JCQnMnDnTuG27du1eur9nG+ARI0Zw9+5ddu3axZYtW7Lc/tlj/MaNG/Hx8cHKyooyZcqYNPbPateuHdOmTQMgNDQUFxcXihUrxpQpU0hOTgagfv36mcaLC/FPSDMu3goFChQwnsD57LJnG/PPPvuM7t27A+ln0q9cuRJbW1sKFSrElStXMt1m7dq1WbVqFQDjx49n/PjxuLm5yTzjQgjxmu7evcucOXOYM2dOpnX58+enb9++AMyYMYOaNWty48YNtm7dmul7JYYMGfLKkzfbtWvHsGHDePjwIRcuXKB3794AfPDBB5w8eTLT9tWrV8fS0pLk5GT2799vPPH/l19+yfRtnBmqVavGl19+yYQJE0hKSmLAgAGZ/qZn/4EQ4t8gw1TEW2Hp0qX07dsXZ2dnrK2t+fDDD9m2bRvOzs7Gbbp27cqwYcPImzcv1tbW1KlTh+3bt+Pp6ZnlbXbv3p0hQ4bg6upq8nGmEEKIVxs5ciQTJkwgICAAT09PcuXKhYWFBZ6envTo0YMDBw6QP39+ADw8PDh06BC9e/emSJEi5MyZE3t7e3x8fPjxxx9fa45xR0dH1qxZQ9myZY37mTFjhnEGk+c5OTmxZs0aypcvj7W19Wv/Xd999x3Lly/H19cXe3t7cubMibu7O7169eLQoUNZzjEuxD+hM8iZBUKj/Pz8jN+Sef78eZl6UAghhBD/OfJ2oBBCCCGEECqRZlwIIYQQQgiVSDMuhBBCCCGESmTMuBBCCCGEECqRd8aFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVTy2t/AqdPpsjOHEEK8leS0m3RSI4QQwtTr1ofXbsYBzMzMyJe/wP8U6N/25PEjrG1yqR3DxJPHj8iVSzuZ/vjjD/Lmzat2DKNHj7T5mGkp059//IGzhh4zrd0/WnuNXb9+Xe0ImiI14sW09tzVWn0A7dUIrT2HtFYfQHv3kZZeZ29SH96oGc+XvwAHf7/yxoGyw6qFYXzUsbvaMUzELA6je3ftZCpXrhxHjhxRO4bRzNlhtOignfsHtPc8CqhRjthd2nnMtHb/aO01VqhQIbUjaIrUiBfT2nNXa/UBtFcjtPYc0lp9AO3dR1p6nb1JfZAx40IIIYQQQqhEmnEhhBBCCCFUIs24EEIIIYQQKpFmXAghhBBCCJVIMy6EEEIIIYRKpBkXQgghhBBCJdKMCyGEEEIIoRJpxlWWkpLCrFmzqFOnDnnz5iVnzpxYWVnh5ubGRx99xNq1axXNk5SUxPDhwwkICMDd3R07Ozty5syJk5MTNWrUYOzYsdy7d0/RTEL8Ww4fPkyXLl3w9PTE2toae3t7ihYtSmBgILGxsWrHe+dcv3aVOTOmENgsgEofuOKWx4Jynvnp+nFLDu3fq0qmqGWL+LJvdxr4VMLd0RIXOx0/LopUJQtoq0a8TfUhNOQ7XOx0uNjpOLhvj6L71uv1zA8LJcC7Ah55bSjuYk+L+j5sWh+jaI4MPy6KNN4XL/pp09hf0UxVSrm/MEvLD/0UzfIstWrEG33pj/h3paWlUb9+feLi4jItv3TpEpcuXWL16tUMHz6csWPHKpLp4cOHfPvtt5mWJyYmsnv3bnbv3k1ERAT79u0jT548imQS4t8watQoRo0aZfL1xElJSTx48ICEhARsbW0JCAhQMeG7Z/7s6cz4/jvcPTzxrROAo5Mz5xPOsHHdGjauW8OM+Uto1rKtopm++2YEVy5dJI+jE3nzF+DKpYuK7v9ZWqsRb0t9OHXiGJPHjcQmVy4eP3qk6L4NBgPdP2nD+ugo3D08affJp6QkJ7NpfTRBgc0YM2k6Xbr3VjRTqbJeDBg2Mst169es5PeTx/H1r69oJgB7Bwe69uyXaXlhV3fFs4C6NUKacRWtXr3a5CBboUIFmjdvzt27d5k3b57xHYYJEybw5Zdf4uDgoEiuggULUqNGDdzc3MiTJw+3bt0iKiqKixfTi1JCQgLh4eEMHTpUkTxC/FOzZs0iODjYeL169erUqFGDPHnycPv2bU6ePImTk5N6Ad9R5StWIWpDHNW9fU2W7925nTZN/BnWvwcNGjfH0tJSsUyTQufi4VmMQq5uTJ88nm+Dhym27+dpsUZovT6kpqbyRfdOlCrjRZGixYhatkjR/a+PjmJ9dBSVq9VkWczPWFtbAzB05Dg+9K3EN18Nol6DxhR2c1csU+myXpQu65VpeUpKChFhoZibm9Pm406K5clg75CbQcODFd9vVtSuEdKMqyghIcHkemxsLI6OjgC4uLgwaNAgIP1dkLt37ypyoHVycuLKlcxfZz1gwACTr3bNOPAKoXX37983aQxmz56tma9Lftc1bPZRlsur1qxFDZ/axG+J5dTx3yhXoZJimXxq11VsX6+itRrxNtSHqRPHcvrkcTbtOMTM7ycovv9N66MB6DtouLERB3B0cuKzXv35ekg/li2KYPBXoxTP9ryN69Zw53YiDRo3xzlvPrXjqEYLNULGjKuoZMmSJteXL1/OkydPuH79Ops3bzYu/+CDD3B1dVU6HgBPnz7l6tWrzJkzx2R5qVKlVMkjxJuKiori/v37ABQqVIirV69SpkwZbGxscHJyonnz5uzdq874ZPFiOc1zApDD/N19z0jrNUJr9eHor4eYNnEsA4aOpHiJkq/+hWzwx80bALi6Fcm0rvBfy3bGb1U004ss+WEuAO07dVVl/ynJyfy4KJJpE8cxPyxUvfNENFAj3t2jnAY0adKE5s2bs2bNGgB69uxJz549TbapU6cOc+bMQafTKZpt8+bN1KtXL8t1Pj4+dO2qzotXiDe1a9cu4+UrV67wzTffGK8/efKE6Oho1q9fz+LFi2nTpo0aEcVzrly+xPa4zeTLX4APSpVRO45qtFojtFgfkpOT+eKzTyhV1oue/b9UfP8Z8jimD2W4dPE8xUp8YLLu8sXzAJw7e1rxXM+7cukiO+K2UKBgIWrXa6BKhj9u3qB/jyCTZV4VKzNz/lLcPTwVy6GFGiHvjKtIp9OxatUq/u///i/LA6mbmxsdOnTAw8NDhXRZa9++PevXr8fKykrtKEK8luvXr5tct7S0pHfv3gwePNj4sX5aWhpdu3YlMTFRjYjiGampqfTt1pHk5GS+Gv0dOXLkUDuSat62GqFmfZg45mvOJ5zh+1kRqj5n6tT7EIDQkPEkJSUZl99OTGTOzCkA3L93V4VkppYtikCv19P2486q3F9tOwSxfN0Wjp67ydmbj4jdeZhW7Try68H9tGniz8MHDxTLooUaIe+Mqyg1NZVPPvmEZcuWAekfSbZq1Yrbt28zf/58Ll68SJcuXTh8+DDTpk1TNFvx4sWZOHEiycnJXLx4kVWrVpGYmMiSJUs4dOgQGzduxM3NTdFMQvwvUlJSTK5PnDiRPn36AFCrVi2aNm0KwIMHD4iJiSEoKCjTbQhl6PV6+n3emT07t/Fx5260atdR7Uiq0mqN0Fp9OLB3N7OnTWLg8GBKlCyt2H6z0qJNe5YvjmTntl/wr1YGv7oNSEtNZeO6NcZx2WZm6r4Pqtfr+XFRBDqdjsCOXVTJMPC52V1Kl/ViWvgCAFYuXcjiyDl07zNAkSxaqBHyzriKwsLCjAfZ3Llzs2vXLkaNGsX06dOZNWuWcbvQ0FBOn1b2Yy1XV1cGDRrEV199RXh4OCdOnKBAgQIAnDp1in79+imaR4j/Ve7cuU2u+/n5ZXkZMp8wJ5Sj1+sZ0KMLq5cvoWVgB76bOlvtSKrTao3QUn1IS0ujX/dOfFC6LL0HqD/Dl7m5OYtWbWDg8GB0OjMWR4TzU8wq6jdqRvjClQA4OudVNeO2XzZz9fIlavrWwdU989h2NXUISj9xcv+enYrtUws1QppxFW3ZssV4uXjx4iZnwleq9PfsAQaDgaNHjyqa7Xl58+alWrVqxuvPz3srhFaVLv3id8qenU8WkOFXKtHr9fT/PIjlS36geet2TJkdqfq7h1rwttQINevDo4cPOZdwhuNHf8Utj4XJl8csX/IDAE38q+Nip2PD2jWKZLK0tGTgsJHsOPw7FxKT+e38H0yYFsaN61cBKFdeudmBsrJU5RM3XyZjzP3jx8rND6+FGiHDVFT09OlT4+XTp09z794948H2wIEDJts+O0VSdvrll1+oVKkSdnZ2Jstv3bplcjax0ieUCvG/atSoESNH/v2RaHx8PGXKpJ8UuG3bNpNtn21whDIyGvEVSxfQtGVbps9Z+E6PE3+W1mqEFuuDhaUl7T75NMt1e3du41zCGQIaNsXRyVnRub2zsurHxQA0axWoWobbiYlsWh/Ne+/l4cMmLVTL8SKHD6Q/j5T84h8t1AhpxlXk5+dn/Crju3fvUqNGDVq1asWdO3eYP3++cbtcuXJRs2ZNRTJNnTqVn3/+GX9/f8qWLYuNjQ1Xr14lKiqKmzdvGrdr3LixInmE+KcqVqxI/fr12bRpEwCDBw/mzJkzWFlZmUzJVqJEiRfOECGyR8bQlBVLF9CkRWtC5y6SRvwZWqsRWqwP1tbWTJ4xN8t1/bp35lzCGfoMHEbFKtWy3CY7PLh/Hzt7e5Nl69asZNnC+XhVrEzDplnPr6+EqGULSUlJoeOnHRT9Mq1nnfn9FAULu2JjY5Np+divhwDQonV7xfJooUZIM66iHj16sGLFCvbs2QPAiRMnGD16tMk2ZmZmTJ8+PdOYpuz0+PFj1q5daywCz/Py8mLy5MmK5RHin4qIiMDf35+TJ0+SlJSU6WS3/Pnzs3LlSmkEFRYyfjTLl/xALltbPIoWZ8qEMZm2adC4eZbfHphdFkfOZf/uHQCcPPEbkD4f8+7tcQBUru7Nx52V+XhfizVC6sOrNapdFZdChSn2/gdYWlrx68F97Noeh1sRD8IXrFD1OLN0wTxA3SEq0VHLCA8NoVoNHwq6umFjk4tzZ0+zNfYnUlNT6TNwGNW8fRTNpHaNkGZcRdbW1sTHxzNnzhxWrlzJsWPHuHv3Lubm5ri4uFCzZk369OlD5cqVFcvUq1cv8ufPz969e7l27Rq3b9/G3NycfPnyUbZsWVq0aEGHDh3ImTOnYpmE+KcKFCjAvn37mDJlCitXruTs2bM8ffoUd3d3mjRpwqBBg8ibV92Tqt5FVy5eANLH/U6dODbLbQq7uivajO/fvcM41ti4bM9OkxPKlGrGtVYjpD68nqYt27IhZhWH9u8hLTWVwm5F6PflCHp8MTjTO+ZKOnxgH6dOHKN8pSqqzt9f06c2Z34/yfEjh9m7eztPHj8mj6MTdQIa0qlbT/z8AxTPpHaNkGZcZRYWFvTq1YtevXqpHQWAevXqyUf14j/J1taWESNGMGLECLWjiL9MCYtkSlik2jFMaC2TlmrE21Yf1HosBw0PZtDwYMX3+yrlK1Xh2gPDqzfMZtW9fanu7at2jEzUrBFyuroQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRdCCCGEEEIl0owLIYQQQgihEmnGhRBCCCGEUIk040IIIYQQQqhEmnEhhBBCCCFUIs24EEIIIYQQKpFmXAghhBBCCJVIMy6EEEIIIYRKpBkXQgghhBBCJTqDwWB4rQ11OnLnzs2YceOzO9NrSU1+grW1tdoxTDx6/AQrDWWaETqdXr37qB3DKOnJEyyttHP/gPaeR9OnT6dPH+08Zo8ea+sxS07S1mvsq2FDuXPnjtoxNEFqxMtJfXg1rdUIrT2HtFYfQGrEy7xJfXijZryAS0EO/n7lH4X7t8QsDqN79+5qxzAxc3YYLTpoJ1NAjXLE7jqidgyjVQvD+Kijdu4f0N7zqFy5chw5op3HTGvPaa09hyq+X4hrV7VxTFSb1IiX09prSWv1AbT3+tbac0hr9QG097zW0nPoTeqDDFMRQgghhBBCJdKMCyGEEEIIoRJpxoUQQgghhFCJNONCCCGEEEKoRJpxIYQQQgghVCLNuBBCCCGEECqRZlwIIYQQQgiVvHPNuMFgYPHixdStWxdHR0csLCxwcXGhdevW7N69W+14QuOuXr3KrFmzCAwMpEyZMjg7O5MzZ06cnZ2pW7cuCxYs4DWn7s9WzZo1Q6fTGX/8/PzUjiTES22IWU3bpvUo5epIEScrqpYuQo+gdly9clmxDFqsDz8uisTFTvfSnzaN/RXNZDAY+Cl6Fa0a1saraAE88trgXf59vuzbnYvnzymaBaBKKfcX3jctP/RTNIvUiNcTtWwRX/btTgOfSrg7WuJip+PHRZGKZsiQlJRE8NABtKjvQ/liLhRxsqKcZ36a1q3JsoURpKamZnsG82zfg4akpaXRpk0bVq9ebbL8+vXrrFy5kqioKKZOnaq5b7gS2rFw4UKGDRuWafmtW7fYsmULW7ZsYeXKlaxevZocOXKokDA9Y0xMjCr7FuJNGQwGhnzxOYsiwnH38KRpq0Bsbe24eeMau3fEc+XSRQoWKpztObRaH0qV9WLAsJFZrlu/ZiW/nzyOr399RTONHj6IsNAQ8uUvQIPGzbG1s+fEsSMsjpzDmpVLidm8ixIlSyuayd7Bga49+2VaXtjVXdEcUiNez3ffjODKpYvkcXQib/4CXLl0UbUsjx4+ZMG8WXhVrIJ//UY4Ojlz7+4dtv68gQE9uxAdtYzFqzZgZpZ971+/U814SEiIyYG2cePGVK5cmW3btrFlyxYMBgP9+vWjSpUqVK1aVcWkQuvy589Pw4YN8fDw4MKFCyxatIikpCQA1q5dS0REBF27dlU817Vr1/jiiy8U368Q/6t5s6axKCKcTt16MmbitEwNSlpamiI5tFofSpf1onRZr0zLU1JSiAgLxdzcnDYfd1Iszx83bzBn5hQKubqxedcR7B0cjOvCQ78neNgAwqaH8P2s+YplArB3yM2g4cGK7vNlpEa83KTQuXh4FqOQqxvTJ4/n2+DM/8Ao5b08eTh19R4WFhYmy9PS0ghsWo/4LbFsjd1A3QaNsi3DO9WMR0REGC97e3uzdu1aAPR6PWXKlOHEiRPo9XrGjRtHdHS0WjGFhrm6urJw4UICAwMxN//75dO+fXvq1KljvL5hwwZVDrTdu3fnzp07uLq64ujoyOHDhxXPIMTrevLkCSHjR+FWxINvJkzN8p3CZ19n2eltqw8b163hzu1EGjRujnPefIrt9/LFC+j1eipXq2nSiAPUbdCY4GEDSLz1p2J5tEZqxOvxqV1Xlf1mxczMLFMjDunHngZNWrBrexwXzp3N1gzvVDN+7tzfY9nKlStnvGxmZkbp0qU5ceIEALGxsaSlpSlWBMTbo3379lkur127No6OjiQmJgLp71opLTIyknXr1qHT6Zg/fz7ffPON4hmEeBPxW2K5e+cObT8O4unTp8SujyHh7Gkccuemll9dingWVSzL21YflvwwF4D2nZRt6Ip4FsPCwoL9e3by4P597Oztjes2b1wHQC0/ZcewA6QkJ/PjokhuXr+Grb09XhUqU6Gy8p9wS43479Dr9cRt3gjA+9k87Oqd6jYdHBz488/0/9h/++0343KDwcDx48eN15OSkjh79iwlSpRQPKN4O924cYN79+4Zr1epUkXR/V+9epX+/fsD8Pnnn+Pv7y8HWqF5R389CIBZjhz4VyvLubOnjevMzMzo1qs/I8dNUiTL21Qfrly6yI64LRQoWIja9Roouu88jo4MHzWeUcMH4lOxBPUbNTOOGd8Zv5VO3XoS1L23opkgffhM/x5BJsu8KlZm5vyluHt4Kp7neVIjtC8lJYVpk8ZhMBi4czuRHXFbOHv6FG07BGX7P5jvVDPepEkT5s9PH8e2bds2mjVrRqVKldi+fbvJwRbgzp07akQUb6G0tDQ+++wz49jWvHnz8vnnnyuaoVu3bty9e5ciRYowYcIERfctxP8q8c8/AAgPDaGMVwV+ittHsfc/4NiRwwzu+xlh0yfj7uFJp649sj3L21Qfli2KQK/X0/bjzqqcBPhZ7/7kdynIoN5dWTBvtnF5leretGjdXvFPDdp2CKJqjVqUKFkam1y2nDt7mvDQEFYuXUibJv5s3fMbtnZ2imZ6ltSIt0NqSgoh344yXtfpdHzedxDDR32b7ft+p6Y2HDduHB4eHsbrMTExfP311/z888+Zts1q/JAQz3vw4AFNmzY1ji+1s7MjJiYGZ2dnxTLMnz+fDRs2oNPpiIiIwNbWVrF9C/FP6PV6AHJaWDB/6Rq8KlYml60tVWvWInzhCszMzAibPlmRLG9LfdDr9fy4KAKdTkdgxy6qZAgZP5o+XTvQZ+BwDpy6zJnrD1i9aTvJyUm0aujHpvXKztQxcNhIvH3r4OScFxsbG0qX9WJa+AJatevIlUsXWRw5R9E8z5Ia8fbIZWvLtQcGrtx7yoFTlxkXMoOlC+bS8kM/Hty/n637fqea8Xz58nHgwAEGDx5MsWLp497y5ctHo0aNGDJkiMm2Li4uKqUUb4vLly/j7e3Nhg0bAHB2dmbLli2KzrSQlJTEgAEDAOjduze+vr6K7VuIf8rOPv0EwHLlK5G/gOkxt0TJ0rgV8eDCuQTu3b2b7Vnelvqw7ZfNXL18iZq+dXB1L6LK/ieNHUnQZ73pM3AoLgULpf8DVcObH5avxTxnTkZ/NVDxXFnpENQdgP17dqqyf6kRbyczMzNcChaiU9ceTJgWzv49O5k6cWz27jNbb12D3nvvPSZMmMDp06dJTk7mxo0brFu3jocPHxq3cXNzo0CBAiqmFFp34MABqlatytGjRwEoXrw4u3fvpnLlyormSEpKMo5DnD59usmXOMTHxxu3i4+Ply//EZrjWex9IH1auqxkLE9KeqJInrehPixV6cTNDL/EpjeWNXxqZ1qXN19+ihYvwfmEszx65j5TSx5HJwAeP36k+L6lRvw3+NYJAGD3jrhs3c871Yzr9XruZvEOy/bt2wkPDzdeDwoKyrSNEBlWr16Nr68v169fB6BWrVrs3r0bT0/1TxIS4m1S86+G7uzpk5nWpaamcuHcWWxy5cLRKfs/0n8b6sPtxEQ2rY/mvffy8GGTFqpkSElNnwXkRdMXJt76EzMzM8xz5lQyVpYOH9gLKP/FP1Ij/jtuXr8GgLl59j6f36kTOB8/fkz+/PkJCAigZMmSWFpa8ttvvxEdHW0cu+jh4WE841iI561YsYLAwEDj88XBwYH69esbT/zK4ODgQLdu3bI9j4WFBS1btsxyXXx8PLdu3QLAyckJX19fSpUqle2ZhHhd7h6e+PoHEL8llsWRc/m489/v9oaGjOfe3bu0DOygyAmBb0N9iFq2kJSUFDp+2gFLS0tVMlSuVpOIsFDCQ0No1KylyVzjC+bN5vrVK1SuVlOxfGd+P0XBwq7Y2NhkWj726/ThRS1aZz3dYHaQGvH2OX3qBIVc3TM9hx4/fkzw8PQhPv4BDbM1wzvVjAMkJyezdu1a48kUz/L09OSnn37C/pl5U4V41vHjx40HWYB79+4xYsSITNu5ubkpcqC1sbFh5cqVWa7z8/MzfgxZqlSpF24nhJq+DZlJ07o1GNynG5vWrcGzeAmOHz3MjvitFHJ14//GTFQsi9brw9IF8wD1hqgANGnRmgVzZ7Fn5za8yxcnoGFT7B1yc+zIIXbEb8XK2prgb0MUyxMdtYzw0BCq1fChoKsbNja5OHf2NFtjfyI1NZU+A4dRzdtHsTxSI17P4si57N+9A4CTJ9KnEl3yw1x2b48DoHJ1b5N/zrNTzKrlhIeGUKW6N4Vd3bG1s+fG9atsjd3AnduJVK1Ri269s/ef8HeqGbeysmLIkCHEx8dz/vx5bt++ja2tLSVLluSjjz6iR48eWFtbqx1TCCHeGe4enmzYdoCJY74mbvNG4rfG4pwvP50/68WAoV/j5JxXkRxarw+HD+zj1IljlK9UhQ9KlVEtR44cOVgaHUt46PesXb2c1SuWkJqSgnPefLQM7EDfgcMpVuIDxfLU9KnNmd9PcvzIYfbu3s6Tx4/J4+hEnYCGdOrWEz//AMWyiNe3f/cOli/5wXTZnp0mJ9sq1YzXa9CYm9evcWDvLg7u282jhw+xs3egZOmyNGsZSOAnXbL907l3qhk3Nzdn/PjxascQb7Hg4GCCg4PVjvFa4uLi1I4gxGspWKgwU2ZHvHrDbKT1+lC+UhWuPTCoHQMAS0tL+gwcSp+BQ9WOQnVvX6p7a2eGEKkRr2dKWCRTwiJV2/+zylWoRLkKlVTN8E6dwCmEEEIIIYSWSDMuhBBCCCGESqQZF0IIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRdCCCGEEEIl0owLIYQQQgihEp3BYDC81oY6Hblz52bMuPHZnem1JCc9wcraWu0YJpKePMHSSjuZZs6YTs9efdSOYZSa/ARrjT1mjx5r63k0I3Q6vXpr5zFLSdLWY/bosbZeYyOGD+XOnTtqx9AEqREvJ/Xh1bRWI6Q+vJrUiBd7k/rwRs14AZeCHPz9yj8K929ZtTCMjzp2VzuGCa1lCqhRjthdR9SOYRSzOIzu3bVz/wDMnB1Giw7aySSP2ctp7fGq+H4hrl3VxjFRbVIjXk5rebR2rAE53ryKPGavpqXH7E3qgwxTEUIIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRea5ufnh06ne60foQ1Xr15l1qxZBAYGUqZMGZydncmZMyfOzs7UrVuXBQsW8JrfNSbeAVVKueNip8vyp+WHfopmSUpKInjoAFrU96F8MReKOFlRzjM/TevWZNnCCFJTUxXN8yKhId8Z76OD+/Yovv+oZYv4sm93GvhUwt3REhc7HT8uilQ8h9brw4aY1bRtWo9Sro4UcbKiauki9Ahqx9UrlxXPotfrmR8WSoB3BTzy2lDcxZ4W9X3YtD5G0RxarQ8Gg4GfolfRqmFtvIoWwCOvDd7l3+fLvt25eP5ctu/fPNv3IIR4pyxcuJBhw4ZlWn7r1i22bNnCli1bWLlyJatXryZHjhwqJBRaY+/gQNee/TItL+zqrmiORw8fsmDeLLwqVsG/fiMcnZy5d/cOW3/ewICeXYiOWsbiVRswM1PvfaxTJ44xedxIbHLl4vGjR6pk+O6bEVy5dJE8jk7kzV+AK5cuqpJDqwwGA0O++JxFEeG4e3jStFUgtrZ23Lxxjd074rly6SIFCxVWNE/3T9qwPjoKdw9P2n3yKSnJyWxaH01QYDPGTJpOl+69Fcmi1fowevggwkJDyJe/AA0aN8fWzp4Tx46wOHIOa1YuJWbzLkqULJ1t+5dmXGhajx49aNy4cablaWlp/N///R9paWkAfPjhh0pHE6+QP39+GjZsiIeHBxcuXGDRokUkJSUBsHbtWiIiIujatavKKYUW2DvkZtDwYLVj8F6ePJy6eg8LCwuT5WlpaQQ2rUf8lli2xm6gboNGquRLTU3li+6dKFXGiyJFixG1bJEqOSaFzsXDsxiFXN2YPnk83wZnbq6UoNX6MG/WNBZFhNOpW0/GTJyWqanMyKWU9dFRrI+OonK1miyL+Rlra2sAho4cx4e+lfjmq0HUa9CYwm7uimXSUn344+YN5sycQiFXNzbvOoK9g4NxXXjo9wQPG0DY9BC+nzU/2zJIMy40rW3btlkuX7JkickB7csvv1QqkngFV1dXFi5cSGBgIObmfx9i2rdvT506dYzXN2zYIM240BQzM7NMjTiAubk5DZq0YNf2OC6cO6t8sL9MnTiW0yePs2nHIWZ+P0G1HD6166q272dpsT48efKEkPGjcCviwTcTpmb57u6zx0UlbFofDUDfQcONjTiAo5MTn/Xqz9dD+rFsUQSDvxqV7Vm0WB8uX7yAXq+ncrWaJo04QN0GjQkeNoDEW39mawZpxsVbadKkScbLlSpVws/PT70wwkT79u2zXF67dm0cHR1JTEwEICUlRclYQsNSkpP5cVEkN69fw9beHq8KlalQuarasYz0ej1xmzcC8H42flT9Mkd/PcS0iWMZ/NVoipcoqUqGt4Wa9SF+Syx379yh7cdBPH36lNj1MSScPY1D7tzU8qtLEc+iimXJ8MfNGwC4uhXJtK7wX8t2xm9VpBnXYn0o4lkMCwsL9u/ZyYP797Gztzeu27xxHQC1/PyzNYM04+Kts3nzZg4fPmy8Lu+Kvx1u3LjBvXv3jNerVKmiYhqhJX/cvEH/HkEmy7wqVmbm/KW4e3gqniclJYVpk8ZhMBi4czuRHXFbOHv6FG07BGV7Uc5KcnIyX3z2CaXKetGzvxzvXkbt+nD014MAmOXIgX+1spw7e9q4zszMjG69+jNy3KQX/Xq2yOPoBMCli+cpVuIDk3WXL54HMMmpBjXrQx5HR4aPGs+o4QPxqViC+o2aGceM74zfSqduPQnK5jH10oyLt87EiRONlz08PPjoo49UTCNeR1paGp999pnxo+O8efPy+eefq5xKaEHbDkFUrVGLEiVLY5PLlnNnTxMeGsLKpQtp08SfrXt+w9bOTtFMqSkphHz797uEOp2Oz/sOYviobxXNkWHimK85n3CGjdsPyknPr6B2fUj88w8AwkNDKONVgZ/i9lHs/Q84duQwg/t+Rtj0ybh7eNKpaw/FMtWp9yHRK5cRGjKemr51sLKyAuB2YiJzZk4B4P69u4rleZ4W6sNnvfuT36Ugg3p3ZcG82cblVap706J1+2wfWiRTG4q3ytGjR4mNjTVeHzBggBQnjXvw4AFNmzZl7dq1ANjZ2RETE4Ozs7PKyYQWDBw2Em/fOjg558XGxobSZb2YFr6AVu06cuXSRRZHzlE8Uy5bW649MHDl3lMOnLrMuJAZLF0wl5Yf+vHg/n1FsxzYu5vZ0ybxxZcjsnU2h/8CLdQHvV4PQE4LC+YvXYNXxcrksrWlas1ahC9cgZmZGWHTJyuaqUWb9tT0qc3eXdvxr1aGrwb1YcgXn1O7Sins7NKHZKg1Q5BW6kPI+NH06dqBPgOHc+DUZc5cf8DqTdtJTk6iVUO/bJ8CUppx8VZ5diygk5MTXbp0UTGNeJXLly/j7e3Nhg0bAHB2dmbLli1Uraqd8cBCmzoEdQdg/56dqmUwMzPDpWAhOnXtwYRp4ezfs5OpE8cqtv+0tDT6de/EB6XL0nvAUMX2+7bSQn2ws08/AbBc+UrkL+Bisq5EydK4FfHgwrkE7t29q1gmc3NzFq3awMDhweh0ZiyOCOenmFXUb9SM8IUrAXB0zqtYngxaqQ/bftnMpLEjCfqsN30GDsWlYKH0f6BqePPD8rWY58zJ6K8GZmsGGaYi3hpXrlxh2bJlxuu9evUyOTNcaMuBAwdo2rQp169fB6B48eL89NNPeHoqPwZYvH0yxrk+fqzOXNrP860TAMDuHXGK7fPRw4ecSzgDgFuezLO8ADTxrw7AvCWr+bBJc6WiaY5W6oNnsfeB9Ok6s5KxPCnpCQ5kvU12sLS0ZOCwkQwcNtJk+a7tcUD6Pw9K0lJ9+CU2/Z+BGj61M63Lmy8/RYuX4NiRwzx6+JBctrbZkkGacfHWmDJlivEb8KytrendW5kvKRBvbvXq1XTo0IHHjx8DUKtWLdasWUOePHlUTibeFocP7AWU/+KfF7l5/RoA5uY5FdunhaUl7T75NMt1e3du41zCGQIaNsXRyVnROaK1SCv1oeZfDd3Z0yczrUtNTeXCubPY5MqFo5M2humt+nExAM1aBSq2T63Vh5TU9JlbXjR9YeKtPzEzM8M8Z/a99qUZF2+F+/fvM2fO32NHg4KCcHJyUjGReJEVK1YQGBhoHDvp4OBA/fr1mT/f9AsTHBwc6NatmxoRhUac+f0UBQu7YmNjk2n52K+HANCiddZToWWH06dOUMjVPVOex48fEzx8AAD+AQ0Vy2Ntbc3kGXOzXNeve2fOJZyhz8BhVKxSTbFMWqSl+uDu4YmvfwDxW2JZHDmXjzv/PVd2aMh47t29S8vADorPNf78lH0A69asZNnC+XhVrEzDpsqc6KrF+lC5Wk0iwkIJDw2hUbOWJnONL5g3m+tXr1C5Wk0sLS2zLYM04+KtEBYWxv2/TpzKkSMHAwdm7/gt8b87fvy48UALcO/ePUaMGJFpOzc3N2nG33HRUcsIDw2hWg0fCrq6YWOTi3NnT7M19idSU1PpM3AY1bx9FMsTs2o54aEhVKnuTWFXd2zt7Llx/SpbYzdw53YiVWvUolvv/orl0arFkXPZv3sHACdP/AbAkh/msnt7HACVq3ubNKHZTWv14duQmTStW4PBfbqxad0aPIuX4PjRw+yI30ohVzf+b8zEV9/Iv6xR7aq4FCpMsfc/wNLSil8P7mPX9jjcingQvmCFYie6arE+NGnRmgVzZ7Fn5za8yxcnoGFT7B1yc+zIIXbEb8XK2prgb0OyNYM040LzUlNTmTp1qvH6Rx99hIeHh4qJhBD/hpo+tTnz+0mOHznM3t3befL4MXkcnagT0JBO3Xri5x+gaJ56DRpz8/o1DuzdxcF9u3n08CF29g6ULF2WZi0DCfyki+LvaGrR/t07WL7kB9Nle3aanGyrVDOuxfrg7uHJhm0HmDjma+I2byR+ayzO+fLT+bNeDBj6NU4qnCzZtGVbNsSs4tD+PaSlplLYrQj9vhxBjy8GZ3rH/F2TI0cOlkbHEh76PWtXL2f1iiWkpqTgnDcfLQM70Hfg8Ezzs//b5KgiNC9nzpxcuXJF7RjiNQUHBxMcHKx2DPEWqO7tS3VvX7VjGJWrUIlyFZQ9ke1/NSUskilhke/cvp+n1fpQsFBhpsyOUDuG0aDhwQwaHqx2DM3WB0tLS/oMHEqfgerMWiRTGwohhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRdCCCGEEEIl0owLIYQQQgihEmnGhRBCCCGEUIk040IIIYQQQqhEZzAYDK+1oU6Hubk5JT4omd2ZXote/xQzsxxqxzBh0D8lRw7tZDp//jxFihRRO4ZR2tOn5NDYY/ZUY8+jCxfO4+6uncdMr9fWY6bX2Gvs5MmTpKSkqB1DE6RGvJzUh1fTWo2Q+vBqUiNe7E3qg/mb3LBz3nzE7jryP4X6t61aGMZHHburHcNEzOIwunfXTqZy5cpx5Ig2Hi+AmbPDaNFBO/cPaO95FFCjnGZeY6C9+0drr7FChQqpHUFTpEa8mNaeu1qrD6C9GqG155DW6gNo7z7S0uvsTeqDDFMRQgghhBBCJdKMCyGEEEIIoRJpxoUQQgghhFCJNONCCCGEEEKoRJpxIYQQQgghVCLNuBBCCCGEECqRZlwIIYQQQgiVSDMuhBBCCCGESqQZ1wB3d3d0Ot1Lf3bs2KF4rsOHD9OlSxc8PT2xtrbG3t6eokWLEhgYSGxsrOJ5hPhfrVixgs8//5xKlSphaWlp8toS6klKSiJ46ABa1PehfDEXijhZUc4zP03r1mTZwghSU1MVzfPjokhc7HQv/WnT2F/RTFIfXs1gMPBT9CpaNayNV9ECeOS1wbv8+3zZtzsXz59TNMuLhIZ8Z3wOHdy3R9F9X792lTkzphDYLIBKH7jilseCcp756fpxSw7t36tolgx6vZ75YaEEeFfAI68NxV3saVHfh03rYxTPooX68EbfwCneHaNGjWLUqFEYDAbjsqSkJB48eEBCQgK2trYEBASomFCI1zd27FjNfduggEcPH7Jg3iy8KlbBv34jHJ2cuXf3Dlt/3sCAnl2IjlrG4lUbMDNT5n2jUmW9GDBsZJbr1q9Zye8nj+PrX1+RLFqmtfowevggwkJDyJe/AA0aN8fWzp4Tx46wOHIOa1YuJWbzLkqULK1YnuedOnGMyeNGYpMrF48fPVJ8//NnT2fG99/h7uGJb50AHJ2cOZ9who3r1rBx3RpmzF9Cs5ZtFctjMBjo/kkb1kdH4e7hSbtPPiUlOZlN66MJCmzGmEnT6dK9t2J5tFAfpBnXmIkTJ2a5vEiRIoplmDVrFsHBwcbr1atXp0aNGuTJk4fbt29z8uRJnJycFMsjxD+l0+nw9PSkUqVK3Lhxg/j4eLUjCeC9PHk4dfUeFhYWJsvT0tIIbFqP+C2xbI3dQN0GjRTJU7qsF6XLemVanpKSQkRYKObm5rT5uJMiWbIi9SGzP27eYM7MKRRydWPzriPYOzgY14WHfk/wsAGETQ/h+1nzFcv0rNTUVL7o3olSZbwoUrQYUcsWKZ6hfMUqRG2Io7q3r8nyvTu306aJP8P696BB4+ZYWloqkmd9dBTro6OoXK0my2J+xtraGoChI8fxoW8lvvlqEPUaNKawm7siebRQH6QZ15hBgwapuv/79+8zdOhQ4/XZs2fTvXt3FRMJ8c/t2rXLeMAPDg6WZlwjzMzMMjXiAObm5jRo0oJd2+O4cO6s8sGes3HdGu7cTqRB4+Y4582nWg6pD5ldvngBvV5P5Wo1TRpxgLoNGhM8bACJt/5UKR1MnTiW0yePs2nHIWZ+P0GVDA2bfZTl8qo1a1HDpzbxW2I5dfw3ylWopEieTeujAeg7aLjxuAzg6OTEZ7368/WQfixbFMHgr0YpkkcL9UHGjGuMp6cnFhYW2NvbU6VKFcaPH8/jx48V239UVBT3798HoFChQly9epUyZcpgY2ODk5MTzZs3Z+9edcaYCfG/evaAL7RPr9cTt3kjAO+rOLwgw5If5gLQvlNXVXNIfcisiGcxLCws2L9nJw/+ypZh88Z1ANTyU3acf4ajvx5i2sSxDBg6kuIlSqqS4VVymucEIIe5cu/N/nHzBgCubpk/0Sn817Kd8VsVy6OF+iDvjGvMuXPpJ5ukpqayf/9+9u/fz8KFC4mLi8PZ2Tnb979r1y7j5StXrvDNN98Yrz958oTo6GjWr1/P4sWLadOmTbbnEUL896WkpDBt0jgMBgN3bieyI24LZ0+fom2HINUaqQxXLl1kR9wWChQsRO16DVTNIvUhszyOjgwfNZ5RwwfiU7EE9Rs1M44Z3xm/lU7dehKk4PjjDMnJyXzx2SeUKutFz/5fKr7/13Hl8iW2x20mX/4CfFCqjGL7zeOYPozp0sXzFCvxgcm6yxfPA3Du7GnF8miBNOMaUbRoUXx8fHBzc+P27dusWLGCa9euAXDixAl69uzJihUrsj3H9evXTa5bWlrSrVs3rK2tCQ8P5969e6SlpdG1a1f8/f1xdHTM9kxCiP+21JQUQr79+yNpnU7H530HMXzUtyqmSrdsUQR6vZ62H3cmR44cqmSQ+vByn/XuT36Xggzq3ZUF82Ybl1ep7k2L1u0xV/Bd3wwTx3ydfpLk9oOqPW9eJjU1lb7dOpKcnMxXo79TNGOdeh8SvXIZoSHjqelbBysrKwBuJyYyZ+YUAO7fu6tYHi2QZlwDNm7cSIkSJUyWffPNN1SuXJnff/8dgNWrV3Pv3j0cnhsT929LSUkxuT5x4kT69OkDQK1atWjatCkADx48ICYmhqCgoGzNI4T478tla8u1Bwb0ej03rl/j5w1rGT9qOAf37WZR1E/Y2durkkuv1/Pjogh0Oh2BHbuokkHqw6uFjB/N1AljGPTVaFoGdsDBITfHjv5K8LD+tGrox5xFUdRv1FSRLAAH9u5m9rRJDBwerOosLi+i1+vp93ln9uzcxsedu9GqXUdF99+iTXuWL45k57Zf8K9WBr+6DUhLTWXjujXGczKUmkFJK96tv1ajnj/QAtjZ2ZkcyJ4+fcrp09n/sU3u3LlNrvv5+WV5GSAhISHb8wgh3h1mZma4FCxEp649mDAtnP17djJ14ljV8mz7ZTNXL1+ipm8dXN2Vm7HkWVIfXm7bL5uZNHYkQZ/1ps/AobgULEQuW1uq1vDmh+VrMc+Zk9FfDVQkC6TPBNSveyc+KF2W3gOGvvoXFKbX6xnQowurly+hZWAHvps6+9W/9C8zNzdn0aoNDBwejE5nxuKIcH6KWUX9Rs0IX7gSAEfnvIrnUpM0428RJSagL136xf/FPzunLGD8aEkIIf5tvnXS56nevSNOtQxLNXLi5ut4V+vDL7EbAKjhUzvTurz58lO0eAnOJ5zl0cOHiuR59PAh5xLOcPzor7jlsTD5wqjlS34AoIl/dVzsdGxYu0aRTBn0ej39Pw9i+ZIfaN66HVNmR6r2DrSlpSUDh41kx+HfuZCYzG/n/2DCtDBuXL8KQLnyyszsohUyTEVlq1at4smTJ7Rt29ZkXNuDBw+IiIgwXrewsOD999/P9jyNGjVi5Mi/v/QiPj6eMmXST+zYtm2bybaVKr1bLxYhhHJuXk8fE23+12wPSrudmMim9dG8914ePmzSQpUMUh9eLSU1fejMi6YvTLz1J2ZmZpjnVOZ5ZGFpSbtPPs1y3d6d2ziXcIaAhk1xdHJWbB5t+LsRX7F0AU1btmX6nIWaHMu+6sfFADRrFahyEmVJM66yS5cu0b9/fwYPHsyHH36Ih4cHt27dYsWKFVy9etW4XYcOHbCzs8v2PBUrVqR+/fps2rQJgMGDB3PmzBmsrKyYM2eOcbsSJUpQr169bM8jxL9h1qxZxo/Nn50RAkznbu7Roweenp6KZnuXnT51gkKu7tjY2Jgsf/z4McHDBwDgH9BQjWhELVtISkoKHT/toNiXoTxP6sOrVa5Wk4iwUMJDQ2jUrKXJXOML5s3m+tUrVK5WU7HH0Nramskz5ma5rl/3zpxLOEOfgcOoWKWaInng76EpK5YuoEmL1oTOXaR6I/7g/v1M54KsW7OSZQvn41WxMg2bZj03enbQQn2QZlwjrl+/zvz5WX9DmI+PD1OnTlUsS0REBP7+/pw8eZKkpCSmTZtmsj5//vysXLlS9RezEK/rxx9/fOEXOUyePNl4uXHjxtKMKyhm1XLCQ0OoUt2bwq7u2NrZc+P6VbbGbuDO7USq1qhFt979Vcm2dME8QBtDVKQ+vFiTFq1ZMHcWe3Zuw7t8cQIaNsXeITfHjhxiR/xWrKytCf42RJEsWhUyfjTLl/xALltbPIoWZ8qEMZm2adC4eZbfPptdGtWuikuhwhR7/wMsLa349eA+dm2Pw62IB+ELVijaX2ihPkgzrrLOnTvj5OTEunXrOHr0KDdv3uT+/fu89957eHl50b59ezp27KjoE7NAgQLs27ePKVOmsHLlSs6ePcvTp09xd3enSZMmDBo0iLx5362TK4QQ/756DRpz8/o1DuzdxcF9u3n08CF29g6ULF2WZi0DCfykiyrT0h0+sI9TJ45RvlIVRedffp7Uh1fLkSMHS6NjCQ/9nrWrl7N6xRJSU1JwzpuPloEd6DtweKa5rN81Vy5eANLHs7/ohOjCru6KNuNNW7ZlQ8wqDu3fQ1pqKoXditDvyxH0+GKwarMnqUmacZXlzp2bDh060KFDB7WjmLC1tWXEiBGMGDFC7ShC/GNxcXFqRxBZKFehkmJfwf0myleqwrUHhldvmM2kPrweS0tL+gwcSp+B2pu95FlTwiKZEhb5zuz3ZQYND2bQ8GC1YwDaqA8ym4oQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRdCCCGEEEIl0owLIYQQQgihEmnGhRBCCCGEUIk040IIIYQQQqhEmnEhhBBCCCFUIs24EEIIIYQQKpFmXAghhBBCCJVIMy6EEEIIIYRKdAaDwfBaG+p05M6dmzHjxmd3pteSmvwEa2trtWOYePT4CVYayjQjdDq9evdRO4ZRSpI2HzNLK+1kmjljOj17aecx09rrTGuvsa+GDeXOnTtqx9AEqREvp7XnrtbqA2ivRkh9eDV5nb3Ym9SHN2rGC7gU5ODvV/5RuH9LzOIwunfvrnYMEzNnh9Gig3YyBdQoR+yuI2rHMJLH7NXkMXs5rT1eFd8vxLWr2jgmqk1qxMtp7bmrtWMNyGP2KvKYvZqWHrM3qQ8yTEUIIYQQQgiVSDMuhBBCCCGESqQZF0IIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBAqkWYcaNasGTqdzvjj5+endiTxjBUrVvD5559TqVIlLC0tTR4roT1+fn4mj9HLfoTQ6/XMDwslwLsCHnltKO5iT4v6PmxaH6N2NEA79WFDzGraNq1HKVdHijhZUbV0EXoEtePqlcuK5rh+7SpzZkwhsFkAlT5wxS2PBeU889P145Yc2r9X0SygvfqQlJRE8NABtKjvQ/liLhRxsqKcZ36a1q3JsoURpKamqpLLYDDwU/QqWjWsjVfRAnjktcG7/Pt82bc7F8+fUyyHVutDlVLuuNjpsvxp+aFftu/fPNv3oHELFy4kJkYbB32RtbFjx3LkiLa+dUwI8c8ZDAa6f9KG9dFRuHt40u6TT0lJTmbT+miCApsxZtJ0unTvrVo+LdQHg8HAkC8+Z1FEOO4enjRtFYitrR03b1xj9454rly6SMFChRXLM3/2dGZ8/x3uHp741gnA0cmZ8wln2LhuDRvXrWHG/CU0a9lWsTxaqw+PHj5kwbxZeFWsgn/9Rjg6OXPv7h22/ryBAT27EB21jMWrNmBmpux7oaOHDyIsNIR8+QvQoHFzbO3sOXHsCIsj57Bm5VJiNu+iRMnSimbSGnsHB7r27JdpeWFX92zf9zvdjF+7do0vvvhC7RjiFXQ6HZ6enlSqVIkbN24QHx+vdiTxEj169KBx48aZlqelpfF///d/pKWlAfDhhx8qHU1ozProKNZHR1G5Wk2WxfyMtbU1AENHjuND30p889Ug6jVoTGE3d8WzaaU+zJs1jUUR4XTq1pMxE6eRI0cOk/UZryellK9YhagNcVT39jVZvnfndto08WdY/x40aNwcS0tLRfJorT68lycPp67ew8LCwmR5WloagU3rEb8llq2xG6jboJFimf64eYM5M6dQyNWNzbuOYO/gYFwXHvo9wcMGEDY9hO9nzc/2LFquD/YOuRk0PFjx/cI73ox3796dO3fu4OrqiqOjI4cPH1Y7ksjCrl27jEU6ODhY9YOteLm2bbN+V2zJkiUmjcOXX36pVCShUZvWRwPQd9Bw42scwNHJic969efrIf1YtiiCwV+NUjybFurDkydPCBk/CrciHnwzYWqmRhzA3FzZMt6w2UdZLq9asxY1fGoTvyWWU8d/o1yFSork0Vp9MDMzy9SIQ/rj1KBJC3Ztj+PCubOKZrp88QJ6vZ7K1WqaNOIAdRs0JnjYABJv/alIFqkPWXtnx4xHRkaybt06dDod8+fPx97eXu1I4gWeLdLi7TVp0iTj5UqVKsm5GYI/bt4AwNWtSKZ1hf9atjN+q6KZQDv1IX5LLHfv3KFBo+Y8ffqUn6JXMX3yeBbMm835BGUbuteR0zwnADkU/AfhbakPer2euM0bAXhf4eEgRTyLYWFhwf49O3lw/77Jus0b1wFQy89f0UzP00J9SElO5sdFkUybOI75YaGKngPxTr4zfvXqVfr37w/A559/jr+/P998843KqYT479q8ebPJO4vv2rseImt5HJ0AuHTxPMVKfGCy7vLF8wCcO3ta0Uxaqg9Hfz0IgFmOHPhXK2tyX5iZmdGtV39Gjpv0ol9X1JXLl9get5l8+QvwQakyasdRXUpKCtMmjcNgMHDndiI74rZw9vQp2nYIUrzxzePoyPBR4xk1fCA+FUtQv1Ez45jxnfFb6dStJ0Eqnpuhlfrwx80b9O8RZLLMq2JlZs5firuHZ7bu+51sxrt168bdu3cpUqQIEyZMUDuOEP95EydONF728PDgo4+y/qhbvFvq1PuQ6JXLCA0ZT03fOlhZWQFwOzGROTOnAHD/3l1FM2mpPiT++QcA4aEhlPGqwE9x+yj2/gccO3KYwX0/I2z6ZNw9POnUtYeqOVNTU+nbrSPJycl8Nfq7LIfTvGtSU1II+fbv4VU6nY7P+w5i+KhvVcnzWe/+5HcpyKDeXVkwb7ZxeZXq3rRo3V7x4U7P0kJ9aNshiKo1alGiZGlsctly7uxpwkNDWLl0IW2a+LN1z2/Y2tll2/7fuWEq8+fPZ8OGDeh0OiIiIrC1tVU7khD/aUePHiU2NtZ4fcCAAVKsBQAt2rSnpk9t9u7ajn+1Mnw1qA9Dvvic2lVKYWeXPjREyVkntFYf9Ho9ADktLJi/dA1eFSuTy9aWqjVrEb5wBWZmZoRNn6x6xn6fd2bPzm183Lkbrdp1VDWPVuSyteXaAwNX7j3lwKnLjAuZwdIFc2n5oV+moSJKCBk/mj5dO9Bn4HAOnLrMmesPWL1pO8nJSbRq6KfaVKJaqQ8Dh43E27cOTs55sbGxoXRZL6aFL6BVu45cuXSRxZFzsnX/71QznpSUxIABAwDo3bs3vr6+r/gNIcQ/9exYQCcnJ7p06aJiGqEl5ubmLFq1gYHDg9HpzFgcEc5PMauo36gZ4QtXAuDonFeRLFqsD3b26SfblStfifwFXEzWlShZGrciHlw4l8C9u3dVSJfeiA/o0YXVy5fQMrAD302d/epfeseYmZnhUrAQnbr2YMK0cPbv2cnUiWMVzbDtl81MGjuSoM9602fgUFwKFkr/p66GNz8sX4t5zpyM/mqgopkyaL0+dAjqDsD+PTuzdT/vXDN+7949AKZPn24yufyzZ2DHx8fLl/8I8S+4cuUKy5YtM17v1avXW3PClVCGpaUlA4eNZMfh37mQmMxv5/9gwrQwbly/CqQ3okrQYn3wLPY+kD7lWlYyliclPcn2LM/T6/X0/zyI5Ut+oHnrdkyZHan43NlvG986AQDs3hGn6H5/id0AQA2f2pnW5c2Xn6LFS3A+4SyPHj5UNNfbUB8yzmt5/PhRtu5HXjlCiGwzZcoU4zfOWVtb07u3eicJibfLqh8XA9CsVaDKSdRT86/m6ezpk5nWpaamcuHcWWxy5cLRyVnRXBmN+IqlC2jasi3T5yyUoWev4eb1awCY/zXrjFJSUlMAXjh9YeKtPzEzM8M8p7K53ob6cPhA+owq2f3FP+/UCZwWFha0bNkyy3Xx8fHcunULSP+oxNfXl1KlSikZT7zArFmzSEhIANLnlH3WoEGDjJd79OiBp2f2nvEsXt/9+/eZM+fvcXZBQUE4OTmpmEho0YP797F7burAdWtWsmzhfLwqVqZhU2VO5tJifXD38MTXP4D4LbEsjpzLx527GteFhozn3t27tAzsoOjJdxlDU1YsXUCTFq0JnbtI1UZca/Xh9KkTFHJ1x8bGxmT548ePCR6ePgzKP6Bhtud4VuVqNYkICyU8NIRGzVqazDW+YN5srl+9QuVqNRX7oibQVn048/spChZ2zfSYnfn9FGO/HgJAi9btszXDO9WM29jYsHLlyizX+fn5GT+KLFWq1Au3E8r78ccfX/hFDpMn/33yUuPGjaUZ15CwsDDu/3WiUo4cORg4UJ0xiULbGtWuikuhwhR7/wMsLa349eA+dm2Pw62IB+ELVijW6Gm1PnwbMpOmdWswuE83Nq1bg2fxEhw/epgd8Vsp5OrG/42Z+Oob+ReFjB/N8iU/kMvWFo+ixZkyYUymbRo0bk7psl6K5NFafYhZtZzw0BCqVPemsKs7tnb23Lh+la2xG7hzO5GqNWrRrXf/bM/xrCYtWrNg7iz27NyGd/niBDRsir1Dbo4dOcSO+K1YWVsT/G2Iopm0VB+io5YRHhpCtRo+FHR1w8YmF+fOnmZr7E+kpqbSZ+Awqnn7ZGuGd6oZF0IoIzU1lalTpxqvf/TRR3h4eKiYSGhV05Zt2RCzikP795CWmkphtyL0+3IEPb4YnOkd83eRu4cnG7YdYOKYr4nbvJH4rbE458tP5896MWDo1zgpdIJrhisXLwDw6OHDF56IWNjVXbFmXGvqNWjMzevXOLB3Fwf37ebRw4fY2TtQsnRZmrUMJPCTLopPI5gjRw6WRscSHvo9a1cvZ/WKJaSmpOCcNx8tAzvQd+DwTPP8Zyet1YeaPrU58/tJjh85zN7d23ny+DF5HJ2oE9CQTt164ucfkO0ZpBn/S1xcnNoRxAvIY/P2yZkzJ1euXFE7hngLDBoezKDhwWrHeCm1j0EFCxVmyuwIVTNkmBIWyZSwSLVjGKn92DyvXIVKlKugzEnHb8LS0pI+A4fSZ+BQtaNorj5U9/alure6syfJCZxCCCGEEEKoRJpxIYQQQgghVCLNuBBCCCGEECqRZlwIIYQQQgiVSDMuhBBCCCGESqQZF0IIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBAqkWZcCCGEEEIIlegMBoPhtTbU6cidOzdjxo3P7kyvJTnpCVbW1mrHMJH05AmWVtrJNHPGdHr26qN2DCN5zF5NHrOX09rjNWL4UO7cuaN2DE2QGvFyWnvuau1YA/KYvYo8Zq+mpcfsTerDGzXjBVwKcvD3K/8o3L9l1cIwPurYXe0YJrSWKaBGOWJ3HVE7hpHW7h/QXiZ5zF5Oa3kqvl+Ia1e1cUxUm9SIl9NaHq0da0B795HW8shj9mpayvMm9UGGqQghhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBAqkWZcCCGEEEIIlUgzLoQQQgghhEqkGRdCCKGaqGWL+LJvdxr4VMLd0RIXOx0/LopULY/BYOCn6FW0algbr6IF8Mhrg3f59/myb3cunj+naJbr164yZ8YUApsFUOkDV9zyWFDOMz9dP27Jof17Fc2S4cdFkbjY6V7606axv6KZ9Ho988NCCfCugEdeG4q72NOivg+b1scomiNDlVLuL7xvWn7op3iepKQkgocOoEV9H8oXc6GIkxXlPPPTtG5Nli2MIDU1VfFMGTbErKZt03qUcnWkiJMVVUsXoUdQO65euaxapgyhId8ZH7eD+/Zk677Ms/XWhRBCiJf47psRXLl0kTyOTuTNX4Arly6qmmf08EGEhYaQL38BGjRujq2dPSeOHWFx5BzWrFxKzOZdlChZWpEs82dPZ8b33+Hu4YlvnQAcnZw5n3CGjevWsHHdGmbMX0Kzlm0VyZKhVFkvBgwbmeW69WtW8vvJ4/j611csj8FgoPsnbVgfHYW7hyftPvmUlORkNq2PJiiwGWMmTadL996K5clg7+BA1579Mi0v7OqueJZHDx+yYN4svCpWwb9+IxydnLl39w5bf97AgJ5diI5axuJVGzAzU+79WYPBwJAvPmdRRDjuHp40bRWIra0dN29cY/eOeK5cukjBQoUVy/O8UyeOMXncSGxy5eLxo0fZvj9pxoUQQqhmUuhcPDyLUcjVjemTx/Nt8DDVsvxx8wZzZk6hkKsbm3cdwd7BwbguPPR7gocNIGx6CN/Pmq9InvIVqxC1IY7q3r4my/fu3E6bJv4M69+DBo2bY2lpqUgegNJlvShd1ivT8pSUFCLCQjE3N6fNx50Uy7M+Oor10VFUrlaTZTE/Y/3XV7MPHTmOD30r8c1Xg6jXoDGF3dwVywRg75CbQcODFd3ni7yXJw+nrt7DwsLCZHlaWhqBTesRvyWWrbEbqNugkWKZ5s2axqKIcDp168mYidPIkSNHpmxqSU1N5YvunShVxosiRYsRtWxRtu9ThqkIIYRQjU/tuhRydVM7BgCXL15Ar9dTuVpNk0YcoG6DxgAk3vpTsTwNm32UqREHqFqzFjV8anP3zh1OHf9NsTwvs3HdGu7cTqRug8Y4582n2H43rY8GoO+g4cZGHMDRyYnPevUnOTmZZYsiFMujRWZmZpkacQBzc3MaNGkBwIVzZxXL8+TJE0LGj8KtiAffTJiaqRHPyKaWqRPHcvrkcUJmzSeHWeZs2UHeGRdCCCGAIp7FsLCwYP+enTy4fx87e3vjus0b1wFQy0/Z8dAvktM8JwA5VGxanrXkh7kAtO/UVdH9/nHzBgCubkUyrSv817Kd8VsZ/NUoRXOlJCfz46JIbl6/hq29PV4VKlOhclVFM7yKXq8nbvNGAN5XaOgVQPyWWO7euUPbj4N4+vQpsetjSDh7GofcuanlV5cinkUVy/K8o78eYtrEsQz+ajTFS5RUbL/aeBULIYQQKsvj6MjwUeMZNXwgPhVLUL9RM+OY8Z3xW+nUrSdBKow/ft6Vy5fYHreZfPkL8EGpMmrH4cqli+yI20KBgoWoXa+BovvO4+gEwKWL5ylW4gOTdZcvngfg3NnTimaC9H8S+vcIMlnmVbEyM+cvxd3DU/E8kD6UaNqkcRgMBu7cTmRH3BbOnj5F2w5Biv6TefTXgwCY5ciBf7WyJo+PmZkZ3Xr1Z+S4SYrlyZCcnMwXn31CqbJe9Oz/paL7lmZcCCGE+MtnvfuT36Ugg3p3ZcG82cblVap706J1e1U/Pof08ax9u3UkOTmZr0Z/l+VH/EpbtigCvV5P2487K56nTr0PiV65jNCQ8dT0rYOVlRUAtxMTmTNzCgD3791VNFPbDkFUrVGLEiVLY5PLlnNnTxMeGsLKpQtp08SfrXt+w9bOTtFMAKkpKYR8+/cnBDqdjs/7DmL4qG8VzZH45x8AhIeGUMarAj/F7aPY+x9w7MhhBvf9jLDpk3H38KRT1x6K5po45uv0E6S3H1T8eSxjxoUQQoi/hIwfTZ+uHegzcDgHTl3mzPUHrN60neTkJFo19FNtujxIH1bQ7/PO7Nm5jY87d6NVu46qZXk204+LItDpdAR27KL4/lu0aU9Nn9rs3bUd/2pl+GpQH4Z88Tm1q5TCzi59mJGSs4QADBw2Em/fOjg558XGxobSZb2YFr6AVu06cuXSRRZHzlE0T4ZctrZce2Dgyr2nHDh1mXEhM1i6YC4tP/Tjwf37iuXQ6/UA5LSwYP7SNXhVrEwuW1uq1qxF+MIVmJmZETZ9smJ5AA7s3c3saZP44ssRis2W9CxpxoUQQghg2y+bmTR2JEGf9abPwKG4FCyU3iTU8OaH5Wsxz5mT0V8NVCWbXq9nQI8urF6+hJaBHfhu6uxX/5ICtv2ymauXL1HTtw6u7pnHbWc3c3NzFq3awMDhweh0ZiyOCOenmFXUb9SM8IUrAXB0zqt4rqx0COoOwP49O1XNYWZmhkvBQnTq2oMJ08LZv2cnUyeOVWz/dvbpJ0eXK1+J/AVcTNaVKFkatyIeXDiXwL27dxXJk5aWRr/unfigdFl6DxiqyD6fJ8NUhBBCCOCX2A0A1PCpnWld3nz5KVq8BMeOHObRw4fksrVVLJder6f/50GsWLqA5q3bMWV2pOLv9r7IUpVO3HyWpaUlA4eNZOBz85/v2h4HpDd9WpAxvv3x4+yft/p1+dYJAGD3jjjF9ulZ7H0gffrHrGQsT0p6ggNZb/NvevTwIecSzgDglifzrDMATfyrAzBvyWo+bNL8X88gzbgQQggBpKSmAC+evjDx1p+YmZlhnjOnYpmebcSbtmzL9DkLNTFOHNLHZW9aH8177+Xhw7+myNOSVT8uBqBZq0CVk6Q7fCD9W1PV+OKfF7l5/RoA5ubKPadr/vXP7tnTJzOtS01N5cK5s9jkyoWjk7MieSwsLWn3yadZrtu7cxvnEs4Q0LApjk7O2TZfvTTjQgghBFC5Wk0iwkIJDw2hUbOWJnONL5g3m+tXr1C5Wk3FvmQnY2jKiqULaNKiNaFzF2mmEQeIWraQlJQUOn7aQdEvHnre89NQAqxbs5JlC+fjVbEyDZt+pFiWM7+fomBhV2xsbDItH/v1EABatG6vWB6A06dOUMjVPVOmx48fEzx8AAD+AQ0Vy+Pu4YmvfwDxW2JZHDmXjzv//alKaMh47t29S8vADoqdLG1tbc3kGXOzXNeve2fOJZyhz8BhVKxSLdsySDMuhBBCNYsj57J/9w4ATp5I/wKbJT/MZff2OAAqV/c2KdbZqUmL1iyYO4s9O7fhXb44AQ2bYu+Qm2NHDrEjfitW1tYEfxuiSBZIP5l0+ZIfyGVri0fR4kyZMCbTNg0aN8/yGzGVsHTBPEDdISoAjWpXxaVQYYq9/wGWllb8enAfu7bH4VbEg/AFKxT9ByY6ahnhoSFUq+FDQVc3bGxyce7sabbG/kRqaip9Bg6jmrePYnkAYlYtJzw0hCrVvSns6o6tnT03rl9la+wG7txOpGqNWnTr3V/RTN+GzKRp3RoM7tONTevW4Fm8BMePHmZH/FYKubrxf2MmKppHbdKMCyGEUM3+3TtYvuQH02V7dpqc5KZUM54jRw6WRscSHvo9a1cvZ/WKJaSmpOCcNx8tAzvQd+DwTHNZZ6crFy8A6WNaX3SCXWFXd1Wa8cMH9nHqxDHKV6qi+lznTVu2ZUPMKg7t30NaaiqF3YrQ78sR9PhicKZ3zLNbTZ/anPn9JMePHGbv7u08efyYPI5O1AloSKduPfHzD1A0D0C9Bo25ef0aB/bu4uC+3Tx6+BA7ewdKli5Ls5aBBH7SRfEpO909PNmw7QATx3xN3OaNxG+NxTlffjp/1osBQ7/GSSMn3SpFmnEhhBCqmRIWyZSwSLVjGFlaWtJn4FD6DFRnVoVnae2+eVb5SlW49sCgdgwABg0PZtDwYLVjAFDd25fq3r5qxzBRrkIlylXQxkmszypYqDBTZkeoHeOllHoNauN0bCGEEEIIId5B0owLIYQQQgihEmnGhRBCCCGEUIk040IIIYQQQqhEmnEhhBBCCCFUIs24EEIIIYQQKpFmXAghhBBCCJVIMy6EEEIIIYRKpBkXQgghhBBCJdKMCyGEEEIIoRJpxoUQQgghhFCJNONCCCGEEEKoRGcwGAyvtaFOh7m5OSU+KJndmV6LQf+UHDlyqB3DRNrTp5iZaSfThQvncXcvonYMI71eW/cPaO95dO68PGYvo7XH6+TJk6SkpKgdQxOkRryc1IdXk+PNy2mtPoA8Zi/zJvXB/E1u2DlvPmJ3HfmfQv3bYhaH0b17d7VjmJg5O4wWHbSTKaBGOc08XgCrFobxUUft3D+gvedR2bLl2CSP2Qtp7fEqVKiQ2hE0RWrEi0l9eDU53ryc1uoDyGP2Mm9SH2SYihBCCCGEECqRZlwIIYQQQgiVSDMuhBBCCCGESqQZF0IIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVTyzjbjhw8fpkuXLnh6emJtbY29vT1FixYlMDCQ2NhYteMJDUtJSWHWrFnUqVOHvHnzkjNnTqysrHBzc+Ojjz5i7dq1akcUzzEYDCxevJi6devi6OiIhYUFLi4utG7dmt27d6sd753146JIXOx0L/1p09hf8Vxaqg9RyxbxZd/uNPCphLujJS52On5cFKlohlcJDfnO+Hgd3LdH0X1fv3aVOTOmENgsgEofuOKWx4Jynvnp+nFLDu3fq2iWDFqsEVVKub/wNdbyQz9FsyQlJRE8dAAt6vtQvpgLRZysKOeZn6Z1a7JsYQSpqamK5tFCfXijb+D8rxg1ahSjRo3CYDAYlyUlJfHgwQMSEhKwtbUlICBAxYRCq9LS0qhfvz5xcXGZll+6dIlLly6xevVqhg8fztixY9UJKUykpaXRpk0bVq9ebbL8+vXrrFy5kqioKKZOnUqfPn1USvjuKlXWiwHDRma5bv2alfx+8ji+/vUVzaS1+vDdNyO4cukieRydyJu/AFcuXVRs36/j1IljTB43EptcuXj86JHi+58/ezozvv8Odw9PfOsE4OjkzPmEM2xct4aN69YwY/4SmrVsq1geLdcIewcHuvbsl2l5YVd3RXM8eviQBfNm4VWxCv71G+Ho5My9u3fY+vMGBvTsQnTUMhav2oCZWfa/X6yV+vDONeOzZs0iODjYeL169erUqFGDPHnycPv2bU6ePImTk5N6AYWmrV692uQgW6FCBZo3b87du3eZN28e9+7dA2DChAl8+eWXODg4qJRUZAgJCTE50DZu3JjKlSuzbds2tmzZgsFgoF+/flSpUoWqVauqmPTdU7qsF6XLemVanpKSQkRYKObm5rT5uJNiebRYHyaFzsXDsxiFXN2YPnk83wYPU3T/L5OamsoX3TtRqowXRYoWI2rZIsUzlK9YhagNcVT39jVZvnfndto08WdY/x40aNwcS0tLRfJouUbYO+Rm0PBgxfb3Iu/lycOpq/ewsLAwWZ6WlkZg03rEb4lla+wG6jZolO1ZtFIf3qlm/P79+wwdOtR4ffbs2XTv3l3FROJtk5CQYHI9NjYWR0dHAFxcXBg0aBCQflC5e/euNOMaEBERYbzs7e1t/IhYr9dTpkwZTpw4gV6vZ9y4cURHR6sVUzxj47o13LmdSIPGzXHOm0+RfWq1PvjUrqt2hBeaOnEsp08eZ9OOQ8z8foIqGRo2+yjL5VVr1qKGT23it8Ry6vhvlKtQSZE8UiNezczMLFMjDmBubk6DJi3YtT2OC+fOKpJFK/XhnRozHhUVxf379wEoVKgQV69epUyZMtjY2ODk5ETz5s3Zu1edMWbi7VCyZEmT68uXL+fJkydcv36dzZs3G5d/8MEHuLq6Kh1PZOHcuXPGy+XKlTNeNjMzo3Tp0sbrsbGxpKWlKZpNZG3JD3MBaN+pq2L7lPrwZo7+eohpE8cyYOhIipco+epfUEFO85wA5DBX7n1HLdeIlORkflwUybSJ45gfFqramPoX0ev1xG3eCMD7JUu/Yut/h1bqwzv1zviuXbuMl69cucI333xjvP7kyROio6NZv349ixcvpk2bNmpEFBrXpEkTmjdvzpo1awDo2bMnPXv2NNmmTp06zJkzB51Op0JC8TwHBwf+/PNPAH777TfjcoPBwPHjx43Xk5KSOHv2LCVKlFA8o/jblUsX2RG3hQIFC1G7XgPF9iv14fUlJyfzxWefUKqsFz37f6l2nCxduXyJ7XGbyZe/AB+UKqPYfrVcI/64eYP+PYJMlnlVrMzM+Utx9/BUNAukD0ebNmkcBoOBO7cT2RG3hbOnT9G2QxC1/JQ5cVsr9eGdemf8+vXrJtctLS3p3bs3gwcPNn5UlJaWRteuXUlMTFQjotA4nU7HqlWr+L//+78sD6Rubm506NABDw8PFdKJrDRp0sR4edu2bTRr1oxvvvmG+vXrmxxsAe7cuaN0PPGcZYsi0Ov1tP24Mzly5FBsv1IfXt/EMV9zPuEM38+KUPQxel2pqan07daR5ORkvhr9naIZtVoj2nYIYvm6LRw9d5OzNx8Ru/Mwrdp15NeD+2nTxJ+HDx4omgcgNSWFkG9H8f340USGzyDhzO983ncQE6eHK5ZBK/XhnXpnPCUlxeT6xIkTjWfI1qpVi6ZNmwLw4MEDYmJiCAoKynQb4t2WmprKJ598wrJly4D0jyRbtWrF7du3mT9/PhcvXqRLly4cPnyYadOmqZxWAIwbN464uDjjx5ExMTHExMRkuW1W4xiFcvR6PT8uikCn0xHYsYui+5b68HoO7N3N7GmTGDg8mBIKDSV4E3q9nn6fd2bPzm183Lkbrdp1VHT/Wq0RA5+btah0WS+mhS8AYOXShSyOnEP3PgMUywOQy9aWaw8M6PV6bly/xs8b1jJ+1HAO7tvNoqifsLO3z/YMWqkP79Q747lz5za57ufnl+VlyHwShhAAYWFhxoNs7ty52bVrF6NGjWL69OnMmjXLuF1oaCinT59WK6Z4Rr58+Thw4ACDBw+mWLFiWFhYkC9fPho1asSQIUNMtnVxcVEppQDY9stmrl6+RE3fOri6F1F031IfXi0tLY1+3TvxQemy9B4w9NW/oDC9Xs+AHl1YvXwJLQM78N3U2YpneNtqRIeg9JOU9+/ZqVoGMzMzXAoWolPXHkyYFs7+PTuZOlGZaR+1Uh/eqWb82cH4z3t2TlkAKyur7I4j3kJbtmwxXi5evLjJmfCVKv19tr7BYODo0aOKZhMv9t577zFhwgROnz5NcnIyN27cYN26dTx8+NC4jZubGwUKFFAxpViqwombGaQ+vNqjhw85l3CG40d/xS2PhckXxyxf8gMATfyr42KnY8PaNYpm0+v19P88iOVLfqB563ZMmR2pyDzVz3vbakQex/SpOh8/Vn6O+Kz41kmfw3/3jjjF9qmF+vBODVNp1KgRI0f+/VFNfHw8Zcqkn9ixbds2k22ffdEIkeHp06fGy6dPn+bevXvGg+2BAwdMtrW2tlY0m8iaXq/n/v37md753L59O+Hhf49NfFeHHWjF7cRENq2P5r338vBhkxaK71/qw6tZWFrS7pNPs1y3d+c2ziWcIaBhUxydnCns5q5YroxGfMXSBTRt2ZbpcxaqNpb9basRhw+kz6ii9Bf/vMjN69cAMP9rJpzsppX68E414xUrVqR+/fps2rQJgMGDB3PmzBmsrKyYM2eOcbsSJUpQr149tWIKDfPz8zPOQ3r37l1q1KhBq1atuHPnDvPnzzdulytXLmrWrKlWTPGMx48fkz9/fgICAihZsiSWlpb89ttvREdHo9frAfDw8KB///4qJ323RS1bSEpKCh0/7aDYF7Q8S+rDq1lbWzN5xtws1/Xr3plzCWfoM3AYFatUUyxTxtCUFUsX0KRFa0LnLlL1pFIt1ogzv5+iYGFXbGxsMi0f+3X6UIwWrdsrkgXg9KkTFHJ1z5Tn8ePHBA9PH7fuH9BQkSxaqQ/vVDMO6RO8+/v7c/LkSZKSkjKdQJE/f35WrlypyTPEhfp69OjBihUr2LNnDwAnTpxg9OjRJtuYmZkxffr0TP9pC/UkJyezdu1aY5F8lqenJz/99BP2CpwsJF5s6YJ5gDpDVDJosT4sjpzL/t07ADh5In3qtSU/zGX39jgAKlf35uPO6t1nagsZP5rlS34gl60tHkWLM2XCmEzbNGjcPMtves0OWqwR0VHLCA8NoVoNHwq6umFjk4tzZ0+zNfYnUlNT6TNwGNW8fRTJAhCzajnhoSFUqe5NYVd3bO3suXH9KltjN3DndiJVa9SiW2/l3hzRQn1455rxAgUKsG/fPqZMmcLKlSs5e/YsT58+xd3dnSZNmjBo0CDy5s2rdkyhUdbW1sTHxzNnzhxWrlzJsWPHuHv3Lubm5ri4uFCzZk369OlD5cqV1Y4q/mJlZcWQIUOIj4/n/Pnz3L59G1tbW0qWLMlHH31Ejx49NPFx8bvs8IF9nDpxjPKVqig6J/TztFgf9u/eYRyPbVy2Z6fJCXfvcjN+5eIFIH08+4tO+ivs6q5YM67FGlHTpzZnfj/J8SOH2bt7O08ePyaPoxN1AhrSqVtP/PwDFMsCUK9BY25ev8aBvbs4uG83jx4+xM7egZKly9KsZSCBn3TBXKEvatJKfXjnmnEAW1tbRowYwYgRI9SOIt5CFhYW9OrVi169eqkdRbwGc3Nzxo8fr3YM8RLlK1Xh2gPDqzdUgNbqw5SwSKaERaod45XUyqnF+0drNaK6ty/VvX3VjmFUrkIlylXQxnkXWqkP79RsKkIIIYQQQmiJNONCCCGEEEKoRJpxIYQQQgghVCLNuBBCCCGEECqRZlwIIYQQQgiVSDMuhBBCCCGESqQZF0IIIYQQQiXSjAshhBBCCKESacaFEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVSiMxgMhtfaUKcjd+7cjBk3PrszvZbkpCdYWVurHcNEStITrDWUadr06fTs1UftGEapydq6fwAePdbW82hGqLYes+SkJ1haaef+0drr/qthQ7lz547aMTRBasTLSX14Na3VCKkPryY14sXepD68UTNewKUgB3+/8o/C/VtWLQzjo47d1Y5hImZxGN27aydT2bLl2LTriNoxjLR2/wDMnB1Giw7ayRRQoxyxGnrMtPY601qeiu8X4tpVbRwT1SY14uW0dvzTWn0A7d1HUh9eTWuvMy3leZP6IMNUhBBCCCGEUIk040IIIYQQQqhEmnEhhBBCCCFUIs24EEIIIYQQKpFmXAghhBBCCJVIMy6EEEIIIYRKpBkXQgghhBBCJdKMCyGEEEIIoRJpxlVmMBhYvHgxdevWxdHREQsLC1xcXGjdujW7d+9WO57qkpKSGD58OAEBAbi7u2NnZ0fOnDlxcnKiRo0ajB07lnv37qkdUwjxLwkN+Q4XOx0udjoO7tuj6L6vX7vKnBlTCGwWQKUPXHHLY0E5z/x0/bglh/bvVTRLBi3WiCql3I2P0fM/LT/0UyyHVutD1LJFfNm3Ow18KuHuaImLnY4fF0UqniMrG2JW07ZpPUq5OlLEyYqqpYvQI6gdV69cVjSHwWDgp+hVtGpYG6+iBfDIa4N3+ff5sm93Lp4/p2gWgB8XRb7wOZ3x06axf7bt3zzbblm8UlpaGm3atGH16tUmy69fv87KlSuJiopi6tSp9Omjra+/VdLDhw/59ttvMy1PTExk9+7d7N69m4iICPbt20eePHlUSCiE+LecOnGMyeNGYpMrF48fPVJ8//NnT2fG99/h7uGJb50AHJ2cOZ9who3r1rBx3RpmzF9Cs5ZtFcuj5Rph7+BA1579Mi0v7OquWAat1ofvvhnBlUsXyePoRN78Bbhy6aJi+34Rg8HAkC8+Z1FEOO4enjRtFYitrR03b1xj9454rly6SMFChRXLM3r4IMJCQ8iXvwANGjfH1s6eE8eOsDhyDmtWLiVm8y5KlCytWJ5SZb0YMGxkluvWr1nJ7yeP4+tfP9v2L824ikJCQkwOso0bN6Zy5cps27aNLVu2YDAY6NevH1WqVKFq1aoqJlVXwYIFqVGjBm5ubuTJk4dbt24RFRXFxYvpB7iEhATCw8MZOnSoykmFEP+r1NRUvujeiVJlvChStBhRyxYpnqF8xSpEbYijurevyfK9O7fTpok/w/r3oEHj5lhaWiqSR8s1wt4hN4OGByu6z6xosT5MCp2Lh2cxCrm6MX3yeL4NHqbYvl9k3qxpLIoIp1O3noyZOI0cOXKYrE9LS1Msyx83bzBn5hQKubqxedcR7B0cjOvCQ78neNgAwqaH8P2s+YplKl3Wi9JlvTItT0lJISIsFHNzc9p83Cnb9i/NuIoiIiKMl729vVm7di0Aer2eMmXKcOLECfR6PePGjSM6OlqtmKpycnLiypUrmZYPGDCAQoUKGa9nHHiFEG+nqRPHcvrkcTbtOMTM7yeokqFhs4+yXF61Zi1q+NQmfkssp47/RrkKlRTJIzXi5bRaH3xq11V0f6/y5MkTQsaPwq2IB99MmJqpEQcwN1euHbx88QJ6vZ7K1WqaNOIAdRs0JnjYABJv/alYnpfZuG4Nd24n0qBxc5zz5su2/UgzrqJz5/4eF1WuXDnjZTMzM0qXLs2JEycAiI2NJS0tTdEXi1Y9ffqUGzduMGfOHJPlpUqVUimREOKfOvrrIaZNHMvgr0ZTvERJteNkKad5TgByKHgc1nKNSElO5sdFkdy8fg1be3u8KlSmQmV1P8GV+pC1+C2x3L1zh7YfB/H06VNi18eQcPY0DrlzU8uvLkU8iyqap4hnMSwsLNi/ZycP7t/Hzt7euG7zxnUA1PLLvvHZb2LJD3MBaN+pa7buR7o7FTk4OPDnn+n//f3222/G5QaDgePHjxuvJyUlcfbsWUqUKKF4Rq3YvHkz9erVy3Kdj48PXbtm7wtFCJE9kpOT+eKzTyhV1oue/b9UO06Wrly+xPa4zeTLX4APSpVRbL9arhF/3LxB/x5BJsu8KlZm5vyluHt4KpYDpD68ytFfDwJgliMH/tXKcu7saeM6MzMzuvXqz8hxkxTLk8fRkeGjxjNq+EB8KpagfqNmxjHjO+O30qlbT4K691Ysz4tcuXSRHXFbKFCwELXrNcjWfclsKipq0qSJ8fK2bdto1qwZ33zzDfXr1zc50ALcuXNH6Xhvhfbt27N+/XqsrKzUjiKE+B9MHPM15xPO8P2siCw/Pldbamoqfbt1JDk5ma9Gf6doRq3WiLYdgli+bgtHz93k7M1HxO48TKt2Hfn14H7aNPHn4YMHimV5GakP6RL//AOA8NAQ7B0c+CluH2euP2D1xm14FC1O2PTJ/DB3lqKZPuvdn1mRy3j06CEL5s1m5pQJxG3eRPlKVWnRur0mRgIsWxSBXq+n7ceds/11L824isaNG4eHh4fxekxMDF9//TU///xzpm0tLCyUjKY5xYsXZ+LEiYwZM4Zu3brh6OgIwJIlS6hcubKMGRfiLXRg725mT5vEF1+OUHTmhNel1+vp93ln9uzcxsedu9GqXUdF96/VGjFw2Ei8fevg5JwXGxsbSpf1Ylr4Alq168iVSxdZHDnn1TfyL5L68HJ6vR6AnBYWzF+6Bq+Klclla0vVmrUIX7gCMzMzwqZPVjRTyPjR9OnagT4Dh3Pg1OX0fw42bSc5OYlWDf3YtD5G0TzP0+v1/LgoAp1OR2DHLtm+P2nGVZQvXz4OHDjA4MGDKVYsfQxVvnz5aNSoEUOGDDHZ1sXFRaWU2uDq6sqgQYP46quvCA8P58SJExQoUACAU6dO0a9fP3UDCiHeSFpaGv26d+KD0mXpPUB7MyHp9XoG9OjC6uVLaBnYge+mzlY8w9tWIzoEdQdg/56diu5X6sPL2dmnnyRZrnwl8hcwfZ6UKFkatyIeXDiXwL27dxXJs+2XzUwaO5Kgz3rTZ+BQXAoWSv/noIY3Pyxfi3nOnIz+aqAiWV6W8erlS9T0rYOre5Fs35804yp77733mDBhAqdPnyY5OZkbN26wbt06Hj58aNzGzc3NeGAR6fLmzUu1atWM1+Pi4tQLI4R4Y48ePuRcwhmOH/0VtzwWJl+usXzJDwA08a+Oi52ODWvXKJpNr9fT//Mgli/5geat2zFldiRmZuqUy7epRuRxdALg8WPl54h/ltQHU57F3gfSp6PMSsbypKQniuT5JXYDADV8amdalzdffooWL8H5hLM8euY5rrSlCp24mUH9QTnvML1ez/3798mdO7fJ8u3btxMeHm68HhQUxLvql19+oVKlStjZ2Zksv3XrFnv3/v2NeDqdTuloQoh/wMLSknaffJrlur07t3Eu4QwBDZvi6ORMYTd3xXJlNOIrli6gacu2TJ+zULWx7G9bjTh8IP2YrNQX/0h9eD01/2p6z54+mWldamoqF86dxSZXLhydnBXJk5KaAvDC6QsTb/2JmZkZ5jlzKpLnebcTE9m0Ppr33svDh01aKLJPacZV9PjxY/Lnz09AQAAlS5bE0tKS3377jejoaOMYLw8PD/r3769yUvVMnTqVn3/+GX9/f8qWLYuNjQ1Xr14lKiqKmzdvGrdr3LixiimFEG/K2tqayTPmZrmuX/fOnEs4Q5+Bw6hYpVqW22SHjKEpK5YuoEmL1oTOXaTqSaVarBFnfj9FwcKu2NjYZFo+9uv0oTMtWrdXJIvUh9fj7uGJr38A8VtiWRw5l487//1ub2jIeO7dvUvLwA6KnTRZuVpNIsJCCQ8NoVGzliZzjS+YN5vrV69QuVpNxb5c63lRyxaSkpJCx087KJZBmnGVJScns3btWuOXOTzL09OTn376Cftn5uB8Fz1+/PiF9xGAl5cXkycre/KJEOK/J2T8aJYv+YFctrZ4FC3OlAljMm3ToHHzLL+pL7torUZERy0jPDSEajV8KOjqho1NLs6dPc3W2J9ITU2lz8BhVPP2USyPFuvD4si57N+9A4CTJ9KnpFzyw1x2b48DoHJ1b5OGWAnfhsykad0aDO7TjU3r1uBZvATHjx5mR/xWCrm68X9jJiqWpUmL1iyYO4s9O7fhXb44AQ2bYu+Qm2NHDrEjfitW1tYEfxuiWJ7nLV0wD1BuiApIM64qKysrhgwZQnx8POfPn+f27dvY2tpSsmRJPvroI3r06IG1tbXaMVXVq1cv8ufPz969e7l27Rq3b9/G3NycfPnyUbZsWVq0aEGHDh3IqdLHWUKI/44rFy8A6ePZp04cm+U2hV3dFWvGtVgjavrU5szvJzl+5DB7d2/nyePH5HF0ok5AQzp164mff4BiWbRaH/bv3mE878G4bM9OkxNblW7G3T082bDtABPHfE3c5o3Eb43FOV9+On/WiwFDv8bJOa9iWXLkyMHS6FjCQ79n7erlrF6xhNSUFJzz5qNlYAf6DhxOsRIfKJbnWYcP7OPUiWOUr1RF0e8UkGZcRebm5owfP17tGJpWr169F36ZgxDiv2lKWCRTwiLfmf2+iBZrRHVvX6p7+6odA9BufdDa8yhDwUKFmTI7Qu0YAFhaWtJn4FD6DNTWTErlK1Xh2gOD4vuV2VSEEEIIIYRQiTTjQgghhBBCqESacSGEEEIIIVQizbgQQgghhBD/396dR0VxpmsAf7rFRmRVUBQNILgiihrEiRhN1KiJoLibiBsTR9FxFCdG471J3IdAJCoaBBfcNxRQGTWMeBs0uJGY4BJFwUhUcIyACyBb9/2Da2sPKJhrVX0mz+8czumuKqnnVMn3vl1di0LYjBMRERERKYTNOBERERGRQtiMExEREREphM04EREREZFC2IwTERERESmEzTgRERERkULYjBMRERERKYTNOBERERGRQlR6vV5fqwVVKtjY2CA4OFjqTLVSXFwMMzMzpWMYKSwqRj2BMn29KhzTp09XOoaBaNsHAB4VF8O0njiZIlaLt89E2j4lj8TK89/z5iI/P1/pGEJgjXg+0cY/0eoDIN42Yn2oGWvEs71IfXihZrxZs2a4cePG/yvcyxIZGYnJkycrHcPI12siMcRfnEwDvD3w448/Kh3DQLTtAwCxWyIxdKw4mbjPnk+0/fV6m+a4dVOMMVFprBHPJ9rfkmhjDSDeNhJtvOE+q5lI++xF6gNPUyEiIiIiUgibcSIiIiIihbAZJyIiIiJSCJtxIiIiIiKFsBknIiIiIlIIm3EiIiIiIoWwGSciIiIiUojkzXhpaSkiIiLQu3dvNG7cGHXr1kW9evXg5OSEoUOH4sCBA1JHMOLs7AyVSvXcn+PHj8uaSSR6vR7btm1D3759YWtrC41GAwcHB4wYMQInTpxQOh5VIyYmBlOmTIGnpydMTU2N/i8TiUy0+gCIVyMePXqE+XNnYUj/nujcygEt7OrBw7UJBvX1xs4t0SgrK5MtCyB2jTi0Pw6jBr2D9o62aGFXD93cWyBw4vu4eeMXWXPs2roRDpaq5/6M9OkjW55XpUasCvvCsH2+O31StvXm3LqJtauXY/TgfvBs5winhhp4uDbBh2OG4fszp2TJYCLlLy8vL0f//v2h1WqrTM/OzkZ2djbi4uIwb948LFmyRMooVAvl5eUYOXIk4uLijKbn5ORgz5492Lt3L1asWCHcE8D+6JYsWSLcgyCIasL6UDuFDx9i8/oIdHrdC336D4StXSPcK8jH0X8dwqypAdi3dye2xR6CWi39F92i1gi9Xo85M6Zga3QUnF1cMWj4aFhYWOJ27i2cOJ6MG9nX0az5a7Llad+xE2Z98nm18/4ZvweXf7qAXn36y5bnVagRly6ex7Kln6O+uTmKCgtlXfeGNeFY/dUXcHZxRa/e/WBr1wjXMq/gcEI8DifEY/WG7Rg8bJSkGSRtxuPi4owG2i5dusDPzw8FBQVYv3497t27BwAICQnBxx9/DGtraynjVBEaGlrt9BYtWsiaQxRhYWFGg6yPjw+6du2KlJQUJCUlQa/XY+bMmfDy8kK3bt0UTEpPU6lUcHV1haenJ3Jzc5GcnKx0JKIaiV4fADFqRIOGDXHp5j1oNBqj6eXl5Rg96B0kJyXiaOIh9B0wUPIsotaI9RErsTU6CuMnTcXi0JWoU6eO0fzy8nLZsgCAe8dOcO/Yqcr00tJSREeugomJCUaOGS9bHtFrRFlZGWZMHo/2HTqhRctW2Ltzq6zr7/y6F/Ye0uKNHr2Mpp/69hhG+vbBJ0GBGODjB1NTU8kySNqMZ2ZmGr1PTEyEra0tAMDBwQEfffQRgMo/lIKCAtkH28frp0rR0dGG1z169DB8RazT6dChQwdcvHgROp0OS5cuxb59+5SKSf8hNTUVZmZmAID58+cLN9ASVUf0+gCIUSPUanWVRhwATExMMMB3CFKPafFz1lVZsohYI4qLixEWvABOLVywKGRFlUYcqNxWIjicEI/8vLsY4OOHRo3tZVuv6DViRegSZPx0Ad8c/x5ffxUi+/rfGzy02undvN9E955vIzkpEZcunINHF0/JMkj6vZabm5vR+927d6O4uBg5OTk4cuSIYXq7du3g6OgoZZRqubq6QqPRwMrKCl5eXggODkZRUZHsOUSRlZVleO3h4WF4rVar4e7ubnifmJgo+5EGerbHgyzRq0T0+gCIXSN0Oh20Rw4DANq4udew9MshYo1ITkpEQX4+Bgz0Q0VFBQ7ui0X4smBsXr8G1zLl+ZBSW9s3rQMAfDD+Q1nXK3KNSP/he6wMXYJZcz9H67ZuNf8DmdU1qQsAqCPxBzpJf7uvry/8/PwQHx8PAJg6dSqmTp1qtEzv3r2xdu1aRS4keDywlJWV4cyZMzhz5gy2bNkCrVaLRo0ayZ5HadbW1rhz5w4A4Ny5c4bper0eFy5cMLx/9OgRrl69irZt28qekYh+H0SvD4BYNaK0tBQrv1wKvV6P/Ly7OK5NwtWMSxjlPxFvviXPxYAi1oj0H74DAKjr1EGfP3VE1tUMwzy1Wo1J04Lw+dIvJc9RkxvZ13Fcm4SmzZrj7XcGKB1HCCUlJZjxl3Fo37ETpgZ9rHScKm78ko1j2iOwb9IU7dp3kHRdkh4ZV6lUiI2NxaefflrtYOrk5AR/f3+4uLhIGaOKli1bIiAgAAsWLMCMGTPg4OBgmHfx4sUqBeGPwtfX1/A6JSUFgwcPxqJFi9C/f3+jgRYA8vPz5Y5HRL8jotYHQMwaUVZairB/LMBXwQuxMWo1Mq9cxpS/fYTQ8CjZMohYI+7e+TcAIGpVGKysrXFQexpXch4g7nAKXFq2RmT4MmxaFyFLlufZuTUaOp0Oo8ZMqPZUmj+i0MWf4VrmFXwVES3cNikrK8PfJo1FSUkJ/mvhF5Lnk/TIeFlZGcaNG4edO3cCqPxacvjw4cjLy8OGDRtw/fp1BAQE4OzZs1i5cqWUUQwOHz5c5dP6okWL0LVrV1y+fBlA5YVF9+7dU+QcRSUtXboUWq3WcDRo//792L9/f7XLVncOIxFRbYlYHwBxa4S5hQVuPdBDp9MhN+cW/nXoAIIXzMN3p09g696DsLSykjyDiDVCp9MBAOpqNNiwIx5NmlZ+cOrm/SaitsSg7xseiAxfhvEfBsqS51kZd22NhkqlwuixAYrlEEnaqRNYs/JL/H3efLSV6TSr2tLpdJg5ZQJOfpuCMRMmYfj7YyVfp6RHxiMjIw0DrY2NDVJTU7FgwQKEh4cjIuLJJ9VVq1YhIyPjWb/mparuazNLS0tMnDjR8L6iokK2PCKxt7dHWloaZs+ejVatWkGj0cDe3h4DBw7EnDlzjJZ9+kgREdGLErE+AOLXCLVaDYdmzTH+w0CErIzCmZPfYkWoPLd+FLFGWFpVfiDy6OxpaMQfa+vmDqcWLvg5KxP3CgpkyVOdlP85gpu/ZMO7V284Ov8x79b2tPLycsycPB7t3Dvir7PmKh3HiE6nw6zAAMTt3o5ho/3xxYo1sqxX0mY8KSnJ8Lp169ZGRxE8PZ9clarX65Geni5llBcm2s3w5dKgQQOEhIQgIyMDJSUlyM3NRUJCAh4+fGhYxsnJCU2bNlUwJRG96l7l+gCIUSN69e4HADhxXCvbOkWrEa6t2gAArKxtqp3/ePqjR8Wy5KnODoUu3BRV4cOHyMq8ggvpP8CpocboYUi7t28CAPj2eQMOliocOhAvWy6dToegKROxe/sm+I14H8vXbJTl/v2AxKepVFRUGF5nZGQYfa2XlpZmtKwcV/vGxsaiuLgYo0aNMrrV0YMHD4xu2aTRaNCmTRvJ84hGp9Ph/v37sLGxMZp+7NgxREU9OS/x6SNERES/hWj1AXj1asTtnFsAAJP/u+OD1ESsEd493wYAXM34qcq8srIy/Jx1FfXNzWFrp8xNGfLu3sU3/9yHBg0a4l3fIYpkEI3G1BTvj/tztfNOfZuCrMwr6PfeINjaNcJrTs6yZHrciMfs2IxBw0YhfO0WWc9jl7QZf+uttwz3IS0oKED37t0xfPhw5OfnY8OGDYblzM3N4e3tLWUUAEB2djaCgoIwe/ZsvPvuu3BxccGvv/6KmJgY3Lx507Ccv78/LC0tJc8jmqKiIjRp0gT9+vWDm5sbTE1Nce7cOezbt89wXp6LiwuCgoIUTkpPi4iIMNyzOTU11Wje0/dJDgwMhKurq6zZiJ5FtPoAiFkjMi5dRHNHZ9SvX99oelFREebPmwUA6NPvPVmyiFgjnF1c0atPPyQnJWLbxnUYM+HJ0edVYcG4V1CAYaP9FbvX+N6dW1BaWoqxf/aX9KExzyNajTAzM8Oy1euqnTdz8gRkZV7B9L9/gte9/iR5FuDJqSkxOzbDd8gIrFq3VfYLSiX93xkYGIiYmBicPHkSQOVV6AsXLjRaRq1WIzw8vMonbSnl5OQYDfZP69mzJ1asWCFbFtGUlJTgwIEDhiL5NFdXVxw8eBBWMlwoRLW3a9euZz7EYdmyZYbXPj4+bMZJGKLWB0CsGrE/djeiVoXB640eeM3RGRaWVsjNuYmjiYeQn3cX3bq/iUl/la/5FbFG/CPsawzq2x2zp0/CNwnxcG3dFhfSz+J48lE0d3TCp4urf5KqHHZsXg9A2VNUWCOeLyx4IXZv3wRzCwu4tGyN5SGLqywzwMev2qeqviySNuNmZmZITk7G2rVrsWfPHpw/fx4FBQUwMTGBg4MDvL29MX36dHTt2lXKGAYTJkyAnZ0dEhISkJ6ejtu3b+P+/fto0KABOnXqhA8++ABjx44V7hY7cqlXrx7mzJmD5ORkXLt2DXl5ebCwsICbmxuGDh2KwMBAoR8eQESvDtHqAyBmjXhngA9u59xC2qlUfHf6BAofPoSllTXc3Dti8LDRGD0uQLajvqLWCGcXVxxKSUPo4s+gPXIYyUcT0ci+CSb8ZRpmzf0Mdo0ay54JAM6mncali+fR2dNL8vtU02934/rPACrPZX/WxdCvOTq/us04UHlu3bRp0zBt2jSpV1UjGxsb+Pv7w9/fX+koQjIxMUFwcLDSMegFabVapSMQ/SYi1QdAzBrh0cVT0sdwvwiRa0Sz5q9h+ZromheUUWdPL9x6oFc6xitVI5ZHbsTyyI2/+3X+J3kuEyUiIiIioirYjBMRERERKYTNOBERERGRQtiMExEREREphM04EREREZFC2IwTERERESmEzTgRERERkULYjBMRERERKYTNOBERERGRQtiMExEREREphM04EREREZFCVHq9Xl+rBVUqqNVqNG3aVOpMtVJYWAhzc3OlYxgpLCyEWX1xMt35923Y29srHcNAtO0DAMVFYmXiPns+0fbX7dwcVFRUKB1DCKwRzyfa35JoYw0g3jYSbbzhPquZSPvsRepDrZtxIiIiIiJ6uXiaChERERGRQtiMExEREREphM04EREREZFC2IwTERERESmEzTgRERERkULYjBMRERERKYTNOBERERGRQtiMExEREREphM04EREREZFC/he/1doWNef0pgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "âœ… Part 1 Complete! Dataset ready for training.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 10: Test Dataset Loading\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ§ª Testing Dataset Loading\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create a small test dataset\n",
        "test_dataset = PuzzleDataset(\n",
        "    dataset_paths=[OUTPUT_DIR],\n",
        "    global_batch_size=32,\n",
        "    seed=42,\n",
        "    test_set_mode=True,\n",
        "    epochs_per_iter=1,\n",
        "    rank=0,\n",
        "    num_replicas=1,\n",
        "    split=\"test\"\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ“Š Dataset metadata:\")\n",
        "print(f\"  Sequence length: {test_dataset.metadata.seq_len}\")\n",
        "print(f\"  Vocabulary size: {test_dataset.metadata.vocab_size}\")\n",
        "print(f\"  Total puzzles: {test_dataset.metadata.total_puzzles}\")\n",
        "\n",
        "# Get one batch\n",
        "dataloader = DataLoader(test_dataset, batch_size=None)\n",
        "set_name, batch, batch_size = next(iter(dataloader))\n",
        "\n",
        "print(f\"\\nğŸ“¦ Sample batch:\")\n",
        "print(f\"  Set name: {set_name}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Input shape: {batch['inputs'].shape}\")\n",
        "print(f\"  Labels shape: {batch['labels'].shape}\")\n",
        "print(f\"  Input range: [{batch['inputs'].min()}, {batch['inputs'].max()}]\")\n",
        "print(f\"  Labels range: [{batch['labels'].min()}, {batch['labels'].max()}]\")\n",
        "\n",
        "# Visualize first example\n",
        "print(\"\\nğŸ¨ Visualizing first example...\")\n",
        "first_input = batch['inputs'][0].numpy().reshape(9, 9)\n",
        "first_label = batch['labels'][0].numpy().reshape(9, 9)\n",
        "visualize_sudoku(first_input, first_label, title=\"Sample Sudoku Puzzle\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… Part 1 Complete! Dataset ready for training.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FjrSl53lQNM"
      },
      "source": [
        "# ğŸ“¦ Part 2: Original TinyRecursiveModels Implementation\n",
        "\n",
        "This section implements the original TinyRecursiveModels (TRM) architecture from the paper \"Less is More: Recursive Reasoning with Tiny Networks\".\n",
        "\n",
        "## Key Components:\n",
        "1. **Basic Layers**: `CastedLinear`, `CastedEmbedding`, `RotaryEmbedding`\n",
        "2. **Attention & FFN**: `Attention`, `SwiGLU`, `rms_norm`\n",
        "3. **Sparse Embedding**: `CastedSparseEmbedding` for puzzle-specific embeddings\n",
        "4. **TRM Model**: Hierarchical recursive reasoning with ACT (Adaptive Computation Time)\n",
        "5. **Loss Functions**: `ACTLossHead` with stablemax cross-entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um7Nh8LllQNM"
      },
      "source": [
        "## Cell 11: Original Layers\n",
        "\n",
        "Basic building blocks for the TRM model:\n",
        "- `CastedLinear`: Linear layer with automatic dtype casting\n",
        "- `CastedEmbedding`: Embedding layer with dtype casting\n",
        "- `RotaryEmbedding`: Rotary Position Embedding (RoPE)\n",
        "- `Attention`: Multi-head attention with RoPE support\n",
        "- `SwiGLU`: SwiGLU FFN (as used in LLaMA)\n",
        "- `rms_norm`: Root Mean Square Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdDLf1u2lQNM",
        "outputId": "a45d1fbd-94f3-43d0-fdae-40cf5036955d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Original Layers defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Available layers:\n",
            "  - CastedLinear: Linear with dtype casting\n",
            "  - CastedEmbedding: Embedding with dtype casting\n",
            "  - RotaryEmbedding: RoPE positional encoding\n",
            "  - Attention: Multi-head attention with RoPE\n",
            "  - SwiGLU: SwiGLU FFN\n",
            "  - rms_norm: RMS normalization function\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 11: Original Layers (CastedLinear, CastedEmbedding, Attention, etc.)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Type alias for RoPE cos/sin tensors\n",
        "CosSin = Tuple[torch.Tensor, torch.Tensor]\n",
        "\n",
        "def _find_multiple(a: int, b: int) -> int:\n",
        "    \"\"\"Find smallest multiple of b that is >= a (ceiling division * b).\"\"\"\n",
        "    return (-(a // -b)) * b\n",
        "\n",
        "# ============ RoPE Helpers ============\n",
        "def rotate_half(x: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Rotates half the hidden dims of the input for RoPE.\"\"\"\n",
        "    x1 = x[..., : x.shape[-1] // 2]\n",
        "    x2 = x[..., x.shape[-1] // 2 :]\n",
        "    return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "def apply_rotary_pos_emb(\n",
        "    q: torch.Tensor,\n",
        "    k: torch.Tensor,\n",
        "    cos: torch.Tensor,\n",
        "    sin: torch.Tensor\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Apply rotary position embeddings to query and key tensors.\n",
        "\n",
        "    Args:\n",
        "        q, k: [batch_size, seq_len, num_heads, head_dim]\n",
        "        cos, sin: [seq_len, head_dim]\n",
        "    \"\"\"\n",
        "    orig_dtype = q.dtype\n",
        "    q = q.to(cos.dtype)\n",
        "    k = k.to(cos.dtype)\n",
        "\n",
        "    q_embed = (q * cos.unsqueeze(-2)) + (rotate_half(q) * sin.unsqueeze(-2))\n",
        "    k_embed = (k * cos.unsqueeze(-2)) + (rotate_half(k) * sin.unsqueeze(-2))\n",
        "\n",
        "    return q_embed.to(orig_dtype), k_embed.to(orig_dtype)\n",
        "\n",
        "# ============ CastedLinear ============\n",
        "class CastedLinear(nn.Module):\n",
        "    \"\"\"Linear layer with automatic dtype casting and truncated normal init.\"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
        "        super().__init__()\n",
        "        # Truncated LeCun normal init: std = 1/sqrt(fan_in)\n",
        "        self.weight = nn.Parameter(\n",
        "            trunc_normal_init_(torch.empty((out_features, in_features)), std=1.0 / (in_features ** 0.5))\n",
        "        )\n",
        "        self.bias = None\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros((out_features,)))\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return F.linear(\n",
        "            input,\n",
        "            self.weight.to(input.dtype),\n",
        "            bias=self.bias.to(input.dtype) if self.bias is not None else None\n",
        "        )\n",
        "\n",
        "# ============ CastedEmbedding ============\n",
        "class CastedEmbedding(nn.Module):\n",
        "    \"\"\"Embedding layer with dtype casting and truncated normal init.\"\"\"\n",
        "\n",
        "    def __init__(self, num_embeddings: int, embedding_dim: int, init_std: float, cast_to: torch.dtype):\n",
        "        super().__init__()\n",
        "        self.cast_to = cast_to\n",
        "        self.embedding_weight = nn.Parameter(\n",
        "            trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std)\n",
        "        )\n",
        "\n",
        "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
        "        return F.embedding(input, self.embedding_weight.to(self.cast_to))\n",
        "\n",
        "# ============ RotaryEmbedding ============\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    \"\"\"Rotary Position Embedding (RoPE) as used in LLaMA.\"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, max_position_embeddings: int, base: float = 10000.0, device=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Compute inverse frequencies\n",
        "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.float32, device=device) / dim))\n",
        "        t = torch.arange(max_position_embeddings, dtype=torch.float32, device=device)\n",
        "        freqs = torch.outer(t, inv_freq)\n",
        "\n",
        "        # Cache cos and sin\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        self.cos_cached = nn.Buffer(emb.cos(), persistent=False)\n",
        "        self.sin_cached = nn.Buffer(emb.sin(), persistent=False)\n",
        "\n",
        "    def forward(self) -> CosSin:\n",
        "        return self.cos_cached, self.sin_cached\n",
        "\n",
        "# ============ Attention ============\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"Multi-head attention with optional RoPE and causal masking.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size: int,\n",
        "        head_dim: int,\n",
        "        num_heads: int,\n",
        "        num_key_value_heads: int,\n",
        "        causal: bool = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.head_dim = head_dim\n",
        "        self.output_size = head_dim * num_heads\n",
        "        self.num_heads = num_heads\n",
        "        self.num_key_value_heads = num_key_value_heads\n",
        "        self.causal = causal\n",
        "\n",
        "        # Fused QKV projection\n",
        "        self.qkv_proj = CastedLinear(\n",
        "            self.hidden_size,\n",
        "            (self.num_heads + 2 * self.num_key_value_heads) * self.head_dim,\n",
        "            bias=False\n",
        "        )\n",
        "        self.o_proj = CastedLinear(self.output_size, self.hidden_size, bias=False)\n",
        "\n",
        "    def forward(self, cos_sin: CosSin, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size, seq_len, _ = hidden_states.shape\n",
        "\n",
        "        # QKV projection\n",
        "        qkv = self.qkv_proj(hidden_states)\n",
        "        qkv = qkv.view(batch_size, seq_len, self.num_heads + 2 * self.num_key_value_heads, self.head_dim)\n",
        "\n",
        "        query = qkv[:, :, :self.num_heads]\n",
        "        key = qkv[:, :, self.num_heads: self.num_heads + self.num_key_value_heads]\n",
        "        value = qkv[:, :, self.num_heads + self.num_key_value_heads:]\n",
        "\n",
        "        # Apply RoPE\n",
        "        if cos_sin is not None:\n",
        "            cos, sin = cos_sin\n",
        "            query, key = apply_rotary_pos_emb(query, key, cos, sin)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        # Reshape for attention: [B, S, H, D] -> [B, H, S, D]\n",
        "        query = einops.rearrange(query, 'B S H D -> B H S D')\n",
        "        key = einops.rearrange(key, 'B S H D -> B H S D')\n",
        "        value = einops.rearrange(value, 'B S H D -> B H S D')\n",
        "\n",
        "        attn_output = F.scaled_dot_product_attention(\n",
        "            query=query, key=key, value=value, is_causal=self.causal\n",
        "        )\n",
        "\n",
        "        # Reshape back: [B, H, S, D] -> [B, S, H*D]\n",
        "        attn_output = einops.rearrange(attn_output, 'B H S D -> B S (H D)')\n",
        "\n",
        "        return self.o_proj(attn_output)\n",
        "\n",
        "# ============ SwiGLU FFN ============\n",
        "class SwiGLU(nn.Module):\n",
        "    \"\"\"SwiGLU Feed-Forward Network as used in LLaMA.\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size: int, expansion: float):\n",
        "        super().__init__()\n",
        "        # Compute intermediate size (2/3 * expansion * hidden_size, rounded to multiple of 256)\n",
        "        inter = _find_multiple(round(expansion * hidden_size * 2 / 3), 256)\n",
        "\n",
        "        self.gate_up_proj = CastedLinear(hidden_size, inter * 2, bias=False)\n",
        "        self.down_proj = CastedLinear(inter, hidden_size, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        gate, up = self.gate_up_proj(x).chunk(2, dim=-1)\n",
        "        return self.down_proj(F.silu(gate) * up)\n",
        "\n",
        "# ============ RMS Normalization ============\n",
        "def rms_norm(hidden_states: torch.Tensor, variance_epsilon: float = 1e-5) -> torch.Tensor:\n",
        "    \"\"\"Root Mean Square Layer Normalization.\"\"\"\n",
        "    input_dtype = hidden_states.dtype\n",
        "    hidden_states = hidden_states.to(torch.float32)\n",
        "\n",
        "    variance = hidden_states.square().mean(-1, keepdim=True)\n",
        "    hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
        "\n",
        "    return hidden_states.to(input_dtype)\n",
        "\n",
        "# ============ LinearSwish (optional) ============\n",
        "class LinearSwish(nn.Module):\n",
        "    \"\"\"Linear layer with SiLU activation.\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size: int, reverse: bool = False):\n",
        "        super().__init__()\n",
        "        self.linear = CastedLinear(hidden_size, hidden_size, bias=False)\n",
        "        self.reverse = reverse\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.reverse:\n",
        "            return F.silu(self.linear(x))\n",
        "        else:\n",
        "            return self.linear(F.silu(x))\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Original Layers defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Available layers:\")\n",
        "print(\"  - CastedLinear: Linear with dtype casting\")\n",
        "print(\"  - CastedEmbedding: Embedding with dtype casting\")\n",
        "print(\"  - RotaryEmbedding: RoPE positional encoding\")\n",
        "print(\"  - Attention: Multi-head attention with RoPE\")\n",
        "print(\"  - SwiGLU: SwiGLU FFN\")\n",
        "print(\"  - rms_norm: RMS normalization function\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX5OIMUslQNM"
      },
      "source": [
        "## Cell 12: Original SparseEmbedding\n",
        "\n",
        "Puzzle-specific embeddings that are:\n",
        "- Efficiently updated using SignSGD (sparse gradient update)\n",
        "- Cast to the forward dtype during forward pass\n",
        "- Stored locally for gradient accumulation during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rszkdKI8lQNM",
        "outputId": "3a815b91-bc2e-4c56-f20b-e396699fe6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Original SparseEmbedding defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Available classes:\n",
            "  - CastedSparseEmbedding: Sparse embedding with efficient updates\n",
            "  - CastedSparseEmbeddingSignSGD: SignSGD optimizer for sparse embeddings\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 12: Original SparseEmbedding\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class CastedSparseEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Sparse embedding for puzzle-specific parameters.\n",
        "\n",
        "    During training:\n",
        "    - Copies embeddings to local buffer for gradient computation\n",
        "    - Uses SignSGD for efficient sparse updates\n",
        "\n",
        "    During inference:\n",
        "    - Directly indexes into the weight matrix\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_embeddings: int,\n",
        "        embedding_dim: int,\n",
        "        batch_size: int,\n",
        "        init_std: float,\n",
        "        cast_to: torch.dtype\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cast_to = cast_to\n",
        "\n",
        "        # Main weights (persistent, no gradient)\n",
        "        self.weights = nn.Buffer(\n",
        "            trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std),\n",
        "            persistent=True\n",
        "        )\n",
        "\n",
        "        # Local weights for training (with gradient, not persistent)\n",
        "        self.local_weights = nn.Buffer(\n",
        "            torch.zeros(batch_size, embedding_dim, requires_grad=True),\n",
        "            persistent=False\n",
        "        )\n",
        "        # Local IDs tracking which embeddings are in local_weights\n",
        "        self.local_ids = nn.Buffer(\n",
        "            torch.zeros(batch_size, dtype=torch.int32),\n",
        "            persistent=False\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        if not self.training:\n",
        "            # Inference: direct lookup\n",
        "            return self.weights[inputs].to(self.cast_to)\n",
        "\n",
        "        # Training: copy to local buffer for gradient\n",
        "        with torch.no_grad():\n",
        "            self.local_weights.copy_(self.weights[inputs])\n",
        "            self.local_ids.copy_(inputs)\n",
        "\n",
        "        # Retain gradient for non-leaf tensor\n",
        "        self.local_weights.retain_grad()\n",
        "\n",
        "        return self.local_weights.to(self.cast_to)\n",
        "\n",
        "\n",
        "class CastedSparseEmbeddingSignSGD(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    SignSGD optimizer for sparse embeddings.\n",
        "\n",
        "    Adam â‰ˆ SignSGD when gradients are very sparse, so this is more efficient.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params,\n",
        "        lr: float = 1e-3,\n",
        "        weight_decay: float = 1e-2,\n",
        "    ):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n",
        "\n",
        "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        # Manually set param_groups to bypass PyTorch's leaf tensor check\n",
        "        # Buffers are not leaf tensors, but we handle them specially in step()\n",
        "        if isinstance(params, torch.Tensor):\n",
        "            params = [params]\n",
        "\n",
        "        # Convert to list if needed\n",
        "        params = list(params)\n",
        "\n",
        "        # Create param_groups manually (bypassing super().__init__ validation)\n",
        "        # We directly set param_groups without calling add_param_group to avoid validation\n",
        "        if isinstance(params[0], dict):\n",
        "            param_groups = params\n",
        "        else:\n",
        "            param_groups = [{'params': params}]\n",
        "\n",
        "        # Initialize Optimizer base class attributes manually\n",
        "        self.defaults = defaults\n",
        "        import weakref\n",
        "        self.state = weakref.WeakValueDictionary()\n",
        "        self._hook_for_profile = None\n",
        "        from collections import OrderedDict\n",
        "        self._optimizer_step_pre_hooks = OrderedDict()\n",
        "        self._optimizer_step_post_hooks = OrderedDict()\n",
        "\n",
        "        # Set param_groups directly (merge defaults into each group)\n",
        "        self.param_groups = []\n",
        "        for param_group in param_groups:\n",
        "            # Merge defaults with param_group\n",
        "            merged_group = {**defaults, **param_group}\n",
        "            self.param_groups.append(merged_group)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        for group in self.param_groups:\n",
        "            # Find sparse embedding components\n",
        "            local_weights_grad = None\n",
        "            local_ids = None\n",
        "            weights = None\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.requires_grad:\n",
        "                    # Use getattr to safely access grad without triggering warnings\n",
        "                    local_weights_grad = getattr(p, 'grad', None)\n",
        "                elif p.ndim == 1:\n",
        "                    local_ids = p\n",
        "                elif p.ndim == 2:\n",
        "                    weights = p\n",
        "\n",
        "            if local_weights_grad is None or local_ids is None or weights is None:\n",
        "                continue\n",
        "\n",
        "            # Unique IDs and aggregate gradients\n",
        "            grad_ids, inv = local_ids.unique(return_inverse=True)\n",
        "            N, D = local_weights_grad.shape\n",
        "\n",
        "            grad = torch.zeros((grad_ids.shape[0], D), dtype=local_weights_grad.dtype, device=local_weights_grad.device)\n",
        "            grad.scatter_add_(0, inv.unsqueeze(-1).expand(-1, D), local_weights_grad)\n",
        "\n",
        "            # SignSGD with decoupled weight decay\n",
        "            p = weights[grad_ids]\n",
        "            p.mul_(1.0 - group[\"lr\"] * group[\"weight_decay\"])\n",
        "            p.add_(torch.sign(grad), alpha=-group[\"lr\"])\n",
        "\n",
        "            # Write back\n",
        "            weights[grad_ids] = p\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Original SparseEmbedding defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Available classes:\")\n",
        "print(\"  - CastedSparseEmbedding: Sparse embedding with efficient updates\")\n",
        "print(\"  - CastedSparseEmbeddingSignSGD: SignSGD optimizer for sparse embeddings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDZ61ztrlQNM"
      },
      "source": [
        "## Cell 13: Original TRM Model\n",
        "\n",
        "The TinyRecursiveReasoningModel with Adaptive Computation Time (ACT):\n",
        "\n",
        "**Architecture:**\n",
        "- **H-level**: High-level reasoning state (updated every H_cycles)\n",
        "- **L-level**: Low-level reasoning state (updated every L_cycles within each H-cycle)\n",
        "- **Input injection**: Token embeddings + puzzle embeddings injected at each L-step\n",
        "\n",
        "**ACT (Adaptive Computation Time):**\n",
        "- Model learns when to halt computation via Q-learning\n",
        "- `q_halt_logits`: Confidence that current answer is correct\n",
        "- `q_continue_logits`: Expected value of continuing computation\n",
        "- Exploration during training: Random early halting with probability `halt_exploration_prob`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fee3XFNblQNM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl9MKDillQNM",
        "outputId": "985dfec7-d0ef-400f-dbf0-b04c0c38b761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Original TRM Model defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Model components:\n",
            "  - OriginalTRMConfig: Model configuration\n",
            "  - TRMBlock: Single transformer block\n",
            "  - TRMReasoningModule: Stack of TRM blocks\n",
            "  - TRMInner: Core reasoning model\n",
            "  - OriginalTRM: Full model with ACT wrapper\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 13: Original TRM Model (TRMConfig, TRMBlock, TRMInner, TRM)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# ============ Carry Dataclasses ============\n",
        "@dataclass\n",
        "class TRMInnerCarry:\n",
        "    \"\"\"Inner carry state for TRM reasoning.\"\"\"\n",
        "    z_H: torch.Tensor  # High-level state: [B, L+puzzle_emb_len, D]\n",
        "    z_L: torch.Tensor  # Low-level state: [B, L+puzzle_emb_len, D]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TRMCarry:\n",
        "    \"\"\"Full carry state including ACT status.\"\"\"\n",
        "    inner_carry: TRMInnerCarry\n",
        "    steps: torch.Tensor         # Current step count: [B]\n",
        "    halted: torch.Tensor        # Whether each sequence has halted: [B]\n",
        "    current_data: Dict[str, torch.Tensor]  # Current batch data\n",
        "\n",
        "\n",
        "# ============ TRM Configuration ============\n",
        "class OriginalTRMConfig(BaseModel):\n",
        "    \"\"\"Configuration for the original TinyRecursiveReasoningModel.\"\"\"\n",
        "\n",
        "    # Data dimensions\n",
        "    batch_size: int\n",
        "    seq_len: int\n",
        "    vocab_size: int\n",
        "    num_puzzle_identifiers: int\n",
        "\n",
        "    # Model dimensions\n",
        "    hidden_size: int = 512\n",
        "    expansion: float = 4.0\n",
        "    num_heads: int = 8\n",
        "\n",
        "    # Puzzle embeddings\n",
        "    puzzle_emb_ndim: int = 512\n",
        "    puzzle_emb_len: int = 16\n",
        "\n",
        "    # Recursion structure\n",
        "    H_cycles: int = 3           # High-level cycles\n",
        "    L_cycles: int = 6           # Low-level cycles per H-cycle\n",
        "    H_layers: int = 0           # Layers in H-block (ignored in original)\n",
        "    L_layers: int = 2           # Layers in L-block\n",
        "\n",
        "    # Position encoding\n",
        "    pos_encodings: str = \"rope\"  # \"rope\", \"learned\", or \"none\"\n",
        "    rope_theta: float = 10000.0\n",
        "\n",
        "    # Normalization\n",
        "    rms_norm_eps: float = 1e-5\n",
        "\n",
        "    # ACT (Adaptive Computation Time)\n",
        "    halt_max_steps: int = 16\n",
        "    halt_exploration_prob: float = 0.1\n",
        "\n",
        "    # Dtype\n",
        "    forward_dtype: str = \"bfloat16\"\n",
        "\n",
        "    # Additional options\n",
        "    mlp_t: bool = False          # Use MLP instead of transformer on L\n",
        "    no_ACT_continue: bool = True # Only use halt sigmoid, no continue loss\n",
        "\n",
        "\n",
        "# ============ TRM Block ============\n",
        "class TRMBlock(nn.Module):\n",
        "    \"\"\"Single transformer block for TRM.\"\"\"\n",
        "\n",
        "    def __init__(self, config: OriginalTRMConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        if config.mlp_t:\n",
        "            # MLP over sequence dimension instead of attention\n",
        "            self.puzzle_emb_len = -(config.puzzle_emb_ndim // -config.hidden_size) if config.puzzle_emb_len == 0 else config.puzzle_emb_len\n",
        "            self.mlp_t = SwiGLU(\n",
        "                hidden_size=config.seq_len + self.puzzle_emb_len, # L\n",
        "                expansion=config.expansion,\n",
        "            )\n",
        "        else:\n",
        "            # Standard self-attention\n",
        "            self.self_attn = Attention(\n",
        "                hidden_size=config.hidden_size,\n",
        "                head_dim=config.hidden_size // config.num_heads,\n",
        "                num_heads=config.num_heads,\n",
        "                num_key_value_heads=config.num_heads,\n",
        "                causal=False\n",
        "            )\n",
        "\n",
        "        # FFN\n",
        "        self.mlp = SwiGLU(\n",
        "            hidden_size=config.hidden_size,\n",
        "            expansion=config.expansion,\n",
        "        )\n",
        "        self.norm_eps = config.rms_norm_eps\n",
        "\n",
        "    def forward(self, cos_sin: CosSin, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        # B, L, D = hidden_states.shape\n",
        "        # Post Norm\n",
        "        if self.config.mlp_t:\n",
        "            hidden_states = hidden_states.transpose(1,2)\n",
        "            out = self.mlp_t(hidden_states)\n",
        "            hidden_states = rms_norm(hidden_states + out, variance_epsilon=self.norm_eps)\n",
        "            hidden_states = hidden_states.transpose(1,2)\n",
        "        else:\n",
        "            # Self Attention\n",
        "            hidden_states = rms_norm(hidden_states + self.self_attn(cos_sin=cos_sin, hidden_states=hidden_states), variance_epsilon=self.norm_eps)\n",
        "        # Fully Connected\n",
        "        out = self.mlp(hidden_states)\n",
        "        hidden_states = rms_norm(hidden_states + out, variance_epsilon=self.norm_eps)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# ============ TRM Reasoning Module ============\n",
        "class TRMReasoningModule(nn.Module):\n",
        "    \"\"\"Stack of TRM blocks with input injection.\"\"\"\n",
        "\n",
        "    def __init__(self, layers: List[TRMBlock]):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        input_injection: torch.Tensor,\n",
        "        **kwargs\n",
        "    ) -> torch.Tensor:\n",
        "        hidden_states = hidden_states + input_injection\n",
        "        for layer in self.layers:\n",
        "            hidden_states = layer(hidden_states=hidden_states, **kwargs)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "# ============ TRM Inner Model ============\n",
        "class TRMInner(nn.Module):\n",
        "    \"\"\"Inner TRM model (without ACT wrapper).\"\"\"\n",
        "\n",
        "    def __init__(self, config: OriginalTRMConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.forward_dtype = getattr(torch, config.forward_dtype)\n",
        "\n",
        "        # Embedding scale\n",
        "        self.embed_scale = math.sqrt(config.hidden_size)\n",
        "        embed_init_std = 1.0 / self.embed_scale\n",
        "\n",
        "        # Token embeddings\n",
        "        self.embed_tokens = CastedEmbedding(\n",
        "            config.vocab_size,\n",
        "            config.hidden_size,\n",
        "            init_std=embed_init_std,\n",
        "            cast_to=self.forward_dtype\n",
        "        )\n",
        "\n",
        "        # Output heads\n",
        "        self.lm_head = CastedLinear(config.hidden_size, config.vocab_size, bias=False)\n",
        "        self.q_head = CastedLinear(config.hidden_size, 2, bias=True)  # [halt, continue]\n",
        "\n",
        "        # Puzzle embeddings\n",
        "        self.puzzle_emb_len = -(config.puzzle_emb_ndim // -config.hidden_size) if config.puzzle_emb_len == 0 else config.puzzle_emb_len  # ceil div\n",
        "        if config.puzzle_emb_ndim > 0:\n",
        "            self.puzzle_emb = CastedSparseEmbedding(\n",
        "                config.num_puzzle_identifiers,\n",
        "                config.puzzle_emb_ndim,\n",
        "                batch_size=config.batch_size,\n",
        "                init_std=0,  # Zero init puzzle embeddings\n",
        "                cast_to=self.forward_dtype\n",
        "            )\n",
        "\n",
        "        # Position encodings\n",
        "        if config.pos_encodings == \"rope\":\n",
        "            self.rotary_emb = RotaryEmbedding(\n",
        "                dim=config.hidden_size // config.num_heads,\n",
        "                max_position_embeddings=config.seq_len + self.puzzle_emb_len,\n",
        "                base=config.rope_theta\n",
        "            )\n",
        "        elif config.pos_encodings == \"learned\":\n",
        "            self.embed_pos = CastedEmbedding(\n",
        "                config.seq_len + self.puzzle_emb_len,\n",
        "                config.hidden_size,\n",
        "                init_std=embed_init_std,\n",
        "                cast_to=self.forward_dtype\n",
        "            )\n",
        "\n",
        "        # Reasoning layers (L-level)\n",
        "        self.L_level = TRMReasoningModule(\n",
        "            layers=[TRMBlock(config) for _ in range(config.L_layers)]\n",
        "        )\n",
        "\n",
        "        # Initial states for H and L\n",
        "        self.H_init = nn.Buffer(\n",
        "            trunc_normal_init_(torch.empty(config.hidden_size, dtype=self.forward_dtype), std=1),\n",
        "            persistent=True\n",
        "        )\n",
        "        self.L_init = nn.Buffer(\n",
        "            trunc_normal_init_(torch.empty(config.hidden_size, dtype=self.forward_dtype), std=1),\n",
        "            persistent=True\n",
        "        )\n",
        "\n",
        "        # Initialize Q-head to near-zero for faster learning\n",
        "        with torch.no_grad():\n",
        "            self.q_head.weight.zero_()\n",
        "            self.q_head.bias.fill_(-5)\n",
        "\n",
        "    def _input_embeddings(self, input: torch.Tensor, puzzle_identifiers: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute input embeddings including puzzle embeddings and position encodings.\"\"\"\n",
        "        # Token embedding\n",
        "        embedding = self.embed_tokens(input.to(torch.int32))\n",
        "\n",
        "        # Puzzle embeddings\n",
        "        if self.config.puzzle_emb_ndim > 0:\n",
        "            puzzle_embedding = self.puzzle_emb(puzzle_identifiers)\n",
        "\n",
        "            # Pad if needed\n",
        "            pad_count = self.puzzle_emb_len * self.config.hidden_size - puzzle_embedding.shape[-1]\n",
        "            if pad_count > 0:\n",
        "                puzzle_embedding = F.pad(puzzle_embedding, (0, pad_count))\n",
        "\n",
        "            # Reshape and prepend to embedding\n",
        "            embedding = torch.cat(\n",
        "                (puzzle_embedding.view(-1, self.puzzle_emb_len, self.config.hidden_size), embedding),\n",
        "                dim=-2\n",
        "            )\n",
        "\n",
        "        # Learned position embeddings\n",
        "        if self.config.pos_encodings == \"learned\":\n",
        "            embedding = 0.707106781 * (embedding + self.embed_pos.embedding_weight.to(self.forward_dtype))\n",
        "\n",
        "        # Scale\n",
        "        return self.embed_scale * embedding\n",
        "\n",
        "    def empty_carry(self, batch_size: int):\n",
        "        \"\"\"Create empty carry state (with device fix for CUDA compatibility).\"\"\"\n",
        "        # Get device from model parameters if available\n",
        "        device = next(self.parameters()).device if list(self.parameters()) else None\n",
        "\n",
        "        return TRMInnerCarry(\n",
        "            z_H=torch.empty(batch_size, self.config.seq_len + self.puzzle_emb_len, self.config.hidden_size, dtype=self.forward_dtype, device=device),\n",
        "            z_L=torch.empty(batch_size, self.config.seq_len + self.puzzle_emb_len, self.config.hidden_size, dtype=self.forward_dtype, device=device),\n",
        "        )\n",
        "\n",
        "    def reset_carry(self, reset_flag: torch.Tensor, carry: TRMInnerCarry):\n",
        "        \"\"\"Reset carry state for halted sequences (with device fix for CUDA compatibility).\"\"\"\n",
        "        # Ensure buffers are on the same device as carry (fix for CUDA)\n",
        "        device = carry.z_H.device\n",
        "        H_init = self.H_init.to(device)\n",
        "        L_init = self.L_init.to(device)\n",
        "\n",
        "        return TRMInnerCarry(\n",
        "            z_H=torch.where(reset_flag.view(-1, 1, 1), H_init, carry.z_H),\n",
        "            z_L=torch.where(reset_flag.view(-1, 1, 1), L_init, carry.z_L),\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        carry: TRMInnerCarry,\n",
        "        batch: Dict[str, torch.Tensor]\n",
        "    ) -> Tuple[TRMInnerCarry, torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        \"\"\"Forward pass through TRM.\"\"\"\n",
        "\n",
        "        # Get RoPE embeddings\n",
        "        cos_sin = self.rotary_emb() if hasattr(self, \"rotary_emb\") else None\n",
        "        seq_info = dict(cos_sin=cos_sin)\n",
        "\n",
        "        # Input encoding\n",
        "        input_embeddings = self._input_embeddings(batch[\"inputs\"], batch[\"puzzle_identifiers\"])\n",
        "\n",
        "        # Recursive reasoning\n",
        "        z_H, z_L = carry.z_H, carry.z_L\n",
        "\n",
        "        # H_cycles-1 iterations without gradient (for efficiency)\n",
        "        with torch.no_grad():\n",
        "            for _H_step in range(self.config.H_cycles - 1):\n",
        "                for _L_step in range(self.config.L_cycles):\n",
        "                    z_L = self.L_level(z_L, z_H + input_embeddings, **seq_info)\n",
        "                z_H = self.L_level(z_H, z_L, **seq_info)\n",
        "\n",
        "        # Last H-cycle with gradient\n",
        "        for _L_step in range(self.config.L_cycles):\n",
        "            z_L = self.L_level(z_L, z_H + input_embeddings, **seq_info)\n",
        "        z_H = self.L_level(z_H, z_L, **seq_info)\n",
        "\n",
        "        # LM Outputs\n",
        "        new_carry = TRMInnerCarry(z_H=z_H.detach(), z_L=z_L.detach())  # New carry no grad\n",
        "        output = self.lm_head(z_H)[:, self.puzzle_emb_len:]\n",
        "        q_logits = self.q_head(z_H[:, 0]).to(torch.float32) # Q-head; uses the first puzzle_emb position\n",
        "        return new_carry, output, (q_logits[..., 0], q_logits[..., 1])\n",
        "\n",
        "\n",
        "# ============ TRM with ACT Wrapper ============\n",
        "class OriginalTRM(nn.Module):\n",
        "    \"\"\"Original TinyRecursiveReasoningModel with Adaptive Computation Time (ACT).\"\"\"\n",
        "\n",
        "    def __init__(self, config_dict: dict):\n",
        "        super().__init__()\n",
        "        self.config = OriginalTRMConfig(**config_dict)\n",
        "        self.inner = TRMInner(self.config)\n",
        "\n",
        "    @property\n",
        "    def puzzle_emb(self):\n",
        "        return self.inner.puzzle_emb\n",
        "\n",
        "    def initial_carry(self, batch: Dict[str, torch.Tensor]):\n",
        "        \"\"\"Initialize carry state for a batch (with device fix for CUDA compatibility).\"\"\"\n",
        "        batch_size = batch[\"inputs\"].shape[0]\n",
        "        device = batch[\"inputs\"].device\n",
        "\n",
        "        # Move model to device if needed (ensures buffers are on correct device)\n",
        "        if next(self.inner.parameters()).device != device:\n",
        "            self.inner = self.inner.to(device)\n",
        "\n",
        "        return TRMCarry(\n",
        "            inner_carry=self.inner.empty_carry(batch_size),\n",
        "            steps=torch.zeros((batch_size,), dtype=torch.int32, device=device),\n",
        "            halted=torch.ones((batch_size,), dtype=torch.bool, device=device),  # Start halted to trigger reset\n",
        "            current_data={k: torch.empty_like(v) for k, v in batch.items()}\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        carry: TRMCarry,\n",
        "        batch: Dict[str, torch.Tensor]\n",
        "    ) -> Tuple[TRMCarry, Dict[str, torch.Tensor]]:\n",
        "        \"\"\"Forward pass with ACT.\"\"\"\n",
        "\n",
        "        # Update data, carry (removing halted sequences)\n",
        "        new_inner_carry = self.inner.reset_carry(carry.halted, carry.inner_carry)\n",
        "\n",
        "        new_steps = torch.where(carry.halted, 0, carry.steps)\n",
        "\n",
        "        new_current_data = {k: torch.where(carry.halted.view((-1, ) + (1, ) * (batch[k].ndim - 1)), batch[k], v) for k, v in carry.current_data.items()}\n",
        "\n",
        "        # Forward inner model\n",
        "        new_inner_carry, logits, (q_halt_logits, q_continue_logits) = self.inner(new_inner_carry, new_current_data)\n",
        "\n",
        "        outputs = {\n",
        "            \"logits\": logits,\n",
        "            \"q_halt_logits\": q_halt_logits,\n",
        "            \"q_continue_logits\": q_continue_logits\n",
        "        }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Step\n",
        "            new_steps = new_steps + 1\n",
        "            is_last_step = new_steps >= self.config.halt_max_steps\n",
        "\n",
        "            halted = is_last_step\n",
        "\n",
        "            # if training, and ACT is enabled\n",
        "            if self.training and (self.config.halt_max_steps > 1):\n",
        "\n",
        "                # Halt signal\n",
        "                # NOTE: During evaluation, always use max steps, this is to guarantee the same halting steps inside a batch for batching purposes\n",
        "\n",
        "                if self.config.no_ACT_continue:\n",
        "                    halted = halted | (q_halt_logits > 0)\n",
        "                else:\n",
        "                    halted = halted | (q_halt_logits > q_continue_logits)\n",
        "\n",
        "                # Exploration\n",
        "                min_halt_steps = (torch.rand_like(q_halt_logits) < self.config.halt_exploration_prob) * torch.randint_like(new_steps, low=2, high=self.config.halt_max_steps + 1)\n",
        "                halted = halted & (new_steps >= min_halt_steps)\n",
        "\n",
        "                if not self.config.no_ACT_continue:\n",
        "                    # Compute target Q\n",
        "                    # NOTE: No replay buffer and target networks for computing target Q-value.\n",
        "                    # As batch_size is large, there're many parallel envs.\n",
        "                    # Similar concept as PQN https://arxiv.org/abs/2407.04811\n",
        "                    _, _, (next_q_halt_logits, next_q_continue_logits) = self.inner(new_inner_carry, new_current_data)\n",
        "                    outputs[\"target_q_continue\"] = torch.sigmoid(torch.where(is_last_step, next_q_halt_logits, torch.maximum(next_q_halt_logits, next_q_continue_logits)))\n",
        "\n",
        "        return TRMCarry(new_inner_carry, new_steps, halted, new_current_data), outputs\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Original TRM Model defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Model components:\")\n",
        "print(\"  - OriginalTRMConfig: Model configuration\")\n",
        "print(\"  - TRMBlock: Single transformer block\")\n",
        "print(\"  - TRMReasoningModule: Stack of TRM blocks\")\n",
        "print(\"  - TRMInner: Core reasoning model\")\n",
        "print(\"  - OriginalTRM: Full model with ACT wrapper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajj5bUQglQNN"
      },
      "source": [
        "## Cell 14: Original Loss Functions\n",
        "\n",
        "Loss functions for training TRM:\n",
        "- **Stablemax Cross-Entropy**: More stable alternative to softmax for numerical stability\n",
        "- **ACTLossHead**: Combines LM loss with Q-learning losses for ACT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0GOC3UslQNN",
        "outputId": "adf572d4-08f2-419d-a5ed-dbc9e2da15ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Original Loss Functions defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Available functions:\n",
            "  - stablemax_cross_entropy: Stablemax-based cross-entropy\n",
            "  - softmax_cross_entropy: Standard cross-entropy\n",
            "  - ACTLossHead: Combined loss for TRM with ACT\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 14: Original Loss Functions\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# ============ Stablemax Functions ============\n",
        "def s(x: torch.Tensor, epsilon: float = 1e-30) -> torch.Tensor:\n",
        "    \"\"\"Stablemax helper function.\"\"\"\n",
        "    return torch.where(\n",
        "        x < 0,\n",
        "        1 / (1 - x + epsilon),\n",
        "        x + 1\n",
        "    )\n",
        "\n",
        "def log_stablemax(x: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
        "    \"\"\"Log-stablemax: more stable than log-softmax for certain distributions.\"\"\"\n",
        "    s_x = s(x)\n",
        "    return torch.log(s_x / torch.sum(s_x, dim=dim, keepdim=True))\n",
        "\n",
        "def stablemax_cross_entropy(\n",
        "    logits: torch.Tensor,\n",
        "    labels: torch.Tensor,\n",
        "    ignore_index: int = IGNORE_LABEL_ID,\n",
        "    valid_mask: torch.Tensor = None\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Cross-entropy loss using stablemax instead of softmax.\n",
        "\n",
        "    More numerically stable for certain distributions.\n",
        "    \"\"\"\n",
        "    logprobs = log_stablemax(logits.to(torch.float64), dim=-1)\n",
        "\n",
        "    if valid_mask is None:\n",
        "        valid_mask = (labels != ignore_index)\n",
        "\n",
        "    transformed_labels = torch.where(valid_mask, labels, 0)\n",
        "    prediction_logprobs = torch.gather(\n",
        "        logprobs,\n",
        "        index=transformed_labels.to(torch.long).unsqueeze(-1),\n",
        "        dim=-1\n",
        "    ).squeeze(-1)\n",
        "\n",
        "    return -torch.where(valid_mask, prediction_logprobs, 0)\n",
        "\n",
        "def softmax_cross_entropy(\n",
        "    logits: torch.Tensor,\n",
        "    labels: torch.Tensor,\n",
        "    ignore_index: int = IGNORE_LABEL_ID,\n",
        "    valid_mask: torch.Tensor = None  # unused, for API compatibility\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Standard softmax cross-entropy loss.\"\"\"\n",
        "    return F.cross_entropy(\n",
        "        logits.to(torch.float32).view(-1, logits.shape[-1]),\n",
        "        labels.to(torch.long).view(-1),\n",
        "        ignore_index=ignore_index,\n",
        "        reduction=\"none\"\n",
        "    ).view(labels.shape)\n",
        "\n",
        "\n",
        "# ============ ACT Loss Head ============\n",
        "class ACTLossHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss head for TRM with Adaptive Computation Time.\n",
        "\n",
        "    Combines:\n",
        "    1. LM loss (stablemax or softmax cross-entropy)\n",
        "    2. Q-halt loss (BCE for halting decision)\n",
        "    3. Q-continue loss (optional, for Q-learning)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, loss_type: str = \"stablemax_cross_entropy\"):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "        # Get loss function by name\n",
        "        loss_functions = {\n",
        "            \"stablemax_cross_entropy\": stablemax_cross_entropy,\n",
        "            \"softmax_cross_entropy\": softmax_cross_entropy\n",
        "        }\n",
        "        self.loss_fn = loss_functions[loss_type]\n",
        "\n",
        "    def initial_carry(self, *args, **kwargs):\n",
        "        return self.model.initial_carry(*args, **kwargs)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        return_keys: Sequence[str] = (),\n",
        "        **model_kwargs,\n",
        "    ) -> Tuple[Any, torch.Tensor, Dict[str, torch.Tensor], Optional[Dict[str, torch.Tensor]], torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass computing loss and metrics.\n",
        "\n",
        "        Returns:\n",
        "            - new_carry: Updated carry state\n",
        "            - loss: Total loss (LM + Q-halt + Q-continue)\n",
        "            - metrics: Dictionary of metrics (accuracy, loss components, etc.)\n",
        "            - detached_outputs: Requested output tensors (detached)\n",
        "            - all_halted: Whether all sequences have halted\n",
        "        \"\"\"\n",
        "        # Forward through model\n",
        "        new_carry, outputs = self.model(**model_kwargs)\n",
        "        labels = new_carry.current_data[\"labels\"]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Predictions\n",
        "            outputs[\"preds\"] = torch.argmax(outputs[\"logits\"], dim=-1)\n",
        "\n",
        "            # Compute correctness\n",
        "            mask = (labels != IGNORE_LABEL_ID)\n",
        "            loss_counts = mask.sum(-1)\n",
        "            loss_divisor = loss_counts.clamp_min(1).unsqueeze(-1)\n",
        "\n",
        "            is_correct = mask & (torch.argmax(outputs[\"logits\"], dim=-1) == labels)\n",
        "            seq_is_correct = is_correct.sum(-1) == loss_counts\n",
        "\n",
        "            # Metrics (only for halted sequences)\n",
        "            valid_metrics = new_carry.halted & (loss_counts > 0)\n",
        "            metrics = {\n",
        "                \"count\": valid_metrics.sum(),\n",
        "                \"accuracy\": torch.where(valid_metrics, (is_correct.to(torch.float32) / loss_divisor).sum(-1), 0).sum(),\n",
        "                \"exact_accuracy\": (valid_metrics & seq_is_correct).sum(),\n",
        "                \"q_halt_accuracy\": (valid_metrics & ((outputs[\"q_halt_logits\"] >= 0) == seq_is_correct)).sum(),\n",
        "                \"steps\": torch.where(valid_metrics, new_carry.steps, 0).sum(),\n",
        "            }\n",
        "\n",
        "        # Losses\n",
        "        lm_loss = (self.loss_fn(outputs[\"logits\"], labels, ignore_index=IGNORE_LABEL_ID, valid_mask=mask) / loss_divisor).sum()\n",
        "        q_halt_loss = F.binary_cross_entropy_with_logits(\n",
        "            outputs[\"q_halt_logits\"],\n",
        "            seq_is_correct.to(outputs[\"q_halt_logits\"].dtype),\n",
        "            reduction=\"sum\"\n",
        "        )\n",
        "\n",
        "        metrics.update({\n",
        "            \"lm_loss\": lm_loss.detach(),\n",
        "            \"q_halt_loss\": q_halt_loss.detach(),\n",
        "        })\n",
        "\n",
        "        # Q-continue loss (optional)\n",
        "        q_continue_loss = 0\n",
        "        if \"target_q_continue\" in outputs:\n",
        "            q_continue_loss = F.binary_cross_entropy_with_logits(\n",
        "                outputs[\"q_continue_logits\"],\n",
        "                outputs[\"target_q_continue\"],\n",
        "                reduction=\"sum\"\n",
        "            )\n",
        "            metrics[\"q_continue_loss\"] = q_continue_loss.detach()\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = lm_loss + 0.5 * (q_halt_loss + q_continue_loss)\n",
        "\n",
        "        # Detached outputs\n",
        "        detached_outputs = {k: outputs[k].detach() for k in return_keys if k in outputs}\n",
        "\n",
        "        return new_carry, total_loss, metrics, detached_outputs, new_carry.halted.all()\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Original Loss Functions defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Available functions:\")\n",
        "print(\"  - stablemax_cross_entropy: Stablemax-based cross-entropy\")\n",
        "print(\"  - softmax_cross_entropy: Standard cross-entropy\")\n",
        "print(\"  - ACTLossHead: Combined loss for TRM with ACT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ4oNpxalQNN"
      },
      "source": [
        "## Cell 15: Test Original TRM Model\n",
        "\n",
        "Verify that the original TRM model works correctly by:\n",
        "1. Creating a model instance with Sudoku configuration\n",
        "2. Running a forward pass with sample data\n",
        "3. Checking output shapes and loss computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5CA6koBklQNN"
      },
      "outputs": [],
      "source": [
        "# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# # Cell 15: Test Original TRM Model\n",
        "# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# print(\"=\"*70)\n",
        "# print(\"ğŸ§ª Testing Original TRM Model\")\n",
        "# print(\"=\"*70)\n",
        "\n",
        "# # ============ Model Configuration for Sudoku ============\n",
        "# BATCH_SIZE = 32\n",
        "# SEQ_LEN = 81  # 9x9 Sudoku\n",
        "\n",
        "# original_trm_config = {\n",
        "#     # Data dimensions\n",
        "#     \"batch_size\": BATCH_SIZE,\n",
        "#     \"seq_len\": SEQ_LEN,\n",
        "#     \"vocab_size\": train_metadata.vocab_size,  # 11 for Sudoku (0-9 + pad)\n",
        "#     \"num_puzzle_identifiers\": train_metadata.num_puzzle_identifiers,\n",
        "\n",
        "#     # Model dimensions\n",
        "#     \"hidden_size\": 512,\n",
        "#     \"expansion\": 4.0,\n",
        "#     \"num_heads\": 8,\n",
        "\n",
        "#     # Puzzle embeddings\n",
        "#     \"puzzle_emb_ndim\": 512,\n",
        "#     \"puzzle_emb_len\": 16,\n",
        "\n",
        "#     # Recursion structure\n",
        "#     \"H_cycles\": 3,\n",
        "#     \"L_cycles\": 6,\n",
        "#     \"H_layers\": 0,\n",
        "#     \"L_layers\": 2,\n",
        "\n",
        "#     # Position encoding\n",
        "#     \"pos_encodings\": \"rope\",\n",
        "#     \"rope_theta\": 10000.0,\n",
        "\n",
        "#     # ACT\n",
        "#     \"halt_max_steps\": 16,\n",
        "#     \"halt_exploration_prob\": 0.1,\n",
        "\n",
        "#     # Dtype\n",
        "#     \"forward_dtype\": \"bfloat16\",\n",
        "\n",
        "#     # Options\n",
        "#     \"mlp_t\": False,\n",
        "#     \"no_ACT_continue\": True,\n",
        "# }\n",
        "\n",
        "# print(\"\\nğŸ“‹ Model Configuration:\")\n",
        "# for k, v in original_trm_config.items():\n",
        "#     print(f\"  {k}: {v}\")\n",
        "\n",
        "# # ============ Create Model ============\n",
        "# print(\"\\nğŸ”§ Creating Original TRM model...\")\n",
        "# original_model = OriginalTRM(original_trm_config)\n",
        "# original_model = original_model.to(DEVICE)\n",
        "\n",
        "# # Count parameters\n",
        "# total_params = sum(p.numel() for p in original_model.parameters())\n",
        "# trainable_params = sum(p.numel() for p in original_model.parameters() if p.requires_grad)\n",
        "# print(f\"  Total parameters: {total_params:,}\")\n",
        "# print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# # ============ Create Loss Head ============\n",
        "# print(\"\\nğŸ¯ Creating ACTLossHead...\")\n",
        "# original_loss_head = ACTLossHead(original_model, loss_type=\"stablemax_cross_entropy\")\n",
        "# original_loss_head = original_loss_head.to(DEVICE)\n",
        "\n",
        "# # ============ Test Forward Pass ============\n",
        "# print(\"\\nğŸš€ Running test forward pass...\")\n",
        "\n",
        "# # Create test batch\n",
        "# test_train_dataset = PuzzleDataset(\n",
        "#     dataset_paths=[OUTPUT_DIR],\n",
        "#     global_batch_size=BATCH_SIZE,\n",
        "#     seed=42,\n",
        "#     test_set_mode=False,\n",
        "#     epochs_per_iter=1,\n",
        "#     rank=0,\n",
        "#     num_replicas=1,\n",
        "#     split=\"train\"\n",
        "# )\n",
        "\n",
        "# test_dataloader = DataLoader(test_train_dataset, batch_size=None)\n",
        "# _, test_batch, _ = next(iter(test_dataloader))\n",
        "\n",
        "# # Move to device\n",
        "# test_batch = {k: v.to(DEVICE) for k, v in test_batch.items()}\n",
        "\n",
        "# print(f\"  Input shape: {test_batch['inputs'].shape}\")\n",
        "# print(f\"  Labels shape: {test_batch['labels'].shape}\")\n",
        "\n",
        "# # Initialize carry\n",
        "# original_model.train()\n",
        "# carry = original_loss_head.initial_carry(batch=test_batch)\n",
        "\n",
        "# # Forward pass\n",
        "# new_carry, loss, metrics, outputs, all_halted = original_loss_head(\n",
        "#     return_keys=[\"logits\", \"preds\"],\n",
        "#     carry=carry,\n",
        "#     batch=test_batch\n",
        "# )\n",
        "\n",
        "# print(f\"\\nğŸ“Š Forward pass results:\")\n",
        "# print(f\"  Loss: {loss.item():.4f}\")\n",
        "# print(f\"  LM Loss: {metrics['lm_loss'].item():.4f}\")\n",
        "# print(f\"  Q-Halt Loss: {metrics['q_halt_loss'].item():.4f}\")\n",
        "# print(f\"  Accuracy: {metrics['accuracy'].item() / max(metrics['count'].item(), 1):.4f}\")\n",
        "# print(f\"  Exact Accuracy: {metrics['exact_accuracy'].item() / max(metrics['count'].item(), 1):.4f}\")\n",
        "# print(f\"  All Halted: {all_halted}\")\n",
        "\n",
        "# # ============ Test ACT Loop ============\n",
        "# print(\"\\nğŸ”„ Testing ACT loop (multiple steps)...\")\n",
        "# carry = original_loss_head.initial_carry(batch=test_batch)\n",
        "\n",
        "# step = 0\n",
        "# while not all_halted and step < 20:  # Max 20 steps for safety\n",
        "#     new_carry, loss, metrics, outputs, all_halted = original_loss_head(\n",
        "#         return_keys=[],\n",
        "#         carry=carry,\n",
        "#         batch=test_batch\n",
        "#     )\n",
        "#     carry = new_carry\n",
        "#     step += 1\n",
        "\n",
        "#     halted_count = carry.halted.sum().item()\n",
        "#     print(f\"  Step {step}: Loss={loss.item():.4f}, Halted={halted_count}/{BATCH_SIZE}, \"\n",
        "#           f\"Exact Acc={metrics['exact_accuracy'].item() / max(metrics['count'].item(), 1):.4f}\")\n",
        "\n",
        "# print(f\"\\nâœ… ACT completed in {step} steps\")\n",
        "\n",
        "# print(\"\\n\" + \"=\"*70)\n",
        "# print(\"âœ… Part 2 Complete! Original TRM Model is working.\")\n",
        "# print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPe9QsiXlQNN"
      },
      "source": [
        "# ğŸ“¦ Part 3: Training & Evaluation Framework\n",
        "\n",
        "This section implements the training and evaluation framework for the TRM model.\n",
        "\n",
        "## Components:\n",
        "1. **TRMTrainer**: Trainer class for the original TRM model\n",
        "2. **evaluate()**: Evaluation function with metrics logging\n",
        "3. **train_epoch()**: Single epoch training with W&B logging\n",
        "4. **Learning rate scheduler**: Cosine annealing with warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEYqeOwTlQNN"
      },
      "source": [
        "## Cell 22: Learning Rate Scheduler\n",
        "\n",
        "Cosine annealing with linear warmup - standard for transformer training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCdXR9QYlQNN",
        "outputId": "81e2431b-abad-437c-a36d-1a1bddc9c04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Learning Rate Scheduler and Optimizer defined!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 22: Learning Rate Scheduler\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def get_lr_scheduler(optimizer, warmup_steps: int, total_steps: int, min_lr_ratio: float = 0.1):\n",
        "    \"\"\"\n",
        "    Create a learning rate scheduler with linear warmup and cosine annealing.\n",
        "\n",
        "    Args:\n",
        "        optimizer: PyTorch optimizer\n",
        "        warmup_steps: Number of warmup steps\n",
        "        total_steps: Total training steps\n",
        "        min_lr_ratio: Minimum LR as ratio of initial LR\n",
        "\n",
        "    Returns:\n",
        "        LambdaLR scheduler\n",
        "    \"\"\"\n",
        "    def lr_lambda(current_step: int) -> float:\n",
        "        if current_step < warmup_steps:\n",
        "            # Linear warmup\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        else:\n",
        "            # Cosine annealing\n",
        "            progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "            return max(min_lr_ratio, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def get_optimizer(model, lr: float, weight_decay: float, betas: Tuple[float, float] = (0.9, 0.95)):\n",
        "    \"\"\"\n",
        "    Create AdamW optimizer with parameter groups.\n",
        "\n",
        "    Separates:\n",
        "    - Main parameters (with weight decay)\n",
        "    - Bias and LayerNorm parameters (no weight decay)\n",
        "    - LoRA parameters (separate group)\n",
        "\n",
        "    Filters out:\n",
        "    - Non-leaf tensors (which can't be optimized)\n",
        "    - Buffers (even if requires_grad=True, they're handled separately by SignSGD)\n",
        "    - Non nn.Parameter objects (extra safety)\n",
        "    \"\"\"\n",
        "    # Get all buffer data_ptrs for identity comparison\n",
        "    buffer_data_ptrs = {buf.data_ptr() for _, buf in model.named_buffers()}\n",
        "\n",
        "    # Separate parameters\n",
        "    decay_params = []\n",
        "    no_decay_params = []\n",
        "    lora_params = []\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "\n",
        "        # Skip if this tensor is actually a buffer (check by data_ptr)\n",
        "        if param.data_ptr() in buffer_data_ptrs:\n",
        "            print(f\"  âš ï¸ Skipping buffer masquerading as parameter: {name}\")\n",
        "            continue\n",
        "\n",
        "        # Skip non-leaf tensors (views, computed tensors, etc.)\n",
        "        if not param.is_leaf:\n",
        "            print(f\"  âš ï¸ Skipping non-leaf parameter: {name}\")\n",
        "            continue\n",
        "\n",
        "        # Skip if not actually an nn.Parameter (extra safety)\n",
        "        if not isinstance(param, nn.Parameter):\n",
        "            print(f\"  âš ï¸ Skipping non-Parameter tensor: {name}\")\n",
        "            continue\n",
        "\n",
        "        if 'lora' in name.lower():\n",
        "            lora_params.append(param)\n",
        "        elif 'bias' in name or 'norm' in name.lower() or 'ln' in name.lower():\n",
        "            no_decay_params.append(param)\n",
        "        else:\n",
        "            decay_params.append(param)\n",
        "\n",
        "    # Validate all parameters are leaf tensors before creating optimizer\n",
        "    all_params = decay_params + no_decay_params + lora_params\n",
        "    for param in all_params:\n",
        "        if not param.is_leaf:\n",
        "            raise ValueError(\n",
        "                f\"Found non-leaf tensor in optimizer parameters. \"\n",
        "                f\"This usually means a parameter is a view or computed tensor. \"\n",
        "                f\"Parameter shape: {param.shape}, requires_grad: {param.requires_grad}\"\n",
        "            )\n",
        "\n",
        "    param_groups = []\n",
        "    if decay_params:\n",
        "        param_groups.append({'params': decay_params, 'weight_decay': weight_decay})\n",
        "    if no_decay_params:\n",
        "        param_groups.append({'params': no_decay_params, 'weight_decay': 0.0})\n",
        "    if lora_params:\n",
        "        param_groups.append({'params': lora_params, 'weight_decay': 0.0, 'lr': lr})  # LoRA often uses same LR\n",
        "\n",
        "    try:\n",
        "        optimizer = torch.optim.AdamW(param_groups, lr=lr, betas=betas)\n",
        "    except RuntimeError as e:\n",
        "        if \"non-leaf\" in str(e).lower():\n",
        "            # Print which parameters are problematic\n",
        "            print(\"âŒ Error creating optimizer. Checking parameters...\")\n",
        "            for name, param in model.named_parameters():\n",
        "                if param.requires_grad and not param.is_leaf:\n",
        "                    print(f\"  Non-leaf parameter: {name}, shape: {param.shape}, is_leaf: {param.is_leaf}\")\n",
        "            raise RuntimeError(f\"Optimizer creation failed: {e}\")\n",
        "        raise\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Learning Rate Scheduler and Optimizer defined!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi3rnmEGlQNN"
      },
      "source": [
        "## Cell 23: TRMTrainer Class\n",
        "\n",
        "Trainer class for the TRM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOtQzNjUlQNN",
        "outputId": "37349a26-0183-4660-f1c0-829a87a7789c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… TRMTrainer class defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Trainer features:\n",
            "  - Unified training for Original and Optimized TRM\n",
            "  - ACT loop with proper halting\n",
            "  - Sparse embedding optimizer support\n",
            "  - EMA support for evaluation\n",
            "  - W&B logging\n",
            "  - Checkpoint save/load\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 23: TRMTrainer Class\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "@dataclass\n",
        "class TrainerConfig:\n",
        "    \"\"\"Configuration for TRMTrainer.\"\"\"\n",
        "    # Training\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 0.1\n",
        "    warmup_steps: int = 500\n",
        "    max_steps: int = 10000\n",
        "    eval_interval: int = 500\n",
        "    log_interval: int = 50\n",
        "\n",
        "    # Batch\n",
        "    gradient_accumulation_steps: int = 1\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # EMA\n",
        "    use_ema: bool = False\n",
        "    ema_decay: float = 0.999\n",
        "\n",
        "    # Sparse embedding\n",
        "    puzzle_emb_lr: float = 1e-2\n",
        "    puzzle_emb_weight_decay: float = 0.1\n",
        "\n",
        "    # W&B\n",
        "    project_name: str = \"TRM-Comparison\"\n",
        "    run_name: Optional[str] = None\n",
        "\n",
        "    # Save\n",
        "    save_dir: str = \"checkpoints\"\n",
        "    save_best: bool = True\n",
        "\n",
        "\n",
        "class TRMTrainer:\n",
        "    \"\"\"\n",
        "    Unified trainer for TinyRecursiveModels.\n",
        "\n",
        "    Works with both Original and Optimized TRM models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        loss_head: nn.Module,\n",
        "        train_dataloader: DataLoader,\n",
        "        eval_dataloader: DataLoader,\n",
        "        config: TrainerConfig,\n",
        "        device: torch.device,\n",
        "\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.loss_head = loss_head\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.eval_dataloader = eval_dataloader\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = get_optimizer(\n",
        "            model,\n",
        "            lr=config.lr,\n",
        "            weight_decay=config.weight_decay\n",
        "        )\n",
        "\n",
        "        # Scheduler\n",
        "        self.scheduler = get_lr_scheduler(\n",
        "            self.optimizer,\n",
        "            warmup_steps=config.warmup_steps,\n",
        "            total_steps=config.max_steps,\n",
        "            min_lr_ratio=0.1\n",
        "        )\n",
        "\n",
        "        # Sparse embedding optimizer (if applicable)\n",
        "        # NOTE: Use puzzle_emb.buffers() as in original pretrain.py\n",
        "        self.sparse_emb_optimizer = None\n",
        "        if hasattr(model, 'puzzle_emb'):\n",
        "            puzzle_emb = model.puzzle_emb\n",
        "            if hasattr(puzzle_emb, 'weights'):\n",
        "                # Create sparse embedding optimizer using buffers() method\n",
        "                # This matches the original implementation in pretrain.py\n",
        "                sparse_buffers = list(puzzle_emb.buffers())\n",
        "                self.sparse_emb_optimizer = CastedSparseEmbeddingSignSGD(\n",
        "                    sparse_buffers,\n",
        "                    lr=config.puzzle_emb_lr,\n",
        "                    weight_decay=config.puzzle_emb_weight_decay\n",
        "                )\n",
        "\n",
        "        # EMA\n",
        "        self.ema = None\n",
        "        if config.use_ema:\n",
        "            self.ema = EMAHelper(mu=config.ema_decay)\n",
        "            self.ema.register(model)\n",
        "\n",
        "        # State\n",
        "        self.global_step = 0\n",
        "        self.best_eval_accuracy = 0.0\n",
        "\n",
        "        # Metrics accumulator\n",
        "        self.train_metrics = {}\n",
        "\n",
        "    def train_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:\n",
        "        \"\"\"Execute a single training step.\"\"\"\n",
        "        self.model.train()\n",
        "\n",
        "        # Move batch to device\n",
        "        batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "\n",
        "        # Initialize carry\n",
        "        carry = self.loss_head.initial_carry(batch=batch)\n",
        "\n",
        "        # ACT loop\n",
        "        total_loss = 0.0\n",
        "        accumulated_metrics = {}\n",
        "        step_count = 0\n",
        "        all_halted = False\n",
        "\n",
        "        while not all_halted and step_count < 50:  # Safety limit\n",
        "            new_carry, loss, metrics, outputs, all_halted = self.loss_head(\n",
        "                return_keys=[],\n",
        "                carry=carry,\n",
        "                batch=batch\n",
        "            )\n",
        "            carry = new_carry\n",
        "            total_loss = total_loss + loss\n",
        "            step_count += 1\n",
        "\n",
        "            # Accumulate metrics\n",
        "            for k, v in metrics.items():\n",
        "                if k not in accumulated_metrics:\n",
        "                    accumulated_metrics[k] = 0.0\n",
        "                accumulated_metrics[k] += v.item() if torch.is_tensor(v) else v\n",
        "\n",
        "        # Average loss over ACT steps\n",
        "        avg_loss = total_loss / max(step_count, 1)\n",
        "\n",
        "        # Backward\n",
        "        avg_loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        if self.config.max_grad_norm > 0:\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
        "\n",
        "        # Optimizer step\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Sparse embedding update\n",
        "        if self.sparse_emb_optimizer is not None:\n",
        "            self.sparse_emb_optimizer.step()\n",
        "            self.sparse_emb_optimizer.zero_grad()\n",
        "\n",
        "        # EMA update\n",
        "        if self.ema is not None:\n",
        "            self.ema.update(self.model)\n",
        "\n",
        "        # Compute metrics\n",
        "        count = accumulated_metrics.get('count', 1)\n",
        "        result_metrics = {\n",
        "            'loss': avg_loss.item(),\n",
        "            'lm_loss': accumulated_metrics.get('lm_loss', 0) / max(count, 1),\n",
        "            'q_halt_loss': accumulated_metrics.get('q_halt_loss', 0) / max(count, 1),\n",
        "            'accuracy': accumulated_metrics.get('accuracy', 0) / max(count, 1),\n",
        "            'exact_accuracy': accumulated_metrics.get('exact_accuracy', 0) / max(count, 1),\n",
        "            'steps': accumulated_metrics.get('steps', 0) / max(count, 1),\n",
        "            'lr': self.scheduler.get_last_lr()[0],\n",
        "        }\n",
        "\n",
        "        return result_metrics\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate(self, max_batches: int = 50) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate the model on the evaluation dataset.\"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # Use EMA model if available\n",
        "        eval_model = self.model\n",
        "        if self.ema is not None:\n",
        "            eval_model = self.ema.ema_copy(self.model)\n",
        "            eval_model.eval()\n",
        "\n",
        "        accumulated_metrics = {}\n",
        "        total_count = 0\n",
        "\n",
        "        for batch_idx, (_, batch, _) in enumerate(self.eval_dataloader):\n",
        "            if batch_idx >= max_batches:\n",
        "                break\n",
        "\n",
        "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "\n",
        "            # Initialize carry\n",
        "            if self.ema is not None:\n",
        "                # Create loss head for EMA model\n",
        "                eval_loss_head = ACTLossHead(eval_model, loss_type=\"stablemax_cross_entropy\")\n",
        "                carry = eval_loss_head.initial_carry(batch=batch)\n",
        "            else:\n",
        "                carry = self.loss_head.initial_carry(batch=batch)\n",
        "                eval_loss_head = self.loss_head\n",
        "\n",
        "            # ACT loop\n",
        "            all_halted = False\n",
        "            step_count = 0\n",
        "\n",
        "            while not all_halted and step_count < 50:\n",
        "                new_carry, loss, metrics, outputs, all_halted = eval_loss_head(\n",
        "                    return_keys=[],\n",
        "                    carry=carry,\n",
        "                    batch=batch\n",
        "                )\n",
        "                carry = new_carry\n",
        "                step_count += 1\n",
        "\n",
        "                # Accumulate only from halted samples\n",
        "                if all_halted or step_count >= 50:\n",
        "                    for k, v in metrics.items():\n",
        "                        if k not in accumulated_metrics:\n",
        "                            accumulated_metrics[k] = 0.0\n",
        "                        accumulated_metrics[k] += v.item() if torch.is_tensor(v) else v\n",
        "\n",
        "        # Compute final metrics\n",
        "        count = accumulated_metrics.get('count', 1)\n",
        "        eval_metrics = {\n",
        "            'eval_accuracy': accumulated_metrics.get('accuracy', 0) / max(count, 1),\n",
        "            'eval_exact_accuracy': accumulated_metrics.get('exact_accuracy', 0) / max(count, 1),\n",
        "            'eval_lm_loss': accumulated_metrics.get('lm_loss', 0) / max(count, 1),\n",
        "            'eval_steps': accumulated_metrics.get('steps', 0) / max(count, 1),\n",
        "            'eval_count': count,\n",
        "        }\n",
        "\n",
        "        return eval_metrics\n",
        "\n",
        "    def train(self, use_wandb: bool = True) -> Dict[str, List[float]]:\n",
        "        \"\"\"Main training loop.\"\"\"\n",
        "        # Initialize W&B\n",
        "        if use_wandb:\n",
        "            run_name = self.config.run_name or f\"{self.model_type}-{self.config.max_steps}steps\"\n",
        "            wandb.init(\n",
        "                project=self.config.project_name,\n",
        "                name=run_name,\n",
        "                config={\n",
        "\n",
        "                    \"lr\": self.config.lr,\n",
        "                    \"weight_decay\": self.config.weight_decay,\n",
        "                    \"warmup_steps\": self.config.warmup_steps,\n",
        "                    \"max_steps\": self.config.max_steps,\n",
        "                    \"use_ema\": self.config.use_ema,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        # Training history\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'train_accuracy': [],\n",
        "            'eval_accuracy': [],\n",
        "            'eval_exact_accuracy': [],\n",
        "        }\n",
        "\n",
        "        # Training loop\n",
        "        train_iter = iter(self.train_dataloader)\n",
        "        pbar = tqdm(range(self.config.max_steps), desc=\"Training\")\n",
        "\n",
        "        for step in pbar:\n",
        "            self.global_step = step\n",
        "\n",
        "            # Get batch\n",
        "            try:\n",
        "                _, batch, _ = next(train_iter)\n",
        "            except StopIteration:\n",
        "                train_iter = iter(self.train_dataloader)\n",
        "                _, batch, _ = next(train_iter)\n",
        "\n",
        "            # Train step\n",
        "            metrics = self.train_step(batch)\n",
        "\n",
        "            # Log training metrics\n",
        "            history['train_loss'].append(metrics['loss'])\n",
        "            history['train_accuracy'].append(metrics['accuracy'])\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'loss': f\"{metrics['loss']:.4f}\",\n",
        "                'acc': f\"{metrics['accuracy']:.4f}\",\n",
        "                'lr': f\"{metrics['lr']:.2e}\"\n",
        "            })\n",
        "\n",
        "            # Log to W&B (log every step for real-time monitoring)\n",
        "            if use_wandb and wandb.run is not None:\n",
        "                # Convert all values to Python scalars\n",
        "                log_dict = {}\n",
        "                for k, v in metrics.items():\n",
        "                    if torch.is_tensor(v):\n",
        "                        log_dict[f\"train/{k}\"] = v.item()\n",
        "                    elif isinstance(v, (int, float)):\n",
        "                        log_dict[f\"train/{k}\"] = float(v)\n",
        "                    else:\n",
        "                        log_dict[f\"train/{k}\"] = v\n",
        "\n",
        "                wandb.log(log_dict, step=step)\n",
        "\n",
        "            # Evaluation\n",
        "            if step > 0 and step % self.config.eval_interval == 0:\n",
        "                eval_metrics = self.evaluate()\n",
        "                history['eval_accuracy'].append(eval_metrics['eval_accuracy'])\n",
        "                history['eval_exact_accuracy'].append(eval_metrics['eval_exact_accuracy'])\n",
        "\n",
        "                print(f\"\\nğŸ“Š Step {step}: Eval Accuracy={eval_metrics['eval_accuracy']:.4f}, \"\n",
        "                      f\"Exact Accuracy={eval_metrics['eval_exact_accuracy']:.4f}\")\n",
        "\n",
        "                if use_wandb and wandb.run is not None:\n",
        "                    # Convert all values to Python scalars\n",
        "                    eval_log_dict = {}\n",
        "                    for k, v in eval_metrics.items():\n",
        "                        key = k.replace('eval_', '')\n",
        "                        if torch.is_tensor(v):\n",
        "                            eval_log_dict[f\"eval/{key}\"] = v.item()\n",
        "                        elif isinstance(v, (int, float)):\n",
        "                            eval_log_dict[f\"eval/{key}\"] = float(v)\n",
        "                        else:\n",
        "                            eval_log_dict[f\"eval/{key}\"] = v\n",
        "\n",
        "                    wandb.log(eval_log_dict, step=step)\n",
        "\n",
        "                # Save best model\n",
        "                if self.config.save_best and eval_metrics['eval_exact_accuracy'] > self.best_eval_accuracy:\n",
        "                    self.best_eval_accuracy = eval_metrics['eval_exact_accuracy']\n",
        "                    self.save_checkpoint(f\"best_{self.model_type}\")\n",
        "\n",
        "        # Final evaluation\n",
        "        final_metrics = self.evaluate()\n",
        "        print(f\"\\nğŸ Final: Eval Accuracy={final_metrics['eval_accuracy']:.4f}, \"\n",
        "              f\"Exact Accuracy={final_metrics['eval_exact_accuracy']:.4f}\")\n",
        "\n",
        "        if use_wandb and wandb.run is not None:\n",
        "            # Convert to scalars\n",
        "            final_log_dict = {\n",
        "                \"final/accuracy\": float(final_metrics['eval_accuracy']),\n",
        "                \"final/exact_accuracy\": float(final_metrics['eval_exact_accuracy']),\n",
        "            }\n",
        "            wandb.log(final_log_dict, step=self.config.max_steps)\n",
        "            wandb.finish()\n",
        "\n",
        "        return history\n",
        "\n",
        "    def save_checkpoint(self, name: str):\n",
        "        \"\"\"Save model checkpoint.\"\"\"\n",
        "        os.makedirs(self.config.save_dir, exist_ok=True)\n",
        "        path = os.path.join(self.config.save_dir, f\"{name}.pt\")\n",
        "\n",
        "        checkpoint = {\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'global_step': self.global_step,\n",
        "            'best_eval_accuracy': self.best_eval_accuracy,\n",
        "        }\n",
        "\n",
        "        if self.ema is not None:\n",
        "            checkpoint['ema_state_dict'] = self.ema.state_dict()\n",
        "\n",
        "        torch.save(checkpoint, path)\n",
        "        print(f\"  ğŸ’¾ Saved checkpoint to {path}\")\n",
        "\n",
        "    def load_checkpoint(self, path: str):\n",
        "        \"\"\"Load model checkpoint.\"\"\"\n",
        "        checkpoint = torch.load(path, map_location=self.device)\n",
        "\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        self.global_step = checkpoint['global_step']\n",
        "        self.best_eval_accuracy = checkpoint.get('best_eval_accuracy', 0.0)\n",
        "\n",
        "        if self.ema is not None and 'ema_state_dict' in checkpoint:\n",
        "            self.ema.load_state_dict(checkpoint['ema_state_dict'])\n",
        "\n",
        "        print(f\"  ğŸ“‚ Loaded checkpoint from {path}\")\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… TRMTrainer class defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Trainer features:\")\n",
        "print(\"  - Unified training for Original and Optimized TRM\")\n",
        "print(\"  - ACT loop with proper halting\")\n",
        "print(\"  - Sparse embedding optimizer support\")\n",
        "print(\"  - EMA support for evaluation\")\n",
        "print(\"  - W&B logging\")\n",
        "print(\"  - Checkpoint save/load\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoI2qfEhlQNN"
      },
      "source": [
        "## Cell 24: Quick Trainer Test\n",
        "\n",
        "Verify that the trainer works correctly with a few steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g3UswRS9lQNQ"
      },
      "outputs": [],
      "source": [
        "# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# # Cell 24: Quick Trainer Test\n",
        "# # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# print(\"=\"*70)\n",
        "# print(\"ğŸ§ª Quick Trainer Test\")\n",
        "# print(\"=\"*70)\n",
        "\n",
        "# # Create a small model for testing\n",
        "# test_config = {\n",
        "#     \"batch_size\": 16,\n",
        "#     \"seq_len\": 81,\n",
        "#     \"puzzle_emb_ndim\": 512,\n",
        "#     \"num_puzzle_identifiers\": train_metadata.num_puzzle_identifiers,\n",
        "#     \"vocab_size\": train_metadata.vocab_size,\n",
        "#     \"H_cycles\": 3,\n",
        "#     \"L_cycles\": 6,\n",
        "#     \"H_layers\": 0,\n",
        "#     \"L_layers\": 2,\n",
        "#     \"hidden_size\": 512,\n",
        "#     \"num_heads\": 8,\n",
        "#     \"expansion\": 4.0,\n",
        "#     \"puzzle_emb_len\": 16,\n",
        "#     \"pos_encodings\": \"rope\",\n",
        "#     \"halt_max_steps\": 4,  # Small for testing\n",
        "#     \"halt_exploration_prob\": 0.1,\n",
        "#     \"forward_dtype\": \"bfloat16\",\n",
        "#     \"mlp_t\": False,\n",
        "#     \"no_ACT_continue\": True,\n",
        "# }\n",
        "\n",
        "# # Create model\n",
        "# test_model = OriginalTRM(test_config)\n",
        "# test_model = test_model.to(DEVICE)\n",
        "# test_loss_head = ACTLossHead(test_model, loss_type=\"stablemax_cross_entropy\")\n",
        "\n",
        "# # Create dataloaders\n",
        "# test_train_dl = DataLoader(\n",
        "#     PuzzleDataset(\n",
        "#         dataset_paths=[OUTPUT_DIR],\n",
        "#         global_batch_size=16,\n",
        "#         seed=42,\n",
        "#         test_set_mode=False,\n",
        "#         epochs_per_iter=1,\n",
        "#         split=\"train\"\n",
        "#     ),\n",
        "#     batch_size=None\n",
        "# )\n",
        "\n",
        "# test_eval_dl = DataLoader(\n",
        "#     PuzzleDataset(\n",
        "#         dataset_paths=[OUTPUT_DIR],\n",
        "#         global_batch_size=16,\n",
        "#         seed=42,\n",
        "#         test_set_mode=True,\n",
        "#         epochs_per_iter=1,\n",
        "#         split=\"test\"\n",
        "#     ),\n",
        "#     batch_size=None\n",
        "# )\n",
        "\n",
        "# # Create trainer\n",
        "# trainer_config = TrainerConfig(\n",
        "#     lr=1e-4,\n",
        "#     weight_decay=0.1,\n",
        "#     warmup_steps=10,\n",
        "#     max_steps=20,  # Small for testing\n",
        "#     eval_interval=10,\n",
        "#     log_interval=5,\n",
        "#     use_ema=False,\n",
        "#     project_name=\"TRM-Baseline-Test\",\n",
        "#     run_name=\"quick-test\",\n",
        "# )\n",
        "\n",
        "# trainer = TRMTrainer(\n",
        "#     model=test_model,\n",
        "#     loss_head=test_loss_head,\n",
        "#     train_dataloader=test_train_dl,\n",
        "#     eval_dataloader=test_eval_dl,\n",
        "#     config=trainer_config,\n",
        "#     device=DEVICE,\n",
        "# )\n",
        "\n",
        "# print(\"\\nâœ… Trainer created successfully!\")\n",
        "# print(f\"  Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
        "# print(f\"  Max steps: {trainer_config.max_steps}\")\n",
        "# print(f\"  Eval interval: {trainer_config.eval_interval}\")\n",
        "\n",
        "# # Quick training test (just 2 steps)\n",
        "# print(\"\\nğŸš€ Running 2 quick training steps...\")\n",
        "# for i in range(2):\n",
        "#     _, batch, _ = next(iter(test_train_dl))\n",
        "#     metrics = trainer.train_step(batch)\n",
        "#     print(f\"  Step {i+1}: loss={metrics['loss']:.4f}, lr={metrics['lr']:.6f}\")\n",
        "\n",
        "# print(\"\\nâœ… Quick trainer test passed!\")\n",
        "# print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjLxGg2-lQNQ"
      },
      "source": [
        "# ğŸ“¦ Part 4: Experiment Configurations\n",
        "\n",
        "Define experiment configurations for training the TRM model.\n",
        "\n",
        "## Configuration:\n",
        "- Base model configuration matching the original paper\n",
        "- Training hyperparameters (LR, batch size, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOn3Lx6NlQNQ"
      },
      "source": [
        "## Cell 25: Experiment Configuration Factory\n",
        "\n",
        "Functions to create model configurations and models for each experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSc6AWKQlQNQ",
        "outputId": "0d28b43c-a048-4bbc-af0e-deb9b693f00e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Experiment configurations defined!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Available experiments:\n",
            "  - baseline: Original TRM model (baseline)\n",
            "  - baseline-ema: Original TRM with EMA\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============ Base Model Configurations ============\n",
        "\n",
        "def get_base_model_config(batch_size: int = 32) -> dict:\n",
        "    \"\"\"Get base model configuration matching the original paper.\"\"\"\n",
        "    return {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"seq_len\": 81,  # 9x9 Sudoku\n",
        "        \"num_puzzle_identifiers\": train_metadata.num_puzzle_identifiers,\n",
        "        \"vocab_size\": train_metadata.vocab_size,\n",
        "\n",
        "        # Architecture (matching the paper)\n",
        "        \"hidden_size\": 512,\n",
        "        \"expansion\": 4.0,\n",
        "        \"num_heads\": 8,\n",
        "\n",
        "        # Puzzle embeddings\n",
        "        \"puzzle_emb_ndim\": 512,\n",
        "        \"puzzle_emb_len\": 16,\n",
        "\n",
        "        # Recursion structure\n",
        "        \"H_cycles\": 3,\n",
        "        \"L_cycles\": 6,\n",
        "        \"H_layers\": 0,\n",
        "        \"L_layers\": 2,\n",
        "\n",
        "        # Position encoding\n",
        "        \"pos_encodings\": \"rope\",\n",
        "        \"rope_theta\": 10000.0,\n",
        "\n",
        "        # ACT\n",
        "        \"halt_max_steps\": 16,\n",
        "        \"halt_exploration_prob\": 0.1,\n",
        "\n",
        "        # Dtype\n",
        "        \"forward_dtype\": \"bfloat16\",\n",
        "\n",
        "        # Options\n",
        "        \"mlp_t\": False,\n",
        "        \"no_ACT_continue\": True,\n",
        "    }\n",
        "\n",
        "\n",
        "def get_trainer_config(\n",
        "    max_steps: int = 10000,\n",
        "    lr: float = 1e-4,\n",
        "    use_ema: bool = False,\n",
        "    run_name: str = \"trm-baseline\"\n",
        ") -> TrainerConfig:\n",
        "    \"\"\"Get trainer configuration.\"\"\"\n",
        "    return TrainerConfig(\n",
        "        lr=lr,\n",
        "        weight_decay=0.1,\n",
        "        warmup_steps=500,\n",
        "        max_steps=max_steps,\n",
        "        eval_interval=500,\n",
        "        log_interval=50,\n",
        "        use_ema=use_ema,\n",
        "        ema_decay=0.999,\n",
        "        puzzle_emb_lr=1e-2,\n",
        "        puzzle_emb_weight_decay=0.1,\n",
        "        project_name=\"TRM-Baseline\",\n",
        "        run_name=run_name,\n",
        "        save_dir=\"checkpoints\",\n",
        "        save_best=True,\n",
        "    )\n",
        "\n",
        "\n",
        "# ============ Experiment Configurations ============\n",
        "\n",
        "EXPERIMENTS = {\n",
        "    \"baseline\": {\n",
        "        \"description\": \"Original TRM model (baseline)\",\n",
        "        \"model_config_fn\": lambda: get_base_model_config(batch_size=128),\n",
        "        \"trainer_config_fn\": lambda max_steps: get_trainer_config(\n",
        "            max_steps=max_steps,\n",
        "            lr=1e-4,\n",
        "            use_ema=False,\n",
        "            run_name=\"baseline\"\n",
        "        ),\n",
        "    },\n",
        "    \"baseline-ema\": {\n",
        "        \"description\": \"Original TRM with EMA\",\n",
        "        \"model_config_fn\": lambda: get_base_model_config(batch_size=128),\n",
        "        \"trainer_config_fn\": lambda max_steps: get_trainer_config(\n",
        "            max_steps=max_steps,\n",
        "            lr=1e-4,\n",
        "            use_ema=True,\n",
        "            run_name=\"baseline-ema\"\n",
        "        ),\n",
        "    },\n",
        "}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Experiment configurations defined!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nğŸ“‹ Available experiments:\")\n",
        "for name, config in EXPERIMENTS.items():\n",
        "    print(f\"  - {name}: {config['description']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HzrCj2dlQNQ"
      },
      "source": [
        "# ğŸ“¦ Part 5: Run Experiments & Evaluation\n",
        "\n",
        "This section runs the training experiments and evaluates the results.\n",
        "\n",
        "## Training Process:\n",
        "1. Create model and trainer\n",
        "2. Train with W&B logging\n",
        "3. Evaluate on test set\n",
        "4. Save best checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUb4TPF9lQNQ"
      },
      "source": [
        "## Cell 26: Experiment Runner\n",
        "\n",
        "Helper function to run multiple experiments and collect results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHgat5bnlQNQ",
        "outputId": "d97e0976-954c-46fb-c10f-4bc2414eac5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Experiment Runner defined!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 26: Experiment Runner\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def run_experiment(\n",
        "    experiment_name: str,\n",
        "    max_steps: int = 10000,\n",
        "    use_wandb: bool = True,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Run a single experiment.\n",
        "\n",
        "    Args:\n",
        "        experiment_name: Name of the experiment (from EXPERIMENTS dict)\n",
        "        max_steps: Maximum training steps\n",
        "        use_wandb: Whether to log to W&B\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with training history and final metrics\n",
        "    \"\"\"\n",
        "    if experiment_name not in EXPERIMENTS:\n",
        "        raise ValueError(f\"Unknown experiment: {experiment_name}\")\n",
        "\n",
        "    exp_config = EXPERIMENTS[experiment_name]\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ğŸš€ Running Experiment: {experiment_name}\")\n",
        "    print(f\"   {exp_config['description']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Create model config\n",
        "    model_config = exp_config[\"model_config_fn\"]()\n",
        "\n",
        "    # Create model\n",
        "    model = OriginalTRM(model_config)\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Create loss head\n",
        "    loss_head = ACTLossHead(model, loss_type=\"stablemax_cross_entropy\")\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dl = DataLoader(\n",
        "        PuzzleDataset(\n",
        "            dataset_paths=[OUTPUT_DIR],\n",
        "            global_batch_size=model_config[\"batch_size\"],\n",
        "            seed=42,\n",
        "            test_set_mode=False,\n",
        "            epochs_per_iter=100,  # Multiple epochs per iteration\n",
        "            split=\"train\"\n",
        "        ),\n",
        "        batch_size=None\n",
        "    )\n",
        "\n",
        "    eval_dl = DataLoader(\n",
        "        PuzzleDataset(\n",
        "            dataset_paths=[OUTPUT_DIR],\n",
        "            global_batch_size=model_config[\"batch_size\"],\n",
        "            seed=42,\n",
        "            test_set_mode=True,\n",
        "            epochs_per_iter=1,\n",
        "            split=\"test\"\n",
        "        ),\n",
        "        batch_size=None\n",
        "    )\n",
        "\n",
        "    # Create trainer config\n",
        "    trainer_config = exp_config[\"trainer_config_fn\"](max_steps)\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = TRMTrainer(\n",
        "        model=model,\n",
        "        loss_head=loss_head,\n",
        "        train_dataloader=train_dl,\n",
        "        eval_dataloader=eval_dl,\n",
        "        config=trainer_config,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    # Print model info\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"\\nğŸ“Š Model Info:\")\n",
        "    print(f\"   Total parameters: {total_params:,}\")\n",
        "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\nğŸ‹ï¸ Training for {max_steps} steps...\")\n",
        "    history = trainer.train(use_wandb=use_wandb)\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\nğŸ“ˆ Final Evaluation...\")\n",
        "    final_metrics = trainer.evaluate(max_batches=100)\n",
        "\n",
        "    print(f\"\\nâœ… Experiment Complete!\")\n",
        "    print(f\"   Final Exact Accuracy: {final_metrics['eval_exact_accuracy']:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"experiment_name\": experiment_name,\n",
        "        \"history\": history,\n",
        "        \"final_metrics\": final_metrics,\n",
        "        \"model_config\": model_config,\n",
        "        \"trainer_config\": trainer_config.__dict__,\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Experiment Runner defined!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bvZqT8klQNQ"
      },
      "source": [
        "## Cell 27: Results Visualization\n",
        "\n",
        "Functions to visualize and compare experiment results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbjJAHKklQNQ",
        "outputId": "91de27dc-2a6f-42b3-948a-b888ad286ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "âœ… Visualization functions defined!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 27: Results Visualization\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def plot_experiment_comparison(results: Dict[str, Dict[str, Any]], metric: str = \"train_loss\"):\n",
        "    \"\"\"\n",
        "    Plot training curves for multiple experiments.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of experiment results\n",
        "        metric: Metric to plot ('train_loss', 'train_accuracy', 'eval_accuracy', etc.)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    colors = plt.cm.Set1(np.linspace(0, 1, len(results)))\n",
        "\n",
        "    for idx, (exp_name, exp_results) in enumerate(results.items()):\n",
        "        if \"error\" in exp_results:\n",
        "            continue\n",
        "\n",
        "        history = exp_results.get(\"history\", {})\n",
        "        if metric in history:\n",
        "            data = history[metric]\n",
        "            label = EXPERIMENTS[exp_name][\"name\"]\n",
        "            plt.plot(data, label=label, color=colors[idx], linewidth=2)\n",
        "\n",
        "    plt.xlabel(\"Steps\", fontsize=12)\n",
        "    plt.ylabel(metric.replace(\"_\", \" \").title(), fontsize=12)\n",
        "    plt.title(f\"Experiment Comparison: {metric.replace('_', ' ').title()}\", fontsize=14)\n",
        "    plt.legend(loc=\"best\", fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_final_results_bar(results: Dict[str, Dict[str, Any]]):\n",
        "    \"\"\"\n",
        "    Bar chart comparing final results across experiments.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of experiment results\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    exp_names = []\n",
        "    accuracies = []\n",
        "    exact_accuracies = []\n",
        "    params = []\n",
        "\n",
        "    for exp_name, exp_results in results.items():\n",
        "        if \"error\" in exp_results:\n",
        "            continue\n",
        "\n",
        "        exp_names.append(EXPERIMENTS[exp_name][\"name\"])\n",
        "        accuracies.append(exp_results.get(\"final_accuracy\", 0))\n",
        "        exact_accuracies.append(exp_results.get(\"final_exact_accuracy\", 0))\n",
        "        params.append(exp_results.get(\"trainable_params\", 0) / 1e6)  # In millions\n",
        "\n",
        "    colors = plt.cm.Set2(np.linspace(0, 1, len(exp_names)))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0].barh(exp_names, accuracies, color=colors)\n",
        "    axes[0].set_xlabel(\"Accuracy\")\n",
        "    axes[0].set_title(\"Final Accuracy\")\n",
        "    axes[0].set_xlim(0, 1)\n",
        "    for i, v in enumerate(accuracies):\n",
        "        axes[0].text(v + 0.02, i, f\"{v:.3f}\", va='center', fontsize=10)\n",
        "\n",
        "    # Exact Accuracy\n",
        "    axes[1].barh(exp_names, exact_accuracies, color=colors)\n",
        "    axes[1].set_xlabel(\"Exact Accuracy\")\n",
        "    axes[1].set_title(\"Final Exact Accuracy\")\n",
        "    axes[1].set_xlim(0, 1)\n",
        "    for i, v in enumerate(exact_accuracies):\n",
        "        axes[1].text(v + 0.02, i, f\"{v:.3f}\", va='center', fontsize=10)\n",
        "\n",
        "    # Parameters\n",
        "    axes[2].barh(exp_names, params, color=colors)\n",
        "    axes[2].set_xlabel(\"Trainable Parameters (M)\")\n",
        "    axes[2].set_title(\"Model Size\")\n",
        "    for i, v in enumerate(params):\n",
        "        axes[2].text(v + 0.1, i, f\"{v:.2f}M\", va='center', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def print_results_table(results: Dict[str, Dict[str, Any]]):\n",
        "    \"\"\"\n",
        "    Print a summary table of experiment results.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of experiment results\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"ğŸ“Š EXPERIMENT RESULTS SUMMARY\")\n",
        "    print(\"=\"*90)\n",
        "    print(f\"{'Experiment':<25} {'Type':<12} {'Params':<12} {'Accuracy':<12} {'Exact Acc':<12} {'Best Acc':<12}\")\n",
        "    print(\"-\"*90)\n",
        "\n",
        "    for exp_name, exp_results in results.items():\n",
        "        if \"error\" in exp_results:\n",
        "            print(f\"{exp_name:<25} ERROR: {exp_results['error'][:50]}\")\n",
        "            continue\n",
        "\n",
        "        model_type = exp_results.get(\"model_type\", \"?\")\n",
        "        trainable = exp_results.get(\"trainable_params\", 0)\n",
        "        final_acc = exp_results.get(\"final_accuracy\", 0)\n",
        "        exact_acc = exp_results.get(\"final_exact_accuracy\", 0)\n",
        "        best_acc = exp_results.get(\"best_accuracy\", 0)\n",
        "\n",
        "        print(f\"{exp_name:<25} {model_type:<12} {trainable/1e6:>10.2f}M {final_acc:>10.4f} {exact_acc:>12.4f} {best_acc:>10.4f}\")\n",
        "\n",
        "    print(\"=\"*90)\n",
        "\n",
        "\n",
        "def save_results_to_json(results: Dict[str, Dict[str, Any]], filepath: str = \"experiment_results.json\"):\n",
        "    \"\"\"\n",
        "    Save experiment results to JSON file.\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary of experiment results\n",
        "        filepath: Output file path\n",
        "    \"\"\"\n",
        "    # Convert tensors and non-serializable objects\n",
        "    serializable_results = {}\n",
        "    for exp_name, exp_results in results.items():\n",
        "        serializable_results[exp_name] = {}\n",
        "        for k, v in exp_results.items():\n",
        "            if k == \"history\":\n",
        "                serializable_results[exp_name][k] = {hk: [float(x) for x in hv] for hk, hv in v.items()}\n",
        "            elif isinstance(v, (int, float, str, bool)):\n",
        "                serializable_results[exp_name][k] = v\n",
        "            elif torch.is_tensor(v):\n",
        "                serializable_results[exp_name][k] = v.item()\n",
        "\n",
        "    with open(filepath, \"w\") as f:\n",
        "        json.dump(serializable_results, f, indent=2)\n",
        "\n",
        "    print(f\"ğŸ’¾ Results saved to {filepath}\")\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… Visualization functions defined!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJzbTUymlQNQ"
      },
      "source": [
        "## Cell 28: Run Experiments\n",
        "\n",
        "**âš ï¸ Training Configuration:**\n",
        "- Set `MAX_STEPS` to control training duration\n",
        "- Set `EXPERIMENTS_TO_RUN` to select which experiments to run\n",
        "- Set `USE_WANDB` to enable/disable W&B logging\n",
        "\n",
        "For quick testing, use small values. For full experiments, use larger values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejgIHs6YlQNQ",
        "outputId": "06396e1b-dd9d-47b7-e9b4-35b8836f7a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GPU cleanup functions defined!\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell: GPU å†…å­˜æ¸…ç†å‡½æ•°\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "def deep_clear_gpu():\n",
        "    \"\"\"å½»åº•æ¸…ç† GPU å†…å­˜\"\"\"\n",
        "    # åˆ é™¤å¸¸è§å˜é‡\n",
        "    vars_to_delete = [\n",
        "        'test_model', 'test_loss_head', 'trainer',\n",
        "        'model', 'loss_head', 'eval_model', 'eval_loss_head',\n",
        "        'original_model', 'original_loss_head',\n",
        "        'test_train_dl', 'test_eval_dl', 'train_dl', 'eval_dl',\n",
        "        'batch', 'test_batch', 'carry', 'new_carry', 'outputs',\n",
        "        'result', 'RESULTS'\n",
        "    ]\n",
        "\n",
        "    deleted = []\n",
        "    for var_name in vars_to_delete:\n",
        "        if var_name in globals():\n",
        "            del globals()[var_name]\n",
        "            deleted.append(var_name)\n",
        "\n",
        "    # å¼ºåˆ¶åƒåœ¾å›æ”¶\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # æ£€æŸ¥å†…å­˜\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
        "        reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
        "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "\n",
        "        print(\"=\"*70)\n",
        "        print(\"ğŸ§¹ GPU Memory After Cleanup\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"  Total: {total:.2f} GB\")\n",
        "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
        "        print(f\"  Reserved: {reserved:.2f} GB\")\n",
        "        print(f\"  Free: {total - reserved:.2f} GB\")\n",
        "        print(f\"\\n  Deleted variables: {', '.join(deleted) if deleted else 'None'}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "def cleanup_all_models():\n",
        "    \"\"\"æ¸…ç†æ‰€æœ‰æ¨¡å‹ï¼ˆåˆ«åå‡½æ•°ï¼‰\"\"\"\n",
        "    deep_clear_gpu()\n",
        "\n",
        "print(\"âœ… GPU cleanup functions defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8810d3291bc94b7994f744612744b03e",
            "9346060c96254aa5b7b4d0dea3888db5",
            "94e1bc2d3c074e4ebc1cc18d87eec3d0",
            "8e60ec224c1f48f7b7effc70c1d59ce3",
            "106b6736b48943f28b0d30afb9d1e798",
            "8ba7b2a3a08542c5b7b1c7334a6db9c8",
            "aafcd1ae86f34f48ac893e44fdc66cbd",
            "975aacb7c48544d5910ad92a8a01d8d9",
            "a34b3abcc54d42d6973dac6cd596fac7",
            "76167bb0a09d402cb15d55bcf9f1cb5c",
            "fd44217ea51342479518d9c31625e286"
          ]
        },
        "id": "GufaSqhslQNQ",
        "outputId": "c20fb76b-d3fb-4f4c-dd3e-8e31929af81e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ§¹ Cleaning GPU memory before experiment...\n",
            "======================================================================\n",
            "======================================================================\n",
            "ğŸ§¹ GPU Memory After Cleanup\n",
            "======================================================================\n",
            "  Total: 79.32 GB\n",
            "  Allocated: 0.00 GB\n",
            "  Reserved: 0.00 GB\n",
            "  Free: 79.32 GB\n",
            "\n",
            "  Deleted variables: batch\n",
            "======================================================================\n",
            "======================================================================\n",
            "ğŸš€ Running TRM Baseline Experiment\n",
            "======================================================================\n",
            "\n",
            "Configuration:\n",
            "  MAX_STEPS: 500\n",
            "  USE_WANDB: True\n",
            "  DEVICE: cuda\n",
            "\n",
            "ğŸ“‹ Running experiment: baseline\n",
            "\n",
            "======================================================================\n",
            "ğŸš€ Running Experiment: baseline\n",
            "   Original TRM model (baseline)\n",
            "======================================================================\n",
            "\n",
            "ğŸ“Š Model Info:\n",
            "   Total parameters: 6,828,034\n",
            "   Trainable parameters: 6,828,034\n",
            "\n",
            "ğŸ‹ï¸ Training for 500 steps...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251202_150805-4ebn4t7k</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline/runs/4ebn4t7k' target=\"_blank\">baseline</a></strong> to <a href='https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline' target=\"_blank\">https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline/runs/4ebn4t7k' target=\"_blank\">https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline/runs/4ebn4t7k</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8810d3291bc94b7994f744612744b03e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ Final: Eval Accuracy=0.4906, Exact Accuracy=0.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>final/accuracy</td><td>â–</td></tr><tr><td>final/exact_accuracy</td><td>â–</td></tr><tr><td>train/accuracy</td><td>â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/exact_accuracy</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/lm_loss</td><td>â–ˆâ–†â–†â–…â–…â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–‡â–‡â–†â–…â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/lr</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>train/q_halt_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–…â–„â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/steps</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>final/accuracy</td><td>0.49062</td></tr><tr><td>final/exact_accuracy</td><td>0</td></tr><tr><td>train/accuracy</td><td>0.49064</td></tr><tr><td>train/exact_accuracy</td><td>0</td></tr><tr><td>train/lm_loss</td><td>18.61011</td></tr><tr><td>train/loss</td><td>148.88182</td></tr><tr><td>train/lr</td><td>0.0001</td></tr><tr><td>train/q_halt_loss</td><td>0.00024</td></tr><tr><td>train/steps</td><td>16</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">baseline</strong> at: <a href='https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline/runs/4ebn4t7k' target=\"_blank\">https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline/runs/4ebn4t7k</a><br> View project at: <a href='https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline' target=\"_blank\">https://wandb.ai/jarviszhang-new-york-university/TRM-Baseline</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251202_150805-4ebn4t7k/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“ˆ Final Evaluation...\n",
            "\n",
            "âœ… Experiment Complete!\n",
            "   Final Exact Accuracy: 0.0000\n",
            "\n",
            "======================================================================\n",
            "âœ… Experiment completed!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“Š Final Results:\n",
            "  Exact Accuracy: 0.0000\n",
            "  LM Loss: 1.1609\n",
            "  Avg Steps: 16.00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============ Configuration ============\n",
        "# Set MAX_STEPS based on your time/compute budget:\n",
        "# - 1000 steps: ~5 minutes (quick test)\n",
        "# - 5000 steps: ~25 minutes (reasonable training)\n",
        "# - 10000 steps: ~50 minutes (full training)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ§¹ Cleaning GPU memory before experiment...\")\n",
        "print(\"=\"*70)\n",
        "deep_clear_gpu()\n",
        "\n",
        "MAX_STEPS = 500  # Adjust based on your needs\n",
        "USE_WANDB = True   # Set to False to disable W&B logging\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸš€ Running TRM Baseline Experiment\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  MAX_STEPS: {MAX_STEPS}\")\n",
        "print(f\"  USE_WANDB: {USE_WANDB}\")\n",
        "print(f\"  DEVICE: {DEVICE}\")\n",
        "\n",
        "# ============ Run Baseline Experiment ============\n",
        "# Note: You can modify this to run multiple experiments\n",
        "# Available experiments: list(EXPERIMENTS.keys())\n",
        "\n",
        "experiment_name = \"baseline\"  # or \"baseline-ema\"\n",
        "\n",
        "print(f\"\\nğŸ“‹ Running experiment: {experiment_name}\")\n",
        "result = run_experiment(\n",
        "    experiment_name=experiment_name,\n",
        "    max_steps=MAX_STEPS,\n",
        "    use_wandb=USE_WANDB,\n",
        ")\n",
        "\n",
        "# Store result\n",
        "RESULTS = {experiment_name: result}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… Experiment completed!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nğŸ“Š Final Results:\")\n",
        "print(f\"  Exact Accuracy: {result['final_metrics']['eval_exact_accuracy']:.4f}\")\n",
        "print(f\"  LM Loss: {result['final_metrics']['eval_lm_loss']:.4f}\")\n",
        "print(f\"  Avg Steps: {result['final_metrics']['eval_steps']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKYI2M1clQNQ"
      },
      "source": [
        "## Cell 29: Visualize and Compare Results\n",
        "\n",
        "Generate plots and tables comparing all experiment results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "he9AFBUDlQNQ",
        "outputId": "3627ebe7-ec09-485c-8e94-d2451d74d9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ğŸ“Š Training Results Summary\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Experiment: baseline\n",
            "   Description: Original TRM model (baseline)\n",
            "   Final Exact Accuracy: 0.0000\n",
            "   Final LM Loss: 1.1609\n",
            "   Average ACT Steps: 16.00\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "âœ… Results visualization complete!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Cell 29: Visualize Results\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if 'RESULTS' in dir() and RESULTS:\n",
        "    print(\"=\"*70)\n",
        "    print(\"ğŸ“Š Training Results Summary\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for exp_name, result in RESULTS.items():\n",
        "        print(f\"\\nğŸ“‹ Experiment: {exp_name}\")\n",
        "        print(f\"   Description: {EXPERIMENTS[exp_name]['description']}\")\n",
        "        print(f\"   Final Exact Accuracy: {result['final_metrics']['eval_exact_accuracy']:.4f}\")\n",
        "        print(f\"   Final LM Loss: {result['final_metrics']['eval_lm_loss']:.4f}\")\n",
        "        print(f\"   Average ACT Steps: {result['final_metrics']['eval_steps']:.2f}\")\n",
        "\n",
        "        # Plot training curves if available\n",
        "        if 'history' in result and result['history']:\n",
        "            history = result['history']\n",
        "\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "            # Loss curve\n",
        "            if 'train_loss' in history:\n",
        "                axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "            axes[0].set_xlabel('Step')\n",
        "            axes[0].set_ylabel('Loss')\n",
        "            axes[0].set_title(f'{exp_name}: Training Loss')\n",
        "            axes[0].legend()\n",
        "            axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "            # Accuracy curve\n",
        "            if 'eval_exact_accuracy' in history:\n",
        "                axes[1].plot(history['eval_exact_accuracy'], label='Eval Exact Acc')\n",
        "            axes[1].set_xlabel('Eval Step')\n",
        "            axes[1].set_ylabel('Accuracy')\n",
        "            axes[1].set_title(f'{exp_name}: Evaluation Accuracy')\n",
        "            axes[1].legend()\n",
        "            axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âœ… Results visualization complete!\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"No results to visualize. Run the experiments first!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0244142daba0413bbb60c6251152fdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863e093b87924d44af65ee0df0deb9ec",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_297836094b0043a7bab779d41c04935e",
            "value": "â€‡3831994/?â€‡[00:33&lt;00:00,â€‡116698.61it/s]"
          }
        },
        "048c444bc8304c4dbcb635bfd6ce9c79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09012e04d2b749aa8eaaafc6bc92914a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8482e7036e44fbb80a22ed3236a818": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106b6736b48943f28b0d30afb9d1e798": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1471721645a94e9e9bd98eea60421376": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172333e5bce24dc1ab5c1a69c8cfaf6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ca2bcf38074319a29df9ddd4171867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e0be965b1aa41c4b2beae7b81984582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e916a981f1b439e901270f327f95d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2395f964b0d74bf5a1f96d367b80ac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce722c6de60489d9074d849376386f6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5b896d4addd04e84bc12aec6a6b5bec5",
            "value": "Augmenting:â€‡100%"
          }
        },
        "251de39768164ec2bb91615333ad3c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09012e04d2b749aa8eaaafc6bc92914a",
            "max": 79360390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9b2a3764c17459e96a6647deec87d8b",
            "value": 79360390
          }
        },
        "261596042dfd453db52e15a621add88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af1cb79c0a92411bbab4ade2bd0a3470",
            "max": 718819925,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31bb4725caae47b4b77bcef6e0f3947b",
            "value": 718819925
          }
        },
        "297836094b0043a7bab779d41c04935e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea5873e06a948968f8ed4b55c835ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "30a52a85c5ce47e89dc192ae373c65f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31bb4725caae47b4b77bcef6e0f3947b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3348a10d6f9245469fa73df072bbc763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60ffd019eef7498d8acddd9f75e993f6",
              "IPY_MODEL_261596042dfd453db52e15a621add88e",
              "IPY_MODEL_51b084d4a3f442d3b8c7af0b52b0b733"
            ],
            "layout": "IPY_MODEL_1e0be965b1aa41c4b2beae7b81984582"
          }
        },
        "354ddcf830a14413aed57043e39ee816": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3c32a182c040468d98703e222dad956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cdf3c8ad63b4a89b78e5f7f30adcea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f2a55d2835d4f7f83d4a7fbee1cc65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2395f964b0d74bf5a1f96d367b80ac15",
              "IPY_MODEL_5032b4004f854829a2fbaa0448ad0921",
              "IPY_MODEL_aa41a0f64a33401f94a5527852fd5d26"
            ],
            "layout": "IPY_MODEL_30a52a85c5ce47e89dc192ae373c65f0"
          }
        },
        "404dddce768d4732a411bca4f080b7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f800cd2257c4686a9e030e195c8ac8a",
              "IPY_MODEL_b7ea7a06db8f4f9bb3789a28e4c283e8",
              "IPY_MODEL_0244142daba0413bbb60c6251152fdee"
            ],
            "layout": "IPY_MODEL_98efff2a3e01443383e7d2dfd872310c"
          }
        },
        "490819751e8846e28b9ff67eed553fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5f478716ed461ebeafabf9f3abe842": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce722c6de60489d9074d849376386f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5032b4004f854829a2fbaa0448ad0921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9aa4b5fa5a44f3920514fc1525f3ac",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_845c3c87bd7047c7916b7f8067efe352",
            "value": 1000
          }
        },
        "51b084d4a3f442d3b8c7af0b52b0b733": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f69cf6386ff44ec5920343e3661af529",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_92ecffad6dea4685b7d2618ccff0281e",
            "value": "â€‡719M/719Mâ€‡[00:02&lt;00:00,â€‡466MB/s]"
          }
        },
        "565ccb324af14f7397c529aa82c0f276": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b896d4addd04e84bc12aec6a6b5bec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d584203cf304648a8a1a3c720565ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f800cd2257c4686a9e030e195c8ac8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172333e5bce24dc1ab5c1a69c8cfaf6c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_17ca2bcf38074319a29df9ddd4171867",
            "value": "Readingâ€‡CSV:â€‡"
          }
        },
        "5fe5d387f8ca4be29f8a9dd95bbfb7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ffd019eef7498d8acddd9f75e993f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565ccb324af14f7397c529aa82c0f276",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1e916a981f1b439e901270f327f95d5e",
            "value": "train.csv:â€‡100%"
          }
        },
        "6dfed1f126774c1894c4edc4c9ff8cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e47c02e634d4b3491454a0d534f7ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70789fbc92754577b4a5f27f6a202064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74c4d59c5f2e458fadfa8d85bac5f5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76167bb0a09d402cb15d55bcf9f1cb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e4c56008774c12b021e3e214c40750": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db794b3d0aa402286b4de66ca747a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8371b0424c8640d9a581167cec0b522f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74c4d59c5f2e458fadfa8d85bac5f5a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3c32a182c040468d98703e222dad956f",
            "value": "test.csv:â€‡100%"
          }
        },
        "845c3c87bd7047c7916b7f8067efe352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "863e093b87924d44af65ee0df0deb9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8810d3291bc94b7994f744612744b03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9346060c96254aa5b7b4d0dea3888db5",
              "IPY_MODEL_94e1bc2d3c074e4ebc1cc18d87eec3d0",
              "IPY_MODEL_8e60ec224c1f48f7b7effc70c1d59ce3"
            ],
            "layout": "IPY_MODEL_106b6736b48943f28b0d30afb9d1e798"
          }
        },
        "8ba7b2a3a08542c5b7b1c7334a6db9c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e60ec224c1f48f7b7effc70c1d59ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76167bb0a09d402cb15d55bcf9f1cb5c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fd44217ea51342479518d9c31625e286",
            "value": "â€‡500/500â€‡[15:03&lt;00:00,â€‡â€‡1.84s/it,â€‡loss=148.8818,â€‡acc=0.4906,â€‡lr=1.00e-04]"
          }
        },
        "92ecffad6dea4685b7d2618ccff0281e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9346060c96254aa5b7b4d0dea3888db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba7b2a3a08542c5b7b1c7334a6db9c8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aafcd1ae86f34f48ac893e44fdc66cbd",
            "value": "Training:â€‡100%"
          }
        },
        "94e1bc2d3c074e4ebc1cc18d87eec3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_975aacb7c48544d5910ad92a8a01d8d9",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a34b3abcc54d42d6973dac6cd596fac7",
            "value": 500
          }
        },
        "975aacb7c48544d5910ad92a8a01d8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d9a7ce6d2d40f789a18554de988e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98efff2a3e01443383e7d2dfd872310c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9aa4b5fa5a44f3920514fc1525f3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f9c5d07abb74981a31e500d653cad26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8371b0424c8640d9a581167cec0b522f",
              "IPY_MODEL_251de39768164ec2bb91615333ad3c45",
              "IPY_MODEL_e248404d9ab9429c91b311966eee8dab"
            ],
            "layout": "IPY_MODEL_048c444bc8304c4dbcb635bfd6ce9c79"
          }
        },
        "a34b3abcc54d42d6973dac6cd596fac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a86b552699fe49198648f8089ca78bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa41a0f64a33401f94a5527852fd5d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fe5d387f8ca4be29f8a9dd95bbfb7c7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ab58b3a43a464c7ab8d8280e9c8c96e7",
            "value": "â€‡1000/1000â€‡[00:00&lt;00:00,â€‡82736.05it/s]"
          }
        },
        "aafcd1ae86f34f48ac893e44fdc66cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab58b3a43a464c7ab8d8280e9c8c96e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac2374f51d454953bc5252823c5fec51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b5f478716ed461ebeafabf9f3abe842",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b4bf82ed874f4cd68f7ff6343ffd1969",
            "value": "Readingâ€‡CSV:â€‡"
          }
        },
        "af1cb79c0a92411bbab4ade2bd0a3470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4bf82ed874f4cd68f7ff6343ffd1969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7ea7a06db8f4f9bb3789a28e4c283e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354ddcf830a14413aed57043e39ee816",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98d9a7ce6d2d40f789a18554de988e8a",
            "value": 1
          }
        },
        "bf2d64c97d054a90b6436b0df10120bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbe8c2dea1fd46f9aa929e0285d896d8",
              "IPY_MODEL_e5f0f04a68c74c389c93a3d6d273dbcc",
              "IPY_MODEL_de202c6cb8734091bfba87ff224b2993"
            ],
            "layout": "IPY_MODEL_77e4c56008774c12b021e3e214c40750"
          }
        },
        "c268f37851f94ff3a5de0f22e732d447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbe8c2dea1fd46f9aa929e0285d896d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e47c02e634d4b3491454a0d534f7ff6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3cdf3c8ad63b4a89b78e5f7f30adcea0",
            "value": "Augmenting:â€‡100%"
          }
        },
        "dd2acc101a144854b8b161542da6d066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1471721645a94e9e9bd98eea60421376",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a86b552699fe49198648f8089ca78bac",
            "value": "â€‡422786/?â€‡[00:03&lt;00:00,â€‡112922.36it/s]"
          }
        },
        "de202c6cb8734091bfba87ff224b2993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d584203cf304648a8a1a3c720565ed7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70789fbc92754577b4a5f27f6a202064",
            "value": "â€‡10000/10000â€‡[00:00&lt;00:00,â€‡370240.28it/s]"
          }
        },
        "e248404d9ab9429c91b311966eee8dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9718beb154346a6a46adfd85efa8627",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7db794b3d0aa402286b4de66ca747a2c",
            "value": "â€‡79.4M/79.4Mâ€‡[00:00&lt;00:00,â€‡16.6MB/s]"
          }
        },
        "e5f0f04a68c74c389c93a3d6d273dbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490819751e8846e28b9ff67eed553fa1",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c268f37851f94ff3a5de0f22e732d447",
            "value": 10000
          }
        },
        "e9718beb154346a6a46adfd85efa8627": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3bc8c5a07894432a942e67f1a0dc6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac2374f51d454953bc5252823c5fec51",
              "IPY_MODEL_fe0d9ded37ff4656b9c98951103528a1",
              "IPY_MODEL_dd2acc101a144854b8b161542da6d066"
            ],
            "layout": "IPY_MODEL_0e8482e7036e44fbb80a22ed3236a818"
          }
        },
        "f69cf6386ff44ec5920343e3661af529": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b2a3764c17459e96a6647deec87d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd44217ea51342479518d9c31625e286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0d9ded37ff4656b9c98951103528a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea5873e06a948968f8ed4b55c835ca8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dfed1f126774c1894c4edc4c9ff8cd7",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
